{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac079b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4c20bdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes=pd.read_csv(\"diabetes.csv\")\n",
    "diabetes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74e345eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= diabetes[['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
    "       'BMI', 'DiabetesPedigreeFunction', 'Age']].values\n",
    "y=diabetes[['Outcome']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4de4a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b939be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f68b69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(614, 8)\n",
      "(154, 8)\n",
      "(614, 1)\n",
      "(154, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "429fb95c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(614, 8, 1)\n",
      "(154, 8, 1)\n",
      "(614, 1)\n",
      "(154, 1)\n"
     ]
    }
   ],
   "source": [
    "# Il faut faire un reshape pour les données d'entrainement et de test\n",
    "# Vu que les données sont uni-dimensionels il faut plutot utiliser une convolution 1D\n",
    "# Donc un reshape pour Convolution 1D\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0],X_train.shape[1],1)\n",
    "X_test = X_test.reshape(X_test.shape[0],X_test.shape[1],1) \n",
    "\n",
    "# Maintenant voici leur nouvelle forme\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d51e45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 7, 16)             48        \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 6, 24)             792       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 6, 24)             0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 6, 24)             0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 6, 24)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 144)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 50)                7250      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 51        \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 8,141\n",
      "Trainable params: 8,141\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.2843 - accuracy: 0.6710 - val_loss: 0.1825 - val_accuracy: 0.7078\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.2571 - accuracy: 0.6775 - val_loss: 0.1727 - val_accuracy: 0.7403\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.2336 - accuracy: 0.7166 - val_loss: 0.1912 - val_accuracy: 0.7013\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.2355 - accuracy: 0.7215 - val_loss: 0.1652 - val_accuracy: 0.7532\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.2318 - accuracy: 0.7166 - val_loss: 0.1708 - val_accuracy: 0.7468\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.2332 - accuracy: 0.7036 - val_loss: 0.1786 - val_accuracy: 0.7208\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.2331 - accuracy: 0.7231 - val_loss: 0.1796 - val_accuracy: 0.7013\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.2025 - accuracy: 0.7443 - val_loss: 0.1784 - val_accuracy: 0.7338\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.2208 - accuracy: 0.7280 - val_loss: 0.1625 - val_accuracy: 0.7532\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.2167 - accuracy: 0.7264 - val_loss: 0.1740 - val_accuracy: 0.7273\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.2091 - accuracy: 0.7459 - val_loss: 0.1760 - val_accuracy: 0.7273\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.2149 - accuracy: 0.7410 - val_loss: 0.1675 - val_accuracy: 0.7403\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.2319 - accuracy: 0.7264 - val_loss: 0.1742 - val_accuracy: 0.7078\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.2155 - accuracy: 0.7264 - val_loss: 0.1876 - val_accuracy: 0.6818\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.2255 - accuracy: 0.7313 - val_loss: 0.1741 - val_accuracy: 0.7273\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.2258 - accuracy: 0.7199 - val_loss: 0.1894 - val_accuracy: 0.6948\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.2156 - accuracy: 0.7410 - val_loss: 0.1673 - val_accuracy: 0.7338\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.2102 - accuracy: 0.7508 - val_loss: 0.1637 - val_accuracy: 0.7403\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.2130 - accuracy: 0.7231 - val_loss: 0.1763 - val_accuracy: 0.7143\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.2143 - accuracy: 0.7459 - val_loss: 0.1733 - val_accuracy: 0.7273\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.2119 - accuracy: 0.7410 - val_loss: 0.1692 - val_accuracy: 0.7143\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.2373 - accuracy: 0.7101 - val_loss: 0.1746 - val_accuracy: 0.7013\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1925 - accuracy: 0.7687 - val_loss: 0.1706 - val_accuracy: 0.7338\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.2195 - accuracy: 0.7362 - val_loss: 0.1688 - val_accuracy: 0.7338\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.2094 - accuracy: 0.7524 - val_loss: 0.1772 - val_accuracy: 0.7208\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.2109 - accuracy: 0.7378 - val_loss: 0.1838 - val_accuracy: 0.7078\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.2031 - accuracy: 0.7427 - val_loss: 0.1721 - val_accuracy: 0.7078\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.2074 - accuracy: 0.7622 - val_loss: 0.1725 - val_accuracy: 0.7208\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.1977 - accuracy: 0.7638 - val_loss: 0.1711 - val_accuracy: 0.7208\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.2115 - accuracy: 0.7557 - val_loss: 0.1586 - val_accuracy: 0.7597\n",
      "Epoch 31/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.2313 - accuracy: 0.7264 - val_loss: 0.1838 - val_accuracy: 0.7013\n",
      "Epoch 32/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.2154 - accuracy: 0.7231 - val_loss: 0.1823 - val_accuracy: 0.7208\n",
      "Epoch 33/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.2043 - accuracy: 0.7427 - val_loss: 0.1630 - val_accuracy: 0.7468\n",
      "Epoch 34/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1973 - accuracy: 0.7655 - val_loss: 0.1631 - val_accuracy: 0.7468\n",
      "Epoch 35/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.2165 - accuracy: 0.7378 - val_loss: 0.1781 - val_accuracy: 0.7208\n",
      "Epoch 36/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.1996 - accuracy: 0.7736 - val_loss: 0.1852 - val_accuracy: 0.7208\n",
      "Epoch 37/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.2043 - accuracy: 0.7508 - val_loss: 0.1715 - val_accuracy: 0.7273\n",
      "Epoch 38/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.1980 - accuracy: 0.7622 - val_loss: 0.1694 - val_accuracy: 0.7597\n",
      "Epoch 39/100\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.2022 - accuracy: 0.7557 - val_loss: 0.1690 - val_accuracy: 0.7662\n",
      "Epoch 40/100\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.1888 - accuracy: 0.7720 - val_loss: 0.1891 - val_accuracy: 0.7143\n",
      "Epoch 41/100\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.2004 - accuracy: 0.7541 - val_loss: 0.1821 - val_accuracy: 0.7143\n",
      "Epoch 42/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1867 - accuracy: 0.7850 - val_loss: 0.1771 - val_accuracy: 0.6948\n",
      "Epoch 43/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.2048 - accuracy: 0.7492 - val_loss: 0.1709 - val_accuracy: 0.7338\n",
      "Epoch 44/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1997 - accuracy: 0.7704 - val_loss: 0.1802 - val_accuracy: 0.7273\n",
      "Epoch 45/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1960 - accuracy: 0.7687 - val_loss: 0.1662 - val_accuracy: 0.7403\n",
      "Epoch 46/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.2138 - accuracy: 0.7492 - val_loss: 0.1804 - val_accuracy: 0.7013\n",
      "Epoch 47/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1995 - accuracy: 0.7590 - val_loss: 0.1788 - val_accuracy: 0.7273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1997 - accuracy: 0.7671 - val_loss: 0.1761 - val_accuracy: 0.7273\n",
      "Epoch 49/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.2025 - accuracy: 0.7459 - val_loss: 0.1833 - val_accuracy: 0.6948\n",
      "Epoch 50/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.2057 - accuracy: 0.7508 - val_loss: 0.1685 - val_accuracy: 0.7338\n",
      "Epoch 51/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.2010 - accuracy: 0.7541 - val_loss: 0.1756 - val_accuracy: 0.7208\n",
      "Epoch 52/100\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.1804 - accuracy: 0.77 - 1s 9ms/step - loss: 0.1760 - accuracy: 0.7801 - val_loss: 0.1652 - val_accuracy: 0.7273\n",
      "Epoch 53/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.2110 - accuracy: 0.7606 - val_loss: 0.1749 - val_accuracy: 0.7273\n",
      "Epoch 54/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.1966 - accuracy: 0.7638 - val_loss: 0.1657 - val_accuracy: 0.7208\n",
      "Epoch 55/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.2027 - accuracy: 0.7704 - val_loss: 0.1669 - val_accuracy: 0.7403\n",
      "Epoch 56/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.1920 - accuracy: 0.7736 - val_loss: 0.1682 - val_accuracy: 0.7273\n",
      "Epoch 57/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1885 - accuracy: 0.7671 - val_loss: 0.1740 - val_accuracy: 0.7143\n",
      "Epoch 58/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1841 - accuracy: 0.7671 - val_loss: 0.1604 - val_accuracy: 0.7468\n",
      "Epoch 59/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1899 - accuracy: 0.7752 - val_loss: 0.1606 - val_accuracy: 0.7468\n",
      "Epoch 60/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1857 - accuracy: 0.7704 - val_loss: 0.1652 - val_accuracy: 0.7338\n",
      "Epoch 61/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1979 - accuracy: 0.7606 - val_loss: 0.1659 - val_accuracy: 0.7338\n",
      "Epoch 62/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1993 - accuracy: 0.7752 - val_loss: 0.1748 - val_accuracy: 0.7403\n",
      "Epoch 63/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.2027 - accuracy: 0.7524 - val_loss: 0.1701 - val_accuracy: 0.7338\n",
      "Epoch 64/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1979 - accuracy: 0.7606 - val_loss: 0.1651 - val_accuracy: 0.7532\n",
      "Epoch 65/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1948 - accuracy: 0.7687 - val_loss: 0.1662 - val_accuracy: 0.7208\n",
      "Epoch 66/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1790 - accuracy: 0.7932 - val_loss: 0.1710 - val_accuracy: 0.7468\n",
      "Epoch 67/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1862 - accuracy: 0.7606 - val_loss: 0.1720 - val_accuracy: 0.7078\n",
      "Epoch 68/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1692 - accuracy: 0.7948 - val_loss: 0.1691 - val_accuracy: 0.7468\n",
      "Epoch 69/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1911 - accuracy: 0.7834 - val_loss: 0.1662 - val_accuracy: 0.7273\n",
      "Epoch 70/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1963 - accuracy: 0.7720 - val_loss: 0.1748 - val_accuracy: 0.7078\n",
      "Epoch 71/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1913 - accuracy: 0.7704 - val_loss: 0.1807 - val_accuracy: 0.7273\n",
      "Epoch 72/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.1930 - accuracy: 0.7720 - val_loss: 0.1704 - val_accuracy: 0.7338\n",
      "Epoch 73/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1908 - accuracy: 0.7720 - val_loss: 0.1685 - val_accuracy: 0.7208\n",
      "Epoch 74/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.2017 - accuracy: 0.7638 - val_loss: 0.1786 - val_accuracy: 0.7208\n",
      "Epoch 75/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1798 - accuracy: 0.7866 - val_loss: 0.1673 - val_accuracy: 0.7208\n",
      "Epoch 76/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.2010 - accuracy: 0.7687 - val_loss: 0.1673 - val_accuracy: 0.7273\n",
      "Epoch 77/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.1942 - accuracy: 0.7752 - val_loss: 0.1668 - val_accuracy: 0.7468\n",
      "Epoch 78/100\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.1814 - accuracy: 0.80 - 0s 8ms/step - loss: 0.1848 - accuracy: 0.7932 - val_loss: 0.1661 - val_accuracy: 0.7403\n",
      "Epoch 79/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.1710 - accuracy: 0.7964 - val_loss: 0.1727 - val_accuracy: 0.7273\n",
      "Epoch 80/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.1765 - accuracy: 0.8046 - val_loss: 0.1635 - val_accuracy: 0.7468\n",
      "Epoch 81/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.1957 - accuracy: 0.7785 - val_loss: 0.1592 - val_accuracy: 0.7532\n",
      "Epoch 82/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.1797 - accuracy: 0.7980 - val_loss: 0.1587 - val_accuracy: 0.7403\n",
      "Epoch 83/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.1971 - accuracy: 0.7671 - val_loss: 0.1687 - val_accuracy: 0.7468\n",
      "Epoch 84/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.1967 - accuracy: 0.7866 - val_loss: 0.1765 - val_accuracy: 0.7273\n",
      "Epoch 85/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.1979 - accuracy: 0.7671 - val_loss: 0.1676 - val_accuracy: 0.7532\n",
      "Epoch 86/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1999 - accuracy: 0.7866 - val_loss: 0.1609 - val_accuracy: 0.7532\n",
      "Epoch 87/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1752 - accuracy: 0.7980 - val_loss: 0.1620 - val_accuracy: 0.7403\n",
      "Epoch 88/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.2029 - accuracy: 0.7704 - val_loss: 0.1635 - val_accuracy: 0.7403\n",
      "Epoch 89/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1861 - accuracy: 0.7834 - val_loss: 0.1668 - val_accuracy: 0.7338\n",
      "Epoch 90/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1760 - accuracy: 0.8062 - val_loss: 0.1614 - val_accuracy: 0.7468\n",
      "Epoch 91/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1754 - accuracy: 0.8046 - val_loss: 0.1623 - val_accuracy: 0.7662\n",
      "Epoch 92/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1901 - accuracy: 0.7655 - val_loss: 0.1580 - val_accuracy: 0.7403\n",
      "Epoch 93/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1717 - accuracy: 0.8127 - val_loss: 0.1669 - val_accuracy: 0.7338\n",
      "Epoch 94/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1934 - accuracy: 0.7769 - val_loss: 0.1759 - val_accuracy: 0.7273\n",
      "Epoch 95/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1736 - accuracy: 0.7948 - val_loss: 0.1648 - val_accuracy: 0.7273\n",
      "Epoch 96/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1950 - accuracy: 0.7655 - val_loss: 0.1661 - val_accuracy: 0.7532\n",
      "Epoch 97/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1924 - accuracy: 0.7785 - val_loss: 0.1684 - val_accuracy: 0.7273\n",
      "Epoch 98/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1935 - accuracy: 0.7883 - val_loss: 0.1634 - val_accuracy: 0.7468\n",
      "Epoch 99/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1810 - accuracy: 0.7818 - val_loss: 0.1690 - val_accuracy: 0.7338\n",
      "Epoch 100/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1819 - accuracy: 0.7964 - val_loss: 0.1603 - val_accuracy: 0.7597\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1603 - accuracy: 0.7597\n",
      "Test Accuracy: 0.7597\n"
     ]
    }
   ],
   "source": [
    "#CNN: 1 convolution layer - 1 Pooling - MLP \n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, Flatten, Dropout, MaxPooling1D\n",
    "from keras import regularizers\n",
    "import keras\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "model_cnn = Sequential()\n",
    "model_cnn.add(Conv1D(16, kernel_size=2, activation='relu', input_shape=(8,1), data_format = 'channels_last'))\n",
    "model_cnn.add(Conv1D(24, kernel_size=2, strides=1,activation='relu'))\n",
    "model_cnn.add(MaxPooling1D(pool_size=1, padding='same'))\n",
    "#model_cnn.add(Dropout(0.25))\n",
    "model_cnn.add(Flatten())\n",
    "model_cnn.add(Dense(50, activation='relu'))\n",
    "model_cnn.add(Dense(1))\n",
    "#model_cnn.add(Dropout(0.3))\n",
    "\n",
    "model_cnn.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "\n",
    "model_cnn.summary()\n",
    "history=model_cnn.fit(X_train, y_train, batch_size=10, epochs=100,validation_data=(X_test, y_test))\n",
    "loss, accuracy = model_cnn.evaluate(X_test, y_test, batch_size=None, verbose=1)\n",
    "print(\"Test Accuracy: {:.4f}\".format(accuracy))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ed83e017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "20/20 [==============================] - 2s 84ms/step - loss: 0.9952 - accuracy: 0.6498 - val_loss: 0.9313 - val_accuracy: 0.6558\n",
      "Epoch 2/600\n",
      "20/20 [==============================] - 2s 98ms/step - loss: 0.8992 - accuracy: 0.6498 - val_loss: 0.8394 - val_accuracy: 0.6558\n",
      "Epoch 3/600\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.8541 - accuracy: 0.6498 - val_loss: 0.7870 - val_accuracy: 0.6558\n",
      "Epoch 4/600\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.8079 - accuracy: 0.6498 - val_loss: 0.7627 - val_accuracy: 0.6558\n",
      "Epoch 5/600\n",
      "20/20 [==============================] - 0s 20ms/step - loss: 0.7619 - accuracy: 0.6498 - val_loss: 0.7257 - val_accuracy: 0.6558\n",
      "Epoch 6/600\n",
      "20/20 [==============================] - 0s 22ms/step - loss: 0.7528 - accuracy: 0.6498 - val_loss: 0.7014 - val_accuracy: 0.6558\n",
      "Epoch 7/600\n",
      "20/20 [==============================] - 0s 25ms/step - loss: 0.7243 - accuracy: 0.6498 - val_loss: 0.6843 - val_accuracy: 0.6558\n",
      "Epoch 8/600\n",
      "20/20 [==============================] - 0s 19ms/step - loss: 0.7152 - accuracy: 0.6498 - val_loss: 0.6685 - val_accuracy: 0.6558\n",
      "Epoch 9/600\n",
      "20/20 [==============================] - 1s 27ms/step - loss: 0.6784 - accuracy: 0.6498 - val_loss: 0.6495 - val_accuracy: 0.6558\n",
      "Epoch 10/600\n",
      "20/20 [==============================] - 0s 22ms/step - loss: 0.6754 - accuracy: 0.6498 - val_loss: 0.6386 - val_accuracy: 0.6558\n",
      "Epoch 11/600\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.6607 - accuracy: 0.6694 - val_loss: 0.6273 - val_accuracy: 0.7208\n",
      "Epoch 12/600\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.6439 - accuracy: 0.6889 - val_loss: 0.6205 - val_accuracy: 0.7597\n",
      "Epoch 13/600\n",
      "20/20 [==============================] - 0s 24ms/step - loss: 0.6479 - accuracy: 0.7182 - val_loss: 0.6202 - val_accuracy: 0.7273\n",
      "Epoch 14/600\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.6288 - accuracy: 0.7215 - val_loss: 0.6081 - val_accuracy: 0.7597\n",
      "Epoch 15/600\n",
      "20/20 [==============================] - 0s 24ms/step - loss: 0.6145 - accuracy: 0.7199 - val_loss: 0.6000 - val_accuracy: 0.7597\n",
      "Epoch 16/600\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.6173 - accuracy: 0.7345 - val_loss: 0.5977 - val_accuracy: 0.7662\n",
      "Epoch 17/600\n",
      "20/20 [==============================] - 1s 50ms/step - loss: 0.6174 - accuracy: 0.7378 - val_loss: 0.5957 - val_accuracy: 0.7338\n",
      "Epoch 18/600\n",
      "20/20 [==============================] - 1s 61ms/step - loss: 0.6065 - accuracy: 0.7378 - val_loss: 0.5912 - val_accuracy: 0.7532\n",
      "Epoch 19/600\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 0.5939 - accuracy: 0.7492 - val_loss: 0.5854 - val_accuracy: 0.7727\n",
      "Epoch 20/600\n",
      "20/20 [==============================] - 0s 20ms/step - loss: 0.6029 - accuracy: 0.7378 - val_loss: 0.5848 - val_accuracy: 0.7662\n",
      "Epoch 21/600\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 0.5949 - accuracy: 0.7394 - val_loss: 0.5779 - val_accuracy: 0.7662\n",
      "Epoch 22/600\n",
      "20/20 [==============================] - 0s 20ms/step - loss: 0.5786 - accuracy: 0.7443 - val_loss: 0.5735 - val_accuracy: 0.7662\n",
      "Epoch 23/600\n",
      "20/20 [==============================] - 1s 27ms/step - loss: 0.5883 - accuracy: 0.7492 - val_loss: 0.5678 - val_accuracy: 0.7792\n",
      "Epoch 24/600\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 0.5808 - accuracy: 0.7557 - val_loss: 0.5696 - val_accuracy: 0.7597\n",
      "Epoch 25/600\n",
      "20/20 [==============================] - 0s 20ms/step - loss: 0.5680 - accuracy: 0.7443 - val_loss: 0.5696 - val_accuracy: 0.7597\n",
      "Epoch 26/600\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.5756 - accuracy: 0.7687 - val_loss: 0.5670 - val_accuracy: 0.7532\n",
      "Epoch 27/600\n",
      "20/20 [==============================] - 1s 44ms/step - loss: 0.5807 - accuracy: 0.7687 - val_loss: 0.5661 - val_accuracy: 0.7468\n",
      "Epoch 28/600\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.5531 - accuracy: 0.7671 - val_loss: 0.5603 - val_accuracy: 0.7403\n",
      "Epoch 29/600\n",
      "20/20 [==============================] - 1s 53ms/step - loss: 0.5569 - accuracy: 0.7720 - val_loss: 0.5581 - val_accuracy: 0.7273\n",
      "Epoch 30/600\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.5706 - accuracy: 0.7590 - val_loss: 0.5648 - val_accuracy: 0.7662\n",
      "Epoch 31/600\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.5581 - accuracy: 0.7655 - val_loss: 0.5529 - val_accuracy: 0.7403\n",
      "Epoch 32/600\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 0.5618 - accuracy: 0.7492 - val_loss: 0.5582 - val_accuracy: 0.7792\n",
      "Epoch 33/600\n",
      "20/20 [==============================] - 1s 66ms/step - loss: 0.5758 - accuracy: 0.7459 - val_loss: 0.5517 - val_accuracy: 0.7662\n",
      "Epoch 34/600\n",
      "20/20 [==============================] - 1s 26ms/step - loss: 0.5523 - accuracy: 0.7622 - val_loss: 0.5460 - val_accuracy: 0.7597\n",
      "Epoch 35/600\n",
      "20/20 [==============================] - 0s 20ms/step - loss: 0.5549 - accuracy: 0.7638 - val_loss: 0.5480 - val_accuracy: 0.7727\n",
      "Epoch 36/600\n",
      "20/20 [==============================] - 0s 20ms/step - loss: 0.5582 - accuracy: 0.7590 - val_loss: 0.5457 - val_accuracy: 0.7597\n",
      "Epoch 37/600\n",
      "20/20 [==============================] - 1s 27ms/step - loss: 0.5614 - accuracy: 0.7736 - val_loss: 0.5451 - val_accuracy: 0.7468\n",
      "Epoch 38/600\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.5500 - accuracy: 0.7671 - val_loss: 0.5454 - val_accuracy: 0.7403\n",
      "Epoch 39/600\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.5527 - accuracy: 0.7606 - val_loss: 0.5426 - val_accuracy: 0.7532\n",
      "Epoch 40/600\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.5254 - accuracy: 0.7932 - val_loss: 0.5366 - val_accuracy: 0.7532\n",
      "Epoch 41/600\n",
      "20/20 [==============================] - 1s 48ms/step - loss: 0.5464 - accuracy: 0.7655 - val_loss: 0.5349 - val_accuracy: 0.7468\n",
      "Epoch 42/600\n",
      "20/20 [==============================] - 1s 56ms/step - loss: 0.5299 - accuracy: 0.7932 - val_loss: 0.5364 - val_accuracy: 0.7468\n",
      "Epoch 43/600\n",
      "20/20 [==============================] - 1s 59ms/step - loss: 0.5497 - accuracy: 0.7671 - val_loss: 0.5369 - val_accuracy: 0.7532\n",
      "Epoch 44/600\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.5420 - accuracy: 0.7655 - val_loss: 0.5312 - val_accuracy: 0.7597\n",
      "Epoch 45/600\n",
      "20/20 [==============================] - 1s 56ms/step - loss: 0.5556 - accuracy: 0.7492 - val_loss: 0.5330 - val_accuracy: 0.7662\n",
      "Epoch 46/600\n",
      "20/20 [==============================] - 1s 47ms/step - loss: 0.5294 - accuracy: 0.7818 - val_loss: 0.5312 - val_accuracy: 0.7662\n",
      "Epoch 47/600\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.5491 - accuracy: 0.7524 - val_loss: 0.5305 - val_accuracy: 0.7727\n",
      "Epoch 48/600\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.5408 - accuracy: 0.7590 - val_loss: 0.5303 - val_accuracy: 0.7727\n",
      "Epoch 49/600\n",
      "20/20 [==============================] - 1s 43ms/step - loss: 0.5443 - accuracy: 0.7541 - val_loss: 0.5298 - val_accuracy: 0.7597\n",
      "Epoch 50/600\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.5282 - accuracy: 0.7834 - val_loss: 0.5247 - val_accuracy: 0.7727\n",
      "Epoch 51/600\n",
      "20/20 [==============================] - 1s 48ms/step - loss: 0.5441 - accuracy: 0.7606 - val_loss: 0.5340 - val_accuracy: 0.7468\n",
      "Epoch 52/600\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.5322 - accuracy: 0.7590 - val_loss: 0.5255 - val_accuracy: 0.7662\n",
      "Epoch 53/600\n",
      "20/20 [==============================] - 1s 46ms/step - loss: 0.5349 - accuracy: 0.7638 - val_loss: 0.5283 - val_accuracy: 0.7597\n",
      "Epoch 54/600\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.5410 - accuracy: 0.7394 - val_loss: 0.5262 - val_accuracy: 0.7597\n",
      "Epoch 55/600\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.5251 - accuracy: 0.7736 - val_loss: 0.5278 - val_accuracy: 0.7532\n",
      "Epoch 56/600\n",
      "20/20 [==============================] - 1s 45ms/step - loss: 0.5212 - accuracy: 0.7752 - val_loss: 0.5240 - val_accuracy: 0.7727\n",
      "Epoch 57/600\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.5300 - accuracy: 0.7687 - val_loss: 0.5236 - val_accuracy: 0.7662\n",
      "Epoch 58/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 1s 40ms/step - loss: 0.5315 - accuracy: 0.7850 - val_loss: 0.5266 - val_accuracy: 0.7597\n",
      "Epoch 59/600\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.5206 - accuracy: 0.7671 - val_loss: 0.5274 - val_accuracy: 0.7597\n",
      "Epoch 60/600\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 0.5342 - accuracy: 0.7590 - val_loss: 0.5315 - val_accuracy: 0.7662\n",
      "Epoch 61/600\n",
      "20/20 [==============================] - 1s 27ms/step - loss: 0.5314 - accuracy: 0.7573 - val_loss: 0.5162 - val_accuracy: 0.7597\n",
      "Epoch 62/600\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.5272 - accuracy: 0.7590 - val_loss: 0.5202 - val_accuracy: 0.7662\n",
      "Epoch 63/600\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.5315 - accuracy: 0.7704 - val_loss: 0.5208 - val_accuracy: 0.7727\n",
      "Epoch 64/600\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.5259 - accuracy: 0.7704 - val_loss: 0.5185 - val_accuracy: 0.7662\n",
      "Epoch 65/600\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.5223 - accuracy: 0.7720 - val_loss: 0.5184 - val_accuracy: 0.7727\n",
      "Epoch 66/600\n",
      "20/20 [==============================] - 1s 43ms/step - loss: 0.5331 - accuracy: 0.7541 - val_loss: 0.5264 - val_accuracy: 0.7662\n",
      "Epoch 67/600\n",
      "20/20 [==============================] - 1s 47ms/step - loss: 0.5127 - accuracy: 0.7818 - val_loss: 0.5207 - val_accuracy: 0.7662\n",
      "Epoch 68/600\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.5215 - accuracy: 0.7752 - val_loss: 0.5160 - val_accuracy: 0.7597\n",
      "Epoch 69/600\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 0.5297 - accuracy: 0.7752 - val_loss: 0.5214 - val_accuracy: 0.7468\n",
      "Epoch 70/600\n",
      "20/20 [==============================] - 1s 42ms/step - loss: 0.5319 - accuracy: 0.7443 - val_loss: 0.5124 - val_accuracy: 0.7662\n",
      "Epoch 71/600\n",
      "20/20 [==============================] - 1s 45ms/step - loss: 0.5249 - accuracy: 0.7638 - val_loss: 0.5248 - val_accuracy: 0.7597\n",
      "Epoch 72/600\n",
      "20/20 [==============================] - 1s 50ms/step - loss: 0.5119 - accuracy: 0.7866 - val_loss: 0.5138 - val_accuracy: 0.7792\n",
      "Epoch 73/600\n",
      "20/20 [==============================] - 1s 54ms/step - loss: 0.5161 - accuracy: 0.7736 - val_loss: 0.5176 - val_accuracy: 0.7532\n",
      "Epoch 74/600\n",
      "20/20 [==============================] - 1s 48ms/step - loss: 0.5293 - accuracy: 0.7508 - val_loss: 0.5084 - val_accuracy: 0.7792\n",
      "Epoch 75/600\n",
      "20/20 [==============================] - 1s 43ms/step - loss: 0.5154 - accuracy: 0.7622 - val_loss: 0.5116 - val_accuracy: 0.7727\n",
      "Epoch 76/600\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.5158 - accuracy: 0.7655 - val_loss: 0.5213 - val_accuracy: 0.7532\n",
      "Epoch 77/600\n",
      "20/20 [==============================] - 1s 48ms/step - loss: 0.5118 - accuracy: 0.7720 - val_loss: 0.5063 - val_accuracy: 0.7662\n",
      "Epoch 78/600\n",
      "20/20 [==============================] - 1s 43ms/step - loss: 0.5166 - accuracy: 0.7866 - val_loss: 0.5056 - val_accuracy: 0.7662\n",
      "Epoch 79/600\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.5057 - accuracy: 0.7834 - val_loss: 0.5098 - val_accuracy: 0.7662\n",
      "Epoch 80/600\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 0.5153 - accuracy: 0.7801 - val_loss: 0.5120 - val_accuracy: 0.7597\n",
      "Epoch 81/600\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.5071 - accuracy: 0.7736 - val_loss: 0.5073 - val_accuracy: 0.7727\n",
      "Epoch 82/600\n",
      "20/20 [==============================] - 1s 42ms/step - loss: 0.5256 - accuracy: 0.7638 - val_loss: 0.5136 - val_accuracy: 0.7662\n",
      "Epoch 83/600\n",
      "20/20 [==============================] - 1s 45ms/step - loss: 0.5024 - accuracy: 0.7899 - val_loss: 0.5044 - val_accuracy: 0.7727\n",
      "Epoch 84/600\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.5184 - accuracy: 0.7736 - val_loss: 0.5074 - val_accuracy: 0.7532\n",
      "Epoch 85/600\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.5253 - accuracy: 0.7573 - val_loss: 0.5098 - val_accuracy: 0.7662\n",
      "Epoch 86/600\n",
      "20/20 [==============================] - 1s 42ms/step - loss: 0.5144 - accuracy: 0.7850 - val_loss: 0.5092 - val_accuracy: 0.7597\n",
      "Epoch 87/600\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.5065 - accuracy: 0.7980 - val_loss: 0.5059 - val_accuracy: 0.7727\n",
      "Epoch 88/600\n",
      "20/20 [==============================] - 1s 42ms/step - loss: 0.5071 - accuracy: 0.7704 - val_loss: 0.5047 - val_accuracy: 0.7597\n",
      "Epoch 89/600\n",
      "20/20 [==============================] - 2s 87ms/step - loss: 0.5039 - accuracy: 0.7785 - val_loss: 0.5057 - val_accuracy: 0.7597\n",
      "Epoch 90/600\n",
      "20/20 [==============================] - 1s 54ms/step - loss: 0.5058 - accuracy: 0.7769 - val_loss: 0.5086 - val_accuracy: 0.7468\n",
      "Epoch 91/600\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.5015 - accuracy: 0.7948 - val_loss: 0.5065 - val_accuracy: 0.7727\n",
      "Epoch 92/600\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.5017 - accuracy: 0.7866 - val_loss: 0.5046 - val_accuracy: 0.7597\n",
      "Epoch 93/600\n",
      "20/20 [==============================] - 1s 74ms/step - loss: 0.5092 - accuracy: 0.7590 - val_loss: 0.5086 - val_accuracy: 0.7468\n",
      "Epoch 94/600\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.5076 - accuracy: 0.7818 - val_loss: 0.5078 - val_accuracy: 0.7662\n",
      "Epoch 95/600\n",
      "20/20 [==============================] - 1s 48ms/step - loss: 0.5069 - accuracy: 0.7801 - val_loss: 0.5058 - val_accuracy: 0.7662\n",
      "Epoch 96/600\n",
      "20/20 [==============================] - 0s 25ms/step - loss: 0.4953 - accuracy: 0.7899 - val_loss: 0.5078 - val_accuracy: 0.7532\n",
      "Epoch 97/600\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.5177 - accuracy: 0.7752 - val_loss: 0.5080 - val_accuracy: 0.7662\n",
      "Epoch 98/600\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.4881 - accuracy: 0.7720 - val_loss: 0.5058 - val_accuracy: 0.7662\n",
      "Epoch 99/600\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.5063 - accuracy: 0.7801 - val_loss: 0.5029 - val_accuracy: 0.7662\n",
      "Epoch 100/600\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.5015 - accuracy: 0.7899 - val_loss: 0.5036 - val_accuracy: 0.7532\n",
      "Epoch 101/600\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.4915 - accuracy: 0.7801 - val_loss: 0.5020 - val_accuracy: 0.7662\n",
      "Epoch 102/600\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 0.4941 - accuracy: 0.7964 - val_loss: 0.5009 - val_accuracy: 0.7662\n",
      "Epoch 103/600\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.5096 - accuracy: 0.7866 - val_loss: 0.5085 - val_accuracy: 0.7597\n",
      "Epoch 104/600\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.4982 - accuracy: 0.7834 - val_loss: 0.5021 - val_accuracy: 0.7532\n",
      "Epoch 105/600\n",
      "20/20 [==============================] - 1s 25ms/step - loss: 0.4935 - accuracy: 0.7932 - val_loss: 0.4959 - val_accuracy: 0.7597\n",
      "Epoch 106/600\n",
      "20/20 [==============================] - 1s 27ms/step - loss: 0.4914 - accuracy: 0.7801 - val_loss: 0.5048 - val_accuracy: 0.7597\n",
      "Epoch 107/600\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.5088 - accuracy: 0.7866 - val_loss: 0.5001 - val_accuracy: 0.7597\n",
      "Epoch 108/600\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.5001 - accuracy: 0.7883 - val_loss: 0.5043 - val_accuracy: 0.7662\n",
      "Epoch 109/600\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.5054 - accuracy: 0.7606 - val_loss: 0.5047 - val_accuracy: 0.7727\n",
      "Epoch 110/600\n",
      "20/20 [==============================] - 1s 46ms/step - loss: 0.4965 - accuracy: 0.7883 - val_loss: 0.4973 - val_accuracy: 0.7662\n",
      "Epoch 111/600\n",
      "20/20 [==============================] - 0s 24ms/step - loss: 0.4975 - accuracy: 0.7834 - val_loss: 0.5017 - val_accuracy: 0.7468\n",
      "Epoch 112/600\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.5037 - accuracy: 0.7818 - val_loss: 0.5017 - val_accuracy: 0.7597\n",
      "Epoch 113/600\n",
      "20/20 [==============================] - 0s 24ms/step - loss: 0.4919 - accuracy: 0.7785 - val_loss: 0.5032 - val_accuracy: 0.7597\n",
      "Epoch 114/600\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.5008 - accuracy: 0.7671 - val_loss: 0.5049 - val_accuracy: 0.7662\n",
      "Epoch 115/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 1s 37ms/step - loss: 0.4840 - accuracy: 0.7704 - val_loss: 0.4991 - val_accuracy: 0.7532\n",
      "Epoch 116/600\n",
      "20/20 [==============================] - 1s 48ms/step - loss: 0.4978 - accuracy: 0.7752 - val_loss: 0.5041 - val_accuracy: 0.7597\n",
      "Epoch 117/600\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.4983 - accuracy: 0.7752 - val_loss: 0.4980 - val_accuracy: 0.7532\n",
      "Epoch 118/600\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.5026 - accuracy: 0.7801 - val_loss: 0.4989 - val_accuracy: 0.7727\n",
      "Epoch 119/600\n",
      "20/20 [==============================] - 1s 56ms/step - loss: 0.4930 - accuracy: 0.7736 - val_loss: 0.4988 - val_accuracy: 0.7597\n",
      "Epoch 120/600\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.4830 - accuracy: 0.7883 - val_loss: 0.4931 - val_accuracy: 0.7597\n",
      "Epoch 121/600\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.5020 - accuracy: 0.7687 - val_loss: 0.4962 - val_accuracy: 0.7662\n",
      "Epoch 122/600\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.5024 - accuracy: 0.7655 - val_loss: 0.4985 - val_accuracy: 0.7597\n",
      "Epoch 123/600\n",
      "20/20 [==============================] - 1s 54ms/step - loss: 0.5099 - accuracy: 0.7606 - val_loss: 0.4933 - val_accuracy: 0.7597\n",
      "Epoch 124/600\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.4848 - accuracy: 0.7687 - val_loss: 0.4925 - val_accuracy: 0.7597\n",
      "Epoch 125/600\n",
      "20/20 [==============================] - 1s 59ms/step - loss: 0.4757 - accuracy: 0.7818 - val_loss: 0.4926 - val_accuracy: 0.7532\n",
      "Epoch 126/600\n",
      "20/20 [==============================] - 1s 54ms/step - loss: 0.4965 - accuracy: 0.7752 - val_loss: 0.4962 - val_accuracy: 0.7532\n",
      "Epoch 127/600\n",
      "20/20 [==============================] - 1s 60ms/step - loss: 0.4966 - accuracy: 0.7866 - val_loss: 0.4981 - val_accuracy: 0.7403s - loss: 0.4895 - accuracy: 0.\n",
      "Epoch 128/600\n",
      "20/20 [==============================] - 1s 54ms/step - loss: 0.4835 - accuracy: 0.7964 - val_loss: 0.4985 - val_accuracy: 0.7532\n",
      "Epoch 129/600\n",
      "20/20 [==============================] - 1s 46ms/step - loss: 0.4924 - accuracy: 0.7752 - val_loss: 0.4973 - val_accuracy: 0.7597\n",
      "Epoch 130/600\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.5021 - accuracy: 0.7866 - val_loss: 0.4929 - val_accuracy: 0.7597\n",
      "Epoch 131/600\n",
      "20/20 [==============================] - 1s 46ms/step - loss: 0.4758 - accuracy: 0.7899 - val_loss: 0.4943 - val_accuracy: 0.7532\n",
      "Epoch 132/600\n",
      "20/20 [==============================] - 1s 43ms/step - loss: 0.4931 - accuracy: 0.7720 - val_loss: 0.4939 - val_accuracy: 0.7597\n",
      "Epoch 133/600\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 0.4690 - accuracy: 0.8013 - val_loss: 0.4995 - val_accuracy: 0.7532\n",
      "Epoch 134/600\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.4893 - accuracy: 0.7818 - val_loss: 0.4992 - val_accuracy: 0.7532\n",
      "Epoch 135/600\n",
      "20/20 [==============================] - 1s 46ms/step - loss: 0.4954 - accuracy: 0.7752 - val_loss: 0.4946 - val_accuracy: 0.7597\n",
      "Epoch 136/600\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.4744 - accuracy: 0.7818 - val_loss: 0.4930 - val_accuracy: 0.7532\n",
      "Epoch 137/600\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.4767 - accuracy: 0.7997 - val_loss: 0.4921 - val_accuracy: 0.7597\n",
      "Epoch 138/600\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.4840 - accuracy: 0.7915 - val_loss: 0.4973 - val_accuracy: 0.7597\n",
      "Epoch 139/600\n",
      "20/20 [==============================] - 1s 52ms/step - loss: 0.4796 - accuracy: 0.7915 - val_loss: 0.4933 - val_accuracy: 0.7662\n",
      "Epoch 140/600\n",
      "20/20 [==============================] - 1s 44ms/step - loss: 0.4863 - accuracy: 0.7883 - val_loss: 0.4936 - val_accuracy: 0.7662\n",
      "Epoch 141/600\n",
      "20/20 [==============================] - 1s 48ms/step - loss: 0.5021 - accuracy: 0.7850 - val_loss: 0.4879 - val_accuracy: 0.7727\n",
      "Epoch 142/600\n",
      "20/20 [==============================] - 1s 46ms/step - loss: 0.4866 - accuracy: 0.7964 - val_loss: 0.4887 - val_accuracy: 0.7532\n",
      "Epoch 143/600\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.4789 - accuracy: 0.7932 - val_loss: 0.4932 - val_accuracy: 0.7532\n",
      "Epoch 144/600\n",
      "20/20 [==============================] - 1s 46ms/step - loss: 0.4944 - accuracy: 0.7883 - val_loss: 0.4935 - val_accuracy: 0.7597\n",
      "Epoch 145/600\n",
      "20/20 [==============================] - 1s 52ms/step - loss: 0.4891 - accuracy: 0.7834 - val_loss: 0.4898 - val_accuracy: 0.7532\n",
      "Epoch 146/600\n",
      "20/20 [==============================] - 1s 49ms/step - loss: 0.4881 - accuracy: 0.7752 - val_loss: 0.4958 - val_accuracy: 0.7662\n",
      "Epoch 147/600\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.4804 - accuracy: 0.7752 - val_loss: 0.4978 - val_accuracy: 0.7662\n",
      "Epoch 148/600\n",
      "20/20 [==============================] - 1s 51ms/step - loss: 0.4918 - accuracy: 0.7752 - val_loss: 0.4921 - val_accuracy: 0.7468\n",
      "Epoch 149/600\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.4841 - accuracy: 0.7866 - val_loss: 0.5016 - val_accuracy: 0.7468\n",
      "Epoch 150/600\n",
      "20/20 [==============================] - 1s 47ms/step - loss: 0.4934 - accuracy: 0.7915 - val_loss: 0.4864 - val_accuracy: 0.7468\n",
      "Epoch 151/600\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.4870 - accuracy: 0.8013 - val_loss: 0.4908 - val_accuracy: 0.7662\n",
      "Epoch 152/600\n",
      "20/20 [==============================] - 1s 43ms/step - loss: 0.5023 - accuracy: 0.7785 - val_loss: 0.4963 - val_accuracy: 0.7597\n",
      "Epoch 153/600\n",
      "20/20 [==============================] - 1s 53ms/step - loss: 0.4911 - accuracy: 0.7883 - val_loss: 0.4951 - val_accuracy: 0.7468\n",
      "Epoch 154/600\n",
      "20/20 [==============================] - 1s 42ms/step - loss: 0.4841 - accuracy: 0.7866 - val_loss: 0.4887 - val_accuracy: 0.7597\n",
      "Epoch 155/600\n",
      "20/20 [==============================] - 1s 45ms/step - loss: 0.4907 - accuracy: 0.7801 - val_loss: 0.4908 - val_accuracy: 0.7597\n",
      "Epoch 156/600\n",
      "20/20 [==============================] - 1s 45ms/step - loss: 0.5035 - accuracy: 0.7720 - val_loss: 0.4887 - val_accuracy: 0.7532\n",
      "Epoch 157/600\n",
      "20/20 [==============================] - 1s 42ms/step - loss: 0.4889 - accuracy: 0.7883 - val_loss: 0.4866 - val_accuracy: 0.7532\n",
      "Epoch 158/600\n",
      "20/20 [==============================] - 1s 65ms/step - loss: 0.4804 - accuracy: 0.7850 - val_loss: 0.4896 - val_accuracy: 0.7662\n",
      "Epoch 159/600\n",
      "20/20 [==============================] - 1s 49ms/step - loss: 0.4759 - accuracy: 0.7997 - val_loss: 0.4869 - val_accuracy: 0.7532\n",
      "Epoch 160/600\n",
      "20/20 [==============================] - 1s 42ms/step - loss: 0.4732 - accuracy: 0.8111 - val_loss: 0.4851 - val_accuracy: 0.7597\n",
      "Epoch 161/600\n",
      "20/20 [==============================] - 1s 46ms/step - loss: 0.4831 - accuracy: 0.7899 - val_loss: 0.4909 - val_accuracy: 0.7532\n",
      "Epoch 162/600\n",
      "20/20 [==============================] - 1s 46ms/step - loss: 0.4762 - accuracy: 0.7980 - val_loss: 0.4908 - val_accuracy: 0.7597\n",
      "Epoch 163/600\n",
      "20/20 [==============================] - 1s 54ms/step - loss: 0.4584 - accuracy: 0.8127 - val_loss: 0.4862 - val_accuracy: 0.7597\n",
      "Epoch 164/600\n",
      "20/20 [==============================] - 1s 51ms/step - loss: 0.4854 - accuracy: 0.7850 - val_loss: 0.4870 - val_accuracy: 0.7532\n",
      "Epoch 165/600\n",
      "20/20 [==============================] - 1s 42ms/step - loss: 0.4754 - accuracy: 0.7980 - val_loss: 0.4862 - val_accuracy: 0.7662\n",
      "Epoch 166/600\n",
      "20/20 [==============================] - 1s 58ms/step - loss: 0.4896 - accuracy: 0.7801 - val_loss: 0.4889 - val_accuracy: 0.7727\n",
      "Epoch 167/600\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.4690 - accuracy: 0.8046 - val_loss: 0.4863 - val_accuracy: 0.7597\n",
      "Epoch 168/600\n",
      "20/20 [==============================] - 1s 54ms/step - loss: 0.4899 - accuracy: 0.7818 - val_loss: 0.4882 - val_accuracy: 0.7532\n",
      "Epoch 169/600\n",
      "20/20 [==============================] - 1s 42ms/step - loss: 0.4725 - accuracy: 0.7899 - val_loss: 0.4893 - val_accuracy: 0.7532\n",
      "Epoch 170/600\n",
      "20/20 [==============================] - 1s 55ms/step - loss: 0.4811 - accuracy: 0.7818 - val_loss: 0.4866 - val_accuracy: 0.7662\n",
      "Epoch 171/600\n",
      "20/20 [==============================] - 1s 43ms/step - loss: 0.4778 - accuracy: 0.7769 - val_loss: 0.4868 - val_accuracy: 0.7597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/600\n",
      "20/20 [==============================] - 1s 53ms/step - loss: 0.4858 - accuracy: 0.7752 - val_loss: 0.4869 - val_accuracy: 0.7597\n",
      "Epoch 173/600\n",
      "20/20 [==============================] - 1s 46ms/step - loss: 0.4844 - accuracy: 0.7785 - val_loss: 0.4858 - val_accuracy: 0.7532\n",
      "Epoch 174/600\n",
      "20/20 [==============================] - 1s 45ms/step - loss: 0.4842 - accuracy: 0.7834 - val_loss: 0.4869 - val_accuracy: 0.7532\n",
      "Epoch 175/600\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 0.4732 - accuracy: 0.7883 - val_loss: 0.4886 - val_accuracy: 0.7532\n",
      "Epoch 176/600\n",
      "20/20 [==============================] - 1s 43ms/step - loss: 0.4749 - accuracy: 0.7866 - val_loss: 0.4915 - val_accuracy: 0.7532\n",
      "Epoch 177/600\n",
      "20/20 [==============================] - 1s 45ms/step - loss: 0.4790 - accuracy: 0.7915 - val_loss: 0.4836 - val_accuracy: 0.7662\n",
      "Epoch 178/600\n",
      "20/20 [==============================] - 1s 45ms/step - loss: 0.4826 - accuracy: 0.7932 - val_loss: 0.4858 - val_accuracy: 0.7597\n",
      "Epoch 179/600\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 0.4791 - accuracy: 0.7980 - val_loss: 0.4847 - val_accuracy: 0.7597\n",
      "Epoch 180/600\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.4844 - accuracy: 0.7899 - val_loss: 0.4848 - val_accuracy: 0.7662\n",
      "Epoch 181/600\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 0.4875 - accuracy: 0.7964 - val_loss: 0.4803 - val_accuracy: 0.7532\n",
      "Epoch 182/600\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.4749 - accuracy: 0.7964 - val_loss: 0.4779 - val_accuracy: 0.7468\n",
      "Epoch 183/600\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.4716 - accuracy: 0.8062 - val_loss: 0.4826 - val_accuracy: 0.7597\n",
      "Epoch 184/600\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.4724 - accuracy: 0.7899 - val_loss: 0.4854 - val_accuracy: 0.7532\n",
      "Epoch 185/600\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.4850 - accuracy: 0.7915 - val_loss: 0.4817 - val_accuracy: 0.7597\n",
      "Epoch 186/600\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.4600 - accuracy: 0.8078 - val_loss: 0.4772 - val_accuracy: 0.7727\n",
      "Epoch 187/600\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.4770 - accuracy: 0.7850 - val_loss: 0.4872 - val_accuracy: 0.7403\n",
      "Epoch 188/600\n",
      "20/20 [==============================] - 1s 43ms/step - loss: 0.4817 - accuracy: 0.7850 - val_loss: 0.4875 - val_accuracy: 0.7597\n",
      "Epoch 189/600\n",
      "20/20 [==============================] - 1s 45ms/step - loss: 0.4829 - accuracy: 0.7834 - val_loss: 0.4860 - val_accuracy: 0.7532\n",
      "Epoch 190/600\n",
      "20/20 [==============================] - 1s 57ms/step - loss: 0.4781 - accuracy: 0.7850 - val_loss: 0.4876 - val_accuracy: 0.7468\n",
      "Epoch 191/600\n",
      "20/20 [==============================] - 1s 50ms/step - loss: 0.4759 - accuracy: 0.7980 - val_loss: 0.4809 - val_accuracy: 0.7532\n",
      "Epoch 192/600\n",
      "20/20 [==============================] - 1s 45ms/step - loss: 0.4811 - accuracy: 0.7671 - val_loss: 0.4863 - val_accuracy: 0.7532\n",
      "Epoch 193/600\n",
      "20/20 [==============================] - 1s 48ms/step - loss: 0.4859 - accuracy: 0.7801 - val_loss: 0.4817 - val_accuracy: 0.7597\n",
      "Epoch 194/600\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.4688 - accuracy: 0.7915 - val_loss: 0.4857 - val_accuracy: 0.7662\n",
      "Epoch 195/600\n",
      "20/20 [==============================] - 1s 50ms/step - loss: 0.4684 - accuracy: 0.7997 - val_loss: 0.4843 - val_accuracy: 0.7532\n",
      "Epoch 196/600\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.4555 - accuracy: 0.7883 - val_loss: 0.4838 - val_accuracy: 0.7597\n",
      "Epoch 197/600\n",
      "20/20 [==============================] - 1s 42ms/step - loss: 0.4859 - accuracy: 0.7883 - val_loss: 0.4904 - val_accuracy: 0.7597\n",
      "Epoch 198/600\n",
      "20/20 [==============================] - 1s 43ms/step - loss: 0.4860 - accuracy: 0.7785 - val_loss: 0.4867 - val_accuracy: 0.7662\n",
      "Epoch 199/600\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.4777 - accuracy: 0.7948 - val_loss: 0.4882 - val_accuracy: 0.7403\n",
      "Epoch 200/600\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 0.4698 - accuracy: 0.7932 - val_loss: 0.4832 - val_accuracy: 0.7597\n",
      "Epoch 201/600\n",
      "20/20 [==============================] - 1s 42ms/step - loss: 0.4794 - accuracy: 0.7883 - val_loss: 0.4866 - val_accuracy: 0.7403\n",
      "Epoch 202/600\n",
      "20/20 [==============================] - 1s 48ms/step - loss: 0.4689 - accuracy: 0.7964 - val_loss: 0.4872 - val_accuracy: 0.7597\n",
      "Epoch 203/600\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.4600 - accuracy: 0.7915 - val_loss: 0.4826 - val_accuracy: 0.7597\n",
      "Epoch 204/600\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.4756 - accuracy: 0.7850 - val_loss: 0.4849 - val_accuracy: 0.7532\n",
      "Epoch 205/600\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.4756 - accuracy: 0.7834 - val_loss: 0.4830 - val_accuracy: 0.7532\n",
      "Epoch 206/600\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.4839 - accuracy: 0.8046 - val_loss: 0.4857 - val_accuracy: 0.7597\n",
      "Epoch 207/600\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.4696 - accuracy: 0.8013 - val_loss: 0.4823 - val_accuracy: 0.7662\n",
      "Epoch 208/600\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.4628 - accuracy: 0.7948 - val_loss: 0.4847 - val_accuracy: 0.7532\n",
      "Epoch 209/600\n",
      "20/20 [==============================] - 1s 60ms/step - loss: 0.4716 - accuracy: 0.8046 - val_loss: 0.4823 - val_accuracy: 0.7597\n",
      "Epoch 210/600\n",
      "20/20 [==============================] - 1s 65ms/step - loss: 0.4645 - accuracy: 0.8013 - val_loss: 0.4822 - val_accuracy: 0.7597\n",
      "Epoch 211/600\n",
      "20/20 [==============================] - 1s 54ms/step - loss: 0.4695 - accuracy: 0.7980 - val_loss: 0.4856 - val_accuracy: 0.7468\n",
      "Epoch 212/600\n",
      "20/20 [==============================] - 1s 44ms/step - loss: 0.4644 - accuracy: 0.7899 - val_loss: 0.4828 - val_accuracy: 0.7468\n",
      "Epoch 213/600\n",
      "20/20 [==============================] - 1s 45ms/step - loss: 0.4610 - accuracy: 0.8029 - val_loss: 0.4838 - val_accuracy: 0.7532\n",
      "Epoch 214/600\n",
      "20/20 [==============================] - 1s 47ms/step - loss: 0.4635 - accuracy: 0.7980 - val_loss: 0.4807 - val_accuracy: 0.7662\n",
      "Epoch 215/600\n",
      "20/20 [==============================] - 1s 54ms/step - loss: 0.4568 - accuracy: 0.8111 - val_loss: 0.4813 - val_accuracy: 0.7597\n",
      "Epoch 216/600\n",
      "20/20 [==============================] - 1s 48ms/step - loss: 0.4536 - accuracy: 0.7948 - val_loss: 0.4780 - val_accuracy: 0.7727\n",
      "Epoch 217/600\n",
      "20/20 [==============================] - 1s 52ms/step - loss: 0.4624 - accuracy: 0.8143 - val_loss: 0.4872 - val_accuracy: 0.7597\n",
      "Epoch 218/600\n",
      "20/20 [==============================] - 1s 48ms/step - loss: 0.4659 - accuracy: 0.7834 - val_loss: 0.4850 - val_accuracy: 0.7532\n",
      "Epoch 219/600\n",
      "20/20 [==============================] - 1s 47ms/step - loss: 0.4586 - accuracy: 0.7948 - val_loss: 0.4786 - val_accuracy: 0.7727\n",
      "Epoch 220/600\n",
      "20/20 [==============================] - 1s 50ms/step - loss: 0.4683 - accuracy: 0.8062 - val_loss: 0.4792 - val_accuracy: 0.7662\n",
      "Epoch 221/600\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.4710 - accuracy: 0.7883 - val_loss: 0.4830 - val_accuracy: 0.7532\n",
      "Epoch 222/600\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.4731 - accuracy: 0.7850 - val_loss: 0.4875 - val_accuracy: 0.7727\n",
      "Epoch 223/600\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.4748 - accuracy: 0.8029 - val_loss: 0.4814 - val_accuracy: 0.7792\n",
      "Epoch 224/600\n",
      "20/20 [==============================] - 1s 49ms/step - loss: 0.4532 - accuracy: 0.8029 - val_loss: 0.4777 - val_accuracy: 0.7662\n",
      "Epoch 225/600\n",
      "20/20 [==============================] - 1s 43ms/step - loss: 0.4617 - accuracy: 0.7948 - val_loss: 0.4804 - val_accuracy: 0.7597\n",
      "Epoch 226/600\n",
      "20/20 [==============================] - 1s 46ms/step - loss: 0.4789 - accuracy: 0.7801 - val_loss: 0.4827 - val_accuracy: 0.7662\n",
      "Epoch 227/600\n",
      "20/20 [==============================] - 1s 52ms/step - loss: 0.4702 - accuracy: 0.7883 - val_loss: 0.4816 - val_accuracy: 0.7532\n",
      "Epoch 228/600\n",
      "20/20 [==============================] - 1s 50ms/step - loss: 0.4756 - accuracy: 0.7850 - val_loss: 0.4866 - val_accuracy: 0.7662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/600\n",
      "20/20 [==============================] - 1s 47ms/step - loss: 0.4674 - accuracy: 0.7818 - val_loss: 0.4879 - val_accuracy: 0.7532\n",
      "Epoch 230/600\n",
      "20/20 [==============================] - 1s 47ms/step - loss: 0.4710 - accuracy: 0.7883 - val_loss: 0.4846 - val_accuracy: 0.7468\n",
      "Epoch 231/600\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.4711 - accuracy: 0.7818 - val_loss: 0.4850 - val_accuracy: 0.7468\n",
      "Epoch 232/600\n",
      "20/20 [==============================] - 1s 42ms/step - loss: 0.4726 - accuracy: 0.7948 - val_loss: 0.4845 - val_accuracy: 0.7597\n",
      "Epoch 233/600\n",
      "20/20 [==============================] - 1s 46ms/step - loss: 0.4687 - accuracy: 0.7997 - val_loss: 0.4900 - val_accuracy: 0.7597\n",
      "Epoch 234/600\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.4707 - accuracy: 0.7850 - val_loss: 0.4822 - val_accuracy: 0.7532\n",
      "Epoch 235/600\n",
      "20/20 [==============================] - 1s 61ms/step - loss: 0.4784 - accuracy: 0.7883 - val_loss: 0.4818 - val_accuracy: 0.7532\n",
      "Epoch 236/600\n",
      "20/20 [==============================] - 1s 47ms/step - loss: 0.4657 - accuracy: 0.7915 - val_loss: 0.4867 - val_accuracy: 0.7468\n",
      "Epoch 237/600\n",
      "20/20 [==============================] - 2s 77ms/step - loss: 0.4580 - accuracy: 0.7964 - val_loss: 0.4823 - val_accuracy: 0.7403\n",
      "Epoch 238/600\n",
      "20/20 [==============================] - 1s 65ms/step - loss: 0.4702 - accuracy: 0.7899 - val_loss: 0.4932 - val_accuracy: 0.7532\n",
      "Epoch 239/600\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.4627 - accuracy: 0.7866 - val_loss: 0.4881 - val_accuracy: 0.7532\n",
      "Epoch 240/600\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.4480 - accuracy: 0.7997 - val_loss: 0.4869 - val_accuracy: 0.7597\n",
      "Epoch 241/600\n",
      "20/20 [==============================] - 1s 48ms/step - loss: 0.4747 - accuracy: 0.7818 - val_loss: 0.4808 - val_accuracy: 0.7532\n",
      "Epoch 242/600\n",
      "20/20 [==============================] - 1s 43ms/step - loss: 0.4700 - accuracy: 0.7964 - val_loss: 0.4801 - val_accuracy: 0.7597\n",
      "Epoch 243/600\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 0.4650 - accuracy: 0.8046 - val_loss: 0.4789 - val_accuracy: 0.7597\n",
      "Epoch 244/600\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.4659 - accuracy: 0.8062 - val_loss: 0.4798 - val_accuracy: 0.7597\n",
      "Epoch 245/600\n",
      "20/20 [==============================] - 1s 47ms/step - loss: 0.4681 - accuracy: 0.7964 - val_loss: 0.4827 - val_accuracy: 0.7597\n",
      "Epoch 246/600\n",
      "20/20 [==============================] - 1s 45ms/step - loss: 0.4569 - accuracy: 0.8143 - val_loss: 0.4819 - val_accuracy: 0.7532\n",
      "Epoch 247/600\n",
      "20/20 [==============================] - 1s 52ms/step - loss: 0.4611 - accuracy: 0.7948 - val_loss: 0.4760 - val_accuracy: 0.7532\n",
      "Epoch 248/600\n",
      "20/20 [==============================] - 1s 49ms/step - loss: 0.4593 - accuracy: 0.8062 - val_loss: 0.4784 - val_accuracy: 0.7597\n",
      "Epoch 249/600\n",
      "20/20 [==============================] - 1s 48ms/step - loss: 0.4776 - accuracy: 0.7997 - val_loss: 0.4818 - val_accuracy: 0.7468\n",
      "Epoch 250/600\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.4759 - accuracy: 0.7818 - val_loss: 0.4818 - val_accuracy: 0.7597\n",
      "Epoch 251/600\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 0.4624 - accuracy: 0.8013 - val_loss: 0.4815 - val_accuracy: 0.7597\n",
      "Epoch 252/600\n",
      "20/20 [==============================] - 1s 46ms/step - loss: 0.4681 - accuracy: 0.7899 - val_loss: 0.4864 - val_accuracy: 0.7468\n",
      "Epoch 253/600\n",
      "20/20 [==============================] - 1s 48ms/step - loss: 0.4622 - accuracy: 0.7883 - val_loss: 0.4852 - val_accuracy: 0.7532\n",
      "Epoch 254/600\n",
      "20/20 [==============================] - 1s 54ms/step - loss: 0.4638 - accuracy: 0.7883 - val_loss: 0.4798 - val_accuracy: 0.7468\n",
      "Epoch 255/600\n",
      "20/20 [==============================] - 1s 42ms/step - loss: 0.4445 - accuracy: 0.8013 - val_loss: 0.4788 - val_accuracy: 0.7597\n",
      "Epoch 256/600\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.4817 - accuracy: 0.7801 - val_loss: 0.4818 - val_accuracy: 0.7532\n",
      "Epoch 257/600\n",
      "20/20 [==============================] - 1s 43ms/step - loss: 0.4510 - accuracy: 0.8094 - val_loss: 0.4813 - val_accuracy: 0.7597\n",
      "Epoch 258/600\n",
      "20/20 [==============================] - 1s 42ms/step - loss: 0.4625 - accuracy: 0.7915 - val_loss: 0.4847 - val_accuracy: 0.7532\n",
      "Epoch 259/600\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.4666 - accuracy: 0.7818 - val_loss: 0.4837 - val_accuracy: 0.7403\n",
      "Epoch 260/600\n",
      "20/20 [==============================] - 1s 53ms/step - loss: 0.4574 - accuracy: 0.7964 - val_loss: 0.4912 - val_accuracy: 0.7468\n",
      "Epoch 261/600\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.4522 - accuracy: 0.8192 - val_loss: 0.4814 - val_accuracy: 0.7532\n",
      "Epoch 262/600\n",
      "20/20 [==============================] - 1s 46ms/step - loss: 0.4623 - accuracy: 0.8062 - val_loss: 0.4802 - val_accuracy: 0.7468\n",
      "Epoch 263/600\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.4584 - accuracy: 0.7948 - val_loss: 0.4795 - val_accuracy: 0.7532\n",
      "Epoch 264/600\n",
      "20/20 [==============================] - 1s 47ms/step - loss: 0.4587 - accuracy: 0.7948 - val_loss: 0.4808 - val_accuracy: 0.7468\n",
      "Epoch 265/600\n",
      "20/20 [==============================] - 1s 50ms/step - loss: 0.4838 - accuracy: 0.7948 - val_loss: 0.4818 - val_accuracy: 0.7403\n",
      "Epoch 266/600\n",
      "20/20 [==============================] - 1s 42ms/step - loss: 0.4687 - accuracy: 0.7915 - val_loss: 0.4841 - val_accuracy: 0.7468\n",
      "Epoch 267/600\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.4604 - accuracy: 0.7915 - val_loss: 0.4790 - val_accuracy: 0.7532\n",
      "Epoch 268/600\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.4626 - accuracy: 0.8013 - val_loss: 0.4801 - val_accuracy: 0.7468\n",
      "Epoch 269/600\n",
      "20/20 [==============================] - 1s 44ms/step - loss: 0.4638 - accuracy: 0.7915 - val_loss: 0.4767 - val_accuracy: 0.7532\n",
      "Epoch 270/600\n",
      "20/20 [==============================] - 1s 44ms/step - loss: 0.4656 - accuracy: 0.7769 - val_loss: 0.4769 - val_accuracy: 0.7532\n",
      "Epoch 271/600\n",
      "20/20 [==============================] - 1s 43ms/step - loss: 0.4594 - accuracy: 0.7899 - val_loss: 0.4872 - val_accuracy: 0.7532\n",
      "Epoch 272/600\n",
      "20/20 [==============================] - 1s 53ms/step - loss: 0.4615 - accuracy: 0.7915 - val_loss: 0.4805 - val_accuracy: 0.7532\n",
      "Epoch 273/600\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.4551 - accuracy: 0.7915 - val_loss: 0.4794 - val_accuracy: 0.7468\n",
      "Epoch 274/600\n",
      "20/20 [==============================] - 1s 47ms/step - loss: 0.4555 - accuracy: 0.8176 - val_loss: 0.4813 - val_accuracy: 0.7273\n",
      "Epoch 275/600\n",
      "20/20 [==============================] - 1s 46ms/step - loss: 0.4434 - accuracy: 0.8241 - val_loss: 0.4815 - val_accuracy: 0.7468\n",
      "Epoch 276/600\n",
      "20/20 [==============================] - 1s 48ms/step - loss: 0.4432 - accuracy: 0.8127 - val_loss: 0.4806 - val_accuracy: 0.7532\n",
      "Epoch 277/600\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.4596 - accuracy: 0.7964 - val_loss: 0.4860 - val_accuracy: 0.7403\n",
      "Epoch 278/600\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.4414 - accuracy: 0.8111 - val_loss: 0.4805 - val_accuracy: 0.7532\n",
      "Epoch 279/600\n",
      "20/20 [==============================] - 1s 44ms/step - loss: 0.4520 - accuracy: 0.7883 - val_loss: 0.4785 - val_accuracy: 0.7597\n",
      "Epoch 280/600\n",
      "20/20 [==============================] - 1s 45ms/step - loss: 0.4389 - accuracy: 0.8127 - val_loss: 0.4805 - val_accuracy: 0.7468\n",
      "Epoch 281/600\n",
      "20/20 [==============================] - 1s 51ms/step - loss: 0.4510 - accuracy: 0.7964 - val_loss: 0.4818 - val_accuracy: 0.7338\n",
      "Epoch 282/600\n",
      "20/20 [==============================] - 1s 59ms/step - loss: 0.4529 - accuracy: 0.7997 - val_loss: 0.4811 - val_accuracy: 0.7532\n",
      "Epoch 283/600\n",
      "20/20 [==============================] - 1s 43ms/step - loss: 0.4483 - accuracy: 0.8062 - val_loss: 0.4826 - val_accuracy: 0.7468\n",
      "Epoch 284/600\n",
      "20/20 [==============================] - 1s 52ms/step - loss: 0.4483 - accuracy: 0.7964 - val_loss: 0.4818 - val_accuracy: 0.7403\n",
      "Epoch 285/600\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.4590 - accuracy: 0.7899 - val_loss: 0.4821 - val_accuracy: 0.7532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/600\n",
      "20/20 [==============================] - 1s 44ms/step - loss: 0.4538 - accuracy: 0.7948 - val_loss: 0.4865 - val_accuracy: 0.7468\n",
      "Epoch 287/600\n",
      "20/20 [==============================] - 1s 48ms/step - loss: 0.4573 - accuracy: 0.8094 - val_loss: 0.4835 - val_accuracy: 0.7468\n",
      "Epoch 288/600\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 0.4690 - accuracy: 0.7932 - val_loss: 0.4810 - val_accuracy: 0.7468\n",
      "Epoch 289/600\n",
      "20/20 [==============================] - 1s 42ms/step - loss: 0.4498 - accuracy: 0.8160 - val_loss: 0.4843 - val_accuracy: 0.7468\n",
      "Epoch 290/600\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.4608 - accuracy: 0.8046 - val_loss: 0.4822 - val_accuracy: 0.7468\n",
      "Epoch 291/600\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.4449 - accuracy: 0.8160 - val_loss: 0.4779 - val_accuracy: 0.7532\n",
      "Epoch 292/600\n",
      "20/20 [==============================] - 1s 47ms/step - loss: 0.4475 - accuracy: 0.7980 - val_loss: 0.4815 - val_accuracy: 0.7403\n",
      "Epoch 293/600\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.4743 - accuracy: 0.7932 - val_loss: 0.4822 - val_accuracy: 0.7403\n",
      "Epoch 294/600\n",
      "20/20 [==============================] - 1s 44ms/step - loss: 0.4572 - accuracy: 0.7866 - val_loss: 0.4793 - val_accuracy: 0.7468\n",
      "Epoch 295/600\n",
      "20/20 [==============================] - 1s 43ms/step - loss: 0.4494 - accuracy: 0.8094 - val_loss: 0.4817 - val_accuracy: 0.7403\n",
      "Epoch 296/600\n",
      "20/20 [==============================] - 1s 53ms/step - loss: 0.4549 - accuracy: 0.7915 - val_loss: 0.4781 - val_accuracy: 0.7403\n",
      "Epoch 297/600\n",
      "20/20 [==============================] - 1s 42ms/step - loss: 0.4432 - accuracy: 0.7980 - val_loss: 0.4840 - val_accuracy: 0.7532\n",
      "Epoch 298/600\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.4591 - accuracy: 0.7932 - val_loss: 0.4838 - val_accuracy: 0.7468\n",
      "Epoch 299/600\n",
      "20/20 [==============================] - 1s 57ms/step - loss: 0.4434 - accuracy: 0.7980 - val_loss: 0.4768 - val_accuracy: 0.7468\n",
      "Epoch 300/600\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.4611 - accuracy: 0.7932 - val_loss: 0.4866 - val_accuracy: 0.7532\n",
      "Epoch 301/600\n",
      "20/20 [==============================] - 1s 44ms/step - loss: 0.4515 - accuracy: 0.8160 - val_loss: 0.4813 - val_accuracy: 0.7403\n",
      "Epoch 302/600\n",
      "20/20 [==============================] - 1s 52ms/step - loss: 0.4733 - accuracy: 0.7866 - val_loss: 0.4826 - val_accuracy: 0.7468\n",
      "Epoch 303/600\n",
      "20/20 [==============================] - 1s 44ms/step - loss: 0.4511 - accuracy: 0.7915 - val_loss: 0.4781 - val_accuracy: 0.7468\n",
      "Epoch 304/600\n",
      "20/20 [==============================] - 1s 45ms/step - loss: 0.4627 - accuracy: 0.7883 - val_loss: 0.4808 - val_accuracy: 0.7468\n",
      "Epoch 305/600\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.4504 - accuracy: 0.7948 - val_loss: 0.4831 - val_accuracy: 0.7468\n",
      "Epoch 306/600\n",
      "20/20 [==============================] - 1s 48ms/step - loss: 0.4680 - accuracy: 0.7850 - val_loss: 0.4835 - val_accuracy: 0.7532\n",
      "Epoch 307/600\n",
      "20/20 [==============================] - 1s 56ms/step - loss: 0.4475 - accuracy: 0.8029 - val_loss: 0.4821 - val_accuracy: 0.7403\n",
      "Epoch 308/600\n",
      "20/20 [==============================] - 1s 63ms/step - loss: 0.4558 - accuracy: 0.7997 - val_loss: 0.4789 - val_accuracy: 0.7662\n",
      "Epoch 309/600\n",
      "20/20 [==============================] - 2s 78ms/step - loss: 0.4595 - accuracy: 0.7899 - val_loss: 0.4758 - val_accuracy: 0.7468\n",
      "Epoch 310/600\n",
      "20/20 [==============================] - 1s 56ms/step - loss: 0.4504 - accuracy: 0.8029 - val_loss: 0.4759 - val_accuracy: 0.7468\n",
      "Epoch 311/600\n",
      "20/20 [==============================] - 1s 58ms/step - loss: 0.4575 - accuracy: 0.8078 - val_loss: 0.4795 - val_accuracy: 0.7468\n",
      "Epoch 312/600\n",
      "20/20 [==============================] - 2s 91ms/step - loss: 0.4544 - accuracy: 0.8013 - val_loss: 0.4722 - val_accuracy: 0.7532\n",
      "Epoch 313/600\n",
      "20/20 [==============================] - 2s 90ms/step - loss: 0.4574 - accuracy: 0.7948 - val_loss: 0.4802 - val_accuracy: 0.7468\n",
      "Epoch 314/600\n",
      "20/20 [==============================] - 1s 67ms/step - loss: 0.4631 - accuracy: 0.7997 - val_loss: 0.4800 - val_accuracy: 0.7403\n",
      "Epoch 315/600\n",
      "20/20 [==============================] - 1s 52ms/step - loss: 0.4459 - accuracy: 0.8176 - val_loss: 0.4807 - val_accuracy: 0.7468\n",
      "Epoch 316/600\n",
      "20/20 [==============================] - 1s 56ms/step - loss: 0.4450 - accuracy: 0.8208 - val_loss: 0.4869 - val_accuracy: 0.7468\n",
      "Epoch 317/600\n",
      "20/20 [==============================] - 1s 44ms/step - loss: 0.4361 - accuracy: 0.8160 - val_loss: 0.4821 - val_accuracy: 0.7338\n",
      "Epoch 318/600\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.4429 - accuracy: 0.8094 - val_loss: 0.4851 - val_accuracy: 0.7468\n",
      "Epoch 319/600\n",
      "20/20 [==============================] - 1s 53ms/step - loss: 0.4729 - accuracy: 0.7899 - val_loss: 0.4822 - val_accuracy: 0.7468\n",
      "Epoch 320/600\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.4325 - accuracy: 0.8274 - val_loss: 0.4782 - val_accuracy: 0.7468\n",
      "Epoch 321/600\n",
      "20/20 [==============================] - 1s 60ms/step - loss: 0.4356 - accuracy: 0.7932 - val_loss: 0.4767 - val_accuracy: 0.7597\n",
      "Epoch 322/600\n",
      "20/20 [==============================] - 1s 62ms/step - loss: 0.4468 - accuracy: 0.8094 - val_loss: 0.4824 - val_accuracy: 0.7403\n",
      "Epoch 323/600\n",
      "20/20 [==============================] - 1s 71ms/step - loss: 0.4507 - accuracy: 0.7932 - val_loss: 0.4852 - val_accuracy: 0.7468\n",
      "Epoch 324/600\n",
      "20/20 [==============================] - 1s 61ms/step - loss: 0.4404 - accuracy: 0.8208 - val_loss: 0.4819 - val_accuracy: 0.7468\n",
      "Epoch 325/600\n",
      "20/20 [==============================] - 1s 62ms/step - loss: 0.4410 - accuracy: 0.8176 - val_loss: 0.4812 - val_accuracy: 0.7468\n",
      "Epoch 326/600\n",
      "20/20 [==============================] - 1s 50ms/step - loss: 0.4630 - accuracy: 0.8013 - val_loss: 0.4827 - val_accuracy: 0.7403\n",
      "Epoch 327/600\n",
      "20/20 [==============================] - 1s 46ms/step - loss: 0.4415 - accuracy: 0.8062 - val_loss: 0.4860 - val_accuracy: 0.7468\n",
      "Epoch 328/600\n",
      "20/20 [==============================] - 1s 55ms/step - loss: 0.4358 - accuracy: 0.8143 - val_loss: 0.4819 - val_accuracy: 0.7403\n",
      "Epoch 329/600\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 0.4471 - accuracy: 0.8111 - val_loss: 0.4750 - val_accuracy: 0.7532\n",
      "Epoch 330/600\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.4499 - accuracy: 0.8094 - val_loss: 0.4803 - val_accuracy: 0.7532\n",
      "Epoch 331/600\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.4438 - accuracy: 0.8192 - val_loss: 0.4814 - val_accuracy: 0.7403\n",
      "Epoch 332/600\n",
      "20/20 [==============================] - 1s 74ms/step - loss: 0.4380 - accuracy: 0.8127 - val_loss: 0.4830 - val_accuracy: 0.7338\n",
      "Epoch 333/600\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.4360 - accuracy: 0.8176 - val_loss: 0.4866 - val_accuracy: 0.7338\n",
      "Epoch 334/600\n",
      "20/20 [==============================] - 1s 48ms/step - loss: 0.4506 - accuracy: 0.8062 - val_loss: 0.4867 - val_accuracy: 0.7403\n",
      "Epoch 335/600\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.4494 - accuracy: 0.8078 - val_loss: 0.4853 - val_accuracy: 0.7468\n",
      "Epoch 336/600\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.4489 - accuracy: 0.7980 - val_loss: 0.4900 - val_accuracy: 0.7338\n",
      "Epoch 337/600\n",
      "20/20 [==============================] - 1s 48ms/step - loss: 0.4545 - accuracy: 0.8046 - val_loss: 0.4889 - val_accuracy: 0.7403\n",
      "Epoch 338/600\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.4494 - accuracy: 0.8046 - val_loss: 0.4815 - val_accuracy: 0.7468\n",
      "Epoch 339/600\n",
      "20/20 [==============================] - 1s 44ms/step - loss: 0.4377 - accuracy: 0.8078 - val_loss: 0.4803 - val_accuracy: 0.7597\n",
      "Epoch 340/600\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.4417 - accuracy: 0.8160 - val_loss: 0.4844 - val_accuracy: 0.7338\n",
      "Epoch 341/600\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.4406 - accuracy: 0.8241 - val_loss: 0.4834 - val_accuracy: 0.7403\n",
      "Epoch 342/600\n",
      "20/20 [==============================] - 1s 71ms/step - loss: 0.4332 - accuracy: 0.8274 - val_loss: 0.4873 - val_accuracy: 0.7468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/600\n",
      "20/20 [==============================] - 2s 83ms/step - loss: 0.4407 - accuracy: 0.8111 - val_loss: 0.4907 - val_accuracy: 0.7468\n",
      "Epoch 344/600\n",
      "20/20 [==============================] - 1s 51ms/step - loss: 0.4484 - accuracy: 0.7997 - val_loss: 0.4905 - val_accuracy: 0.7403\n",
      "Epoch 345/600\n",
      "20/20 [==============================] - 1s 54ms/step - loss: 0.4314 - accuracy: 0.8127 - val_loss: 0.4821 - val_accuracy: 0.7468\n",
      "Epoch 346/600\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 0.4391 - accuracy: 0.8127 - val_loss: 0.4805 - val_accuracy: 0.7532\n",
      "Epoch 347/600\n",
      "20/20 [==============================] - 1s 48ms/step - loss: 0.4350 - accuracy: 0.8094 - val_loss: 0.4767 - val_accuracy: 0.7597\n",
      "Epoch 348/600\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.4509 - accuracy: 0.8029 - val_loss: 0.4842 - val_accuracy: 0.7468\n",
      "Epoch 349/600\n",
      "20/20 [==============================] - 1s 52ms/step - loss: 0.4264 - accuracy: 0.8192 - val_loss: 0.4920 - val_accuracy: 0.7468\n",
      "Epoch 350/600\n",
      "20/20 [==============================] - 1s 49ms/step - loss: 0.4552 - accuracy: 0.8094 - val_loss: 0.4977 - val_accuracy: 0.7338\n",
      "Epoch 351/600\n",
      "20/20 [==============================] - 1s 50ms/step - loss: 0.4399 - accuracy: 0.8176 - val_loss: 0.4897 - val_accuracy: 0.7468\n",
      "Epoch 352/600\n",
      "20/20 [==============================] - 2s 92ms/step - loss: 0.4439 - accuracy: 0.8062 - val_loss: 0.4825 - val_accuracy: 0.7403\n",
      "Epoch 353/600\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 0.4318 - accuracy: 0.8029 - val_loss: 0.4830 - val_accuracy: 0.7403\n",
      "Epoch 354/600\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.4429 - accuracy: 0.8062 - val_loss: 0.4866 - val_accuracy: 0.7403\n",
      "Epoch 355/600\n",
      "20/20 [==============================] - 1s 43ms/step - loss: 0.4375 - accuracy: 0.8143 - val_loss: 0.4828 - val_accuracy: 0.7468\n",
      "Epoch 356/600\n",
      "20/20 [==============================] - 1s 50ms/step - loss: 0.4419 - accuracy: 0.8062 - val_loss: 0.4889 - val_accuracy: 0.7468\n",
      "Epoch 357/600\n",
      "20/20 [==============================] - 1s 44ms/step - loss: 0.4374 - accuracy: 0.8111 - val_loss: 0.4869 - val_accuracy: 0.7468\n",
      "Epoch 358/600\n",
      "20/20 [==============================] - 1s 50ms/step - loss: 0.4403 - accuracy: 0.8111 - val_loss: 0.4854 - val_accuracy: 0.7532\n",
      "Epoch 359/600\n",
      "20/20 [==============================] - 1s 51ms/step - loss: 0.4415 - accuracy: 0.8094 - val_loss: 0.4869 - val_accuracy: 0.7597\n",
      "Epoch 360/600\n",
      "20/20 [==============================] - 1s 44ms/step - loss: 0.4477 - accuracy: 0.8111 - val_loss: 0.4843 - val_accuracy: 0.7532\n",
      "Epoch 361/600\n",
      "20/20 [==============================] - 1s 47ms/step - loss: 0.4541 - accuracy: 0.8078 - val_loss: 0.4829 - val_accuracy: 0.7532\n",
      "Epoch 362/600\n",
      "20/20 [==============================] - 1s 52ms/step - loss: 0.4244 - accuracy: 0.8225 - val_loss: 0.4812 - val_accuracy: 0.7468\n",
      "Epoch 363/600\n",
      "20/20 [==============================] - 1s 46ms/step - loss: 0.4331 - accuracy: 0.8143 - val_loss: 0.4809 - val_accuracy: 0.7468\n",
      "Epoch 364/600\n",
      "20/20 [==============================] - 1s 52ms/step - loss: 0.4384 - accuracy: 0.8274 - val_loss: 0.4741 - val_accuracy: 0.7662\n",
      "Epoch 365/600\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.4492 - accuracy: 0.8046 - val_loss: 0.4879 - val_accuracy: 0.7532\n",
      "Epoch 366/600\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.4483 - accuracy: 0.8143 - val_loss: 0.4833 - val_accuracy: 0.7403\n",
      "Epoch 367/600\n",
      "20/20 [==============================] - 1s 52ms/step - loss: 0.4250 - accuracy: 0.8225 - val_loss: 0.4865 - val_accuracy: 0.7468\n",
      "Epoch 368/600\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.4412 - accuracy: 0.8111 - val_loss: 0.4857 - val_accuracy: 0.7468\n",
      "Epoch 369/600\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.4338 - accuracy: 0.8111 - val_loss: 0.4874 - val_accuracy: 0.7468\n",
      "Epoch 370/600\n",
      "20/20 [==============================] - 1s 57ms/step - loss: 0.4570 - accuracy: 0.7948 - val_loss: 0.4890 - val_accuracy: 0.7532\n",
      "Epoch 371/600\n",
      "20/20 [==============================] - 1s 54ms/step - loss: 0.4465 - accuracy: 0.8225 - val_loss: 0.4880 - val_accuracy: 0.7468\n",
      "Epoch 372/600\n",
      "20/20 [==============================] - 1s 53ms/step - loss: 0.4460 - accuracy: 0.8094 - val_loss: 0.4786 - val_accuracy: 0.7532\n",
      "Epoch 373/600\n",
      "20/20 [==============================] - 1s 26ms/step - loss: 0.4398 - accuracy: 0.8078 - val_loss: 0.4804 - val_accuracy: 0.7468\n",
      "Epoch 374/600\n",
      "20/20 [==============================] - 1s 71ms/step - loss: 0.4590 - accuracy: 0.8127 - val_loss: 0.4869 - val_accuracy: 0.7338\n",
      "Epoch 375/600\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 0.4446 - accuracy: 0.8062 - val_loss: 0.4841 - val_accuracy: 0.7468\n",
      "Epoch 376/600\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.4700 - accuracy: 0.7818 - val_loss: 0.4854 - val_accuracy: 0.7468\n",
      "Epoch 377/600\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.4288 - accuracy: 0.8160 - val_loss: 0.4827 - val_accuracy: 0.7532\n",
      "Epoch 378/600\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 0.4258 - accuracy: 0.8306 - val_loss: 0.4885 - val_accuracy: 0.7403\n",
      "Epoch 379/600\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.4260 - accuracy: 0.81 - 1s 28ms/step - loss: 0.4260 - accuracy: 0.8192 - val_loss: 0.4905 - val_accuracy: 0.7338\n",
      "Epoch 380/600\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.4507 - accuracy: 0.8127 - val_loss: 0.4872 - val_accuracy: 0.7403\n",
      "Epoch 381/600\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.4386 - accuracy: 0.8094 - val_loss: 0.4802 - val_accuracy: 0.7532\n",
      "Epoch 382/600\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 0.4271 - accuracy: 0.8192 - val_loss: 0.4840 - val_accuracy: 0.7403\n",
      "Epoch 383/600\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 0.4500 - accuracy: 0.7932 - val_loss: 0.4833 - val_accuracy: 0.7338\n",
      "Epoch 384/600\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.4419 - accuracy: 0.8111 - val_loss: 0.4843 - val_accuracy: 0.7468\n",
      "Epoch 385/600\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.4373 - accuracy: 0.8274 - val_loss: 0.4925 - val_accuracy: 0.7273\n",
      "Epoch 386/600\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.4318 - accuracy: 0.8013 - val_loss: 0.4856 - val_accuracy: 0.7403\n",
      "Epoch 387/600\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.4427 - accuracy: 0.7915 - val_loss: 0.4842 - val_accuracy: 0.7468\n",
      "Epoch 388/600\n",
      "20/20 [==============================] - 1s 27ms/step - loss: 0.4421 - accuracy: 0.7948 - val_loss: 0.4874 - val_accuracy: 0.7532\n",
      "Epoch 389/600\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 0.4457 - accuracy: 0.8078 - val_loss: 0.4870 - val_accuracy: 0.7468\n",
      "Epoch 390/600\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.4325 - accuracy: 0.8176 - val_loss: 0.4824 - val_accuracy: 0.7468\n",
      "Epoch 391/600\n",
      "20/20 [==============================] - 1s 26ms/step - loss: 0.4575 - accuracy: 0.7964 - val_loss: 0.4797 - val_accuracy: 0.7532\n",
      "Epoch 392/600\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.4459 - accuracy: 0.8176 - val_loss: 0.4835 - val_accuracy: 0.7468\n",
      "Epoch 393/600\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.4276 - accuracy: 0.8143 - val_loss: 0.4840 - val_accuracy: 0.7403\n",
      "Epoch 394/600\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 0.4403 - accuracy: 0.8094 - val_loss: 0.4843 - val_accuracy: 0.7338\n",
      "Epoch 395/600\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.4397 - accuracy: 0.8160 - val_loss: 0.4814 - val_accuracy: 0.7468\n",
      "Epoch 396/600\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.4459 - accuracy: 0.8062 - val_loss: 0.4805 - val_accuracy: 0.7403\n",
      "Epoch 397/600\n",
      "20/20 [==============================] - 1s 43ms/step - loss: 0.4450 - accuracy: 0.8013 - val_loss: 0.4786 - val_accuracy: 0.7532\n",
      "Epoch 398/600\n",
      "20/20 [==============================] - 1s 27ms/step - loss: 0.4364 - accuracy: 0.8257 - val_loss: 0.4862 - val_accuracy: 0.7532\n",
      "Epoch 399/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 1s 34ms/step - loss: 0.4327 - accuracy: 0.8094 - val_loss: 0.4787 - val_accuracy: 0.7468\n",
      "Epoch 400/600\n",
      "20/20 [==============================] - 0s 21ms/step - loss: 0.4342 - accuracy: 0.8111 - val_loss: 0.4888 - val_accuracy: 0.7468\n",
      "Epoch 401/600\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.4384 - accuracy: 0.7932 - val_loss: 0.4846 - val_accuracy: 0.7468\n",
      "Epoch 402/600\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 0.4459 - accuracy: 0.8192 - val_loss: 0.4859 - val_accuracy: 0.7338\n",
      "Epoch 403/600\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.4336 - accuracy: 0.8062 - val_loss: 0.4866 - val_accuracy: 0.7338\n",
      "Epoch 404/600\n",
      "20/20 [==============================] - 0s 24ms/step - loss: 0.4360 - accuracy: 0.8094 - val_loss: 0.4915 - val_accuracy: 0.7403\n",
      "Epoch 405/600\n",
      "20/20 [==============================] - 0s 21ms/step - loss: 0.4512 - accuracy: 0.8111 - val_loss: 0.4837 - val_accuracy: 0.7338\n",
      "Epoch 406/600\n",
      "20/20 [==============================] - 0s 23ms/step - loss: 0.4470 - accuracy: 0.8078 - val_loss: 0.4827 - val_accuracy: 0.7468\n",
      "Epoch 407/600\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 0.4330 - accuracy: 0.8208 - val_loss: 0.4880 - val_accuracy: 0.7338\n",
      "Epoch 408/600\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.4456 - accuracy: 0.8013 - val_loss: 0.4836 - val_accuracy: 0.7468\n",
      "Epoch 409/600\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.4463 - accuracy: 0.8127 - val_loss: 0.4863 - val_accuracy: 0.7338\n",
      "Epoch 410/600\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 0.4430 - accuracy: 0.8029 - val_loss: 0.4843 - val_accuracy: 0.7338\n",
      "Epoch 411/600\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.4341 - accuracy: 0.8208 - val_loss: 0.4816 - val_accuracy: 0.7468\n",
      "Epoch 412/600\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.4219 - accuracy: 0.8192 - val_loss: 0.4869 - val_accuracy: 0.7403\n",
      "Epoch 413/600\n",
      "20/20 [==============================] - 0s 23ms/step - loss: 0.4274 - accuracy: 0.8160 - val_loss: 0.4890 - val_accuracy: 0.7403\n",
      "Epoch 414/600\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.4402 - accuracy: 0.8176 - val_loss: 0.4822 - val_accuracy: 0.7532\n",
      "Epoch 415/600\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.4392 - accuracy: 0.8046 - val_loss: 0.4775 - val_accuracy: 0.7532\n",
      "Epoch 416/600\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.4356 - accuracy: 0.8078 - val_loss: 0.4805 - val_accuracy: 0.7468\n",
      "Epoch 417/600\n",
      "20/20 [==============================] - 0s 25ms/step - loss: 0.4306 - accuracy: 0.8127 - val_loss: 0.4805 - val_accuracy: 0.7468\n",
      "Epoch 418/600\n",
      "20/20 [==============================] - 0s 25ms/step - loss: 0.4400 - accuracy: 0.8078 - val_loss: 0.4838 - val_accuracy: 0.7597\n",
      "Epoch 419/600\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.4341 - accuracy: 0.8127 - val_loss: 0.4875 - val_accuracy: 0.7532\n",
      "Epoch 420/600\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.4382 - accuracy: 0.8143 - val_loss: 0.4808 - val_accuracy: 0.7662\n",
      "Epoch 421/600\n",
      "20/20 [==============================] - 0s 23ms/step - loss: 0.4438 - accuracy: 0.8046 - val_loss: 0.4889 - val_accuracy: 0.7403\n",
      "Epoch 422/600\n",
      "20/20 [==============================] - 0s 25ms/step - loss: 0.4280 - accuracy: 0.8160 - val_loss: 0.4800 - val_accuracy: 0.7532\n",
      "Epoch 423/600\n",
      "20/20 [==============================] - 1s 27ms/step - loss: 0.4306 - accuracy: 0.8029 - val_loss: 0.4805 - val_accuracy: 0.7532\n",
      "Epoch 424/600\n",
      "20/20 [==============================] - 0s 23ms/step - loss: 0.4192 - accuracy: 0.8160 - val_loss: 0.4830 - val_accuracy: 0.7468\n",
      "Epoch 425/600\n",
      "20/20 [==============================] - 0s 23ms/step - loss: 0.4516 - accuracy: 0.8046 - val_loss: 0.4864 - val_accuracy: 0.7662\n",
      "Epoch 426/600\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.4375 - accuracy: 0.8111 - val_loss: 0.4865 - val_accuracy: 0.7597\n",
      "Epoch 427/600\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.4121 - accuracy: 0.8355 - val_loss: 0.4844 - val_accuracy: 0.7532\n",
      "Epoch 428/600\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.4315 - accuracy: 0.8225 - val_loss: 0.4851 - val_accuracy: 0.7468\n",
      "Epoch 429/600\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.4363 - accuracy: 0.8013 - val_loss: 0.4869 - val_accuracy: 0.7532\n",
      "Epoch 430/600\n",
      "20/20 [==============================] - 1s 56ms/step - loss: 0.4254 - accuracy: 0.8160 - val_loss: 0.4842 - val_accuracy: 0.7468\n",
      "Epoch 431/600\n",
      "20/20 [==============================] - 1s 54ms/step - loss: 0.4340 - accuracy: 0.8111 - val_loss: 0.4843 - val_accuracy: 0.7468\n",
      "Epoch 432/600\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.4438 - accuracy: 0.8029 - val_loss: 0.4865 - val_accuracy: 0.7468\n",
      "Epoch 433/600\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.4390 - accuracy: 0.8127 - val_loss: 0.4814 - val_accuracy: 0.7532\n",
      "Epoch 434/600\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.4200 - accuracy: 0.8241 - val_loss: 0.4856 - val_accuracy: 0.7468\n",
      "Epoch 435/600\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.4289 - accuracy: 0.8192 - val_loss: 0.4926 - val_accuracy: 0.7273\n",
      "Epoch 436/600\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 0.4396 - accuracy: 0.8046 - val_loss: 0.4910 - val_accuracy: 0.7338\n",
      "Epoch 437/600\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.4444 - accuracy: 0.8111 - val_loss: 0.4922 - val_accuracy: 0.7338\n",
      "Epoch 438/600\n",
      "20/20 [==============================] - 1s 45ms/step - loss: 0.4489 - accuracy: 0.8062 - val_loss: 0.4846 - val_accuracy: 0.7532\n",
      "Epoch 439/600\n",
      "20/20 [==============================] - 1s 42ms/step - loss: 0.4293 - accuracy: 0.8176 - val_loss: 0.4815 - val_accuracy: 0.7597\n",
      "Epoch 440/600\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.4402 - accuracy: 0.8274 - val_loss: 0.4807 - val_accuracy: 0.7597\n",
      "Epoch 441/600\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.4435 - accuracy: 0.8127 - val_loss: 0.4826 - val_accuracy: 0.7532\n",
      "Epoch 442/600\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.4260 - accuracy: 0.8143 - val_loss: 0.4808 - val_accuracy: 0.7532\n",
      "Epoch 443/600\n",
      "20/20 [==============================] - 0s 24ms/step - loss: 0.4417 - accuracy: 0.8046 - val_loss: 0.4837 - val_accuracy: 0.7403\n",
      "Epoch 444/600\n",
      "20/20 [==============================] - 0s 25ms/step - loss: 0.4218 - accuracy: 0.8225 - val_loss: 0.4829 - val_accuracy: 0.7468\n",
      "Epoch 445/600\n",
      "20/20 [==============================] - 0s 21ms/step - loss: 0.4393 - accuracy: 0.8127 - val_loss: 0.4865 - val_accuracy: 0.7468\n",
      "Epoch 446/600\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.4275 - accuracy: 0.8176 - val_loss: 0.4862 - val_accuracy: 0.7468\n",
      "Epoch 447/600\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.4310 - accuracy: 0.8062 - val_loss: 0.4869 - val_accuracy: 0.7468\n",
      "Epoch 448/600\n",
      "20/20 [==============================] - 0s 25ms/step - loss: 0.4397 - accuracy: 0.8143 - val_loss: 0.4860 - val_accuracy: 0.7468\n",
      "Epoch 449/600\n",
      "20/20 [==============================] - 0s 22ms/step - loss: 0.4232 - accuracy: 0.8143 - val_loss: 0.4866 - val_accuracy: 0.7468\n",
      "Epoch 450/600\n",
      "20/20 [==============================] - 0s 21ms/step - loss: 0.4111 - accuracy: 0.8208 - val_loss: 0.4822 - val_accuracy: 0.7468\n",
      "Epoch 451/600\n",
      "20/20 [==============================] - 1s 26ms/step - loss: 0.4391 - accuracy: 0.8241 - val_loss: 0.4844 - val_accuracy: 0.7468\n",
      "Epoch 452/600\n",
      "20/20 [==============================] - 0s 23ms/step - loss: 0.4232 - accuracy: 0.8241 - val_loss: 0.4847 - val_accuracy: 0.7468\n",
      "Epoch 453/600\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.4336 - accuracy: 0.8078 - val_loss: 0.4847 - val_accuracy: 0.7468\n",
      "Epoch 454/600\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.4366 - accuracy: 0.8176 - val_loss: 0.4923 - val_accuracy: 0.7273\n",
      "Epoch 455/600\n",
      "20/20 [==============================] - 1s 27ms/step - loss: 0.4422 - accuracy: 0.8241 - val_loss: 0.4900 - val_accuracy: 0.7468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 456/600\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.4404 - accuracy: 0.8160 - val_loss: 0.4900 - val_accuracy: 0.7532\n",
      "Epoch 457/600\n",
      "20/20 [==============================] - 0s 22ms/step - loss: 0.4457 - accuracy: 0.8192 - val_loss: 0.4881 - val_accuracy: 0.7468\n",
      "Epoch 458/600\n",
      "20/20 [==============================] - 1s 27ms/step - loss: 0.4216 - accuracy: 0.8290 - val_loss: 0.4824 - val_accuracy: 0.7597\n",
      "Epoch 459/600\n",
      "20/20 [==============================] - 0s 23ms/step - loss: 0.4404 - accuracy: 0.8160 - val_loss: 0.4859 - val_accuracy: 0.7468\n",
      "Epoch 460/600\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.4346 - accuracy: 0.8078 - val_loss: 0.4863 - val_accuracy: 0.7468\n",
      "Epoch 461/600\n",
      "20/20 [==============================] - 1s 27ms/step - loss: 0.4212 - accuracy: 0.8241 - val_loss: 0.4868 - val_accuracy: 0.7532\n",
      "Epoch 462/600\n",
      "20/20 [==============================] - 1s 27ms/step - loss: 0.4172 - accuracy: 0.8225 - val_loss: 0.4833 - val_accuracy: 0.7403\n",
      "Epoch 463/600\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 0.4210 - accuracy: 0.8160 - val_loss: 0.4888 - val_accuracy: 0.7403\n",
      "Epoch 464/600\n",
      "20/20 [==============================] - 0s 24ms/step - loss: 0.4248 - accuracy: 0.8290 - val_loss: 0.4833 - val_accuracy: 0.7468\n",
      "Epoch 465/600\n",
      "20/20 [==============================] - 0s 20ms/step - loss: 0.4185 - accuracy: 0.8192 - val_loss: 0.4844 - val_accuracy: 0.7662\n",
      "Epoch 466/600\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.4503 - accuracy: 0.8290 - val_loss: 0.4905 - val_accuracy: 0.7338\n",
      "Epoch 467/600\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.4379 - accuracy: 0.8078 - val_loss: 0.4829 - val_accuracy: 0.7532\n",
      "Epoch 468/600\n",
      "20/20 [==============================] - 0s 23ms/step - loss: 0.4405 - accuracy: 0.8127 - val_loss: 0.4880 - val_accuracy: 0.7403\n",
      "Epoch 469/600\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.4192 - accuracy: 0.8274 - val_loss: 0.4846 - val_accuracy: 0.7532\n",
      "Epoch 470/600\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.4142 - accuracy: 0.8192 - val_loss: 0.4873 - val_accuracy: 0.7468\n",
      "Epoch 471/600\n",
      "20/20 [==============================] - 0s 24ms/step - loss: 0.4410 - accuracy: 0.8290 - val_loss: 0.4920 - val_accuracy: 0.7403\n",
      "Epoch 472/600\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 0.4563 - accuracy: 0.8094 - val_loss: 0.4948 - val_accuracy: 0.7338\n",
      "Epoch 473/600\n",
      "20/20 [==============================] - 0s 24ms/step - loss: 0.4297 - accuracy: 0.8143 - val_loss: 0.4919 - val_accuracy: 0.7468\n",
      "Epoch 474/600\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 0.4377 - accuracy: 0.8127 - val_loss: 0.4897 - val_accuracy: 0.7662\n",
      "Epoch 475/600\n",
      "20/20 [==============================] - 1s 26ms/step - loss: 0.4292 - accuracy: 0.8257 - val_loss: 0.4850 - val_accuracy: 0.7597\n",
      "Epoch 476/600\n",
      "20/20 [==============================] - 0s 23ms/step - loss: 0.4407 - accuracy: 0.8274 - val_loss: 0.4863 - val_accuracy: 0.7468\n",
      "Epoch 477/600\n",
      "20/20 [==============================] - 0s 21ms/step - loss: 0.4300 - accuracy: 0.8241 - val_loss: 0.4852 - val_accuracy: 0.7532\n",
      "Epoch 478/600\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.4342 - accuracy: 0.8143 - val_loss: 0.4850 - val_accuracy: 0.7468\n",
      "Epoch 479/600\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.4204 - accuracy: 0.8225 - val_loss: 0.4825 - val_accuracy: 0.7532\n",
      "Epoch 480/600\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.4400 - accuracy: 0.8078 - val_loss: 0.4823 - val_accuracy: 0.7597\n",
      "Epoch 481/600\n",
      "20/20 [==============================] - 1s 27ms/step - loss: 0.4082 - accuracy: 0.8274 - val_loss: 0.4884 - val_accuracy: 0.7468\n",
      "Epoch 482/600\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 0.4320 - accuracy: 0.8143 - val_loss: 0.4917 - val_accuracy: 0.7338\n",
      "Epoch 483/600\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.4372 - accuracy: 0.8143 - val_loss: 0.4881 - val_accuracy: 0.7468\n",
      "Epoch 484/600\n",
      "20/20 [==============================] - 0s 23ms/step - loss: 0.4324 - accuracy: 0.8225 - val_loss: 0.4877 - val_accuracy: 0.7532\n",
      "Epoch 485/600\n",
      "20/20 [==============================] - 1s 27ms/step - loss: 0.4382 - accuracy: 0.8046 - val_loss: 0.4871 - val_accuracy: 0.7792\n",
      "Epoch 486/600\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.4231 - accuracy: 0.8355 - val_loss: 0.4839 - val_accuracy: 0.7727\n",
      "Epoch 487/600\n",
      "20/20 [==============================] - 0s 22ms/step - loss: 0.4233 - accuracy: 0.8111 - val_loss: 0.4829 - val_accuracy: 0.7727\n",
      "Epoch 488/600\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.4290 - accuracy: 0.8290 - val_loss: 0.4904 - val_accuracy: 0.7403\n",
      "Epoch 489/600\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.4451 - accuracy: 0.8143 - val_loss: 0.4885 - val_accuracy: 0.7532\n",
      "Epoch 490/600\n",
      "20/20 [==============================] - 0s 24ms/step - loss: 0.4170 - accuracy: 0.8274 - val_loss: 0.4906 - val_accuracy: 0.7403\n",
      "Epoch 491/600\n",
      "20/20 [==============================] - 0s 23ms/step - loss: 0.4386 - accuracy: 0.8160 - val_loss: 0.4933 - val_accuracy: 0.7338\n",
      "Epoch 492/600\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.4228 - accuracy: 0.8127 - val_loss: 0.4852 - val_accuracy: 0.7532\n",
      "Epoch 493/600\n",
      "20/20 [==============================] - 1s 43ms/step - loss: 0.4214 - accuracy: 0.8160 - val_loss: 0.4862 - val_accuracy: 0.7597\n",
      "Epoch 494/600\n",
      "20/20 [==============================] - 0s 25ms/step - loss: 0.4187 - accuracy: 0.8208 - val_loss: 0.4838 - val_accuracy: 0.7792\n",
      "Epoch 495/600\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.4300 - accuracy: 0.8078 - val_loss: 0.4904 - val_accuracy: 0.7727\n",
      "Epoch 496/600\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.4223 - accuracy: 0.8192 - val_loss: 0.4872 - val_accuracy: 0.7727\n",
      "Epoch 497/600\n",
      "20/20 [==============================] - 1s 27ms/step - loss: 0.4115 - accuracy: 0.8257 - val_loss: 0.4862 - val_accuracy: 0.7597\n",
      "Epoch 498/600\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.4481 - accuracy: 0.8176 - val_loss: 0.4971 - val_accuracy: 0.7338\n",
      "Epoch 499/600\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.4172 - accuracy: 0.8388 - val_loss: 0.4932 - val_accuracy: 0.7468\n",
      "Epoch 500/600\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.4141 - accuracy: 0.8257 - val_loss: 0.4915 - val_accuracy: 0.7468\n",
      "Epoch 501/600\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.4347 - accuracy: 0.8046 - val_loss: 0.4904 - val_accuracy: 0.7532\n",
      "Epoch 502/600\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.4318 - accuracy: 0.8046 - val_loss: 0.4900 - val_accuracy: 0.7338\n",
      "Epoch 503/600\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.4372 - accuracy: 0.8208 - val_loss: 0.4905 - val_accuracy: 0.7403\n",
      "Epoch 504/600\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.4472 - accuracy: 0.8078 - val_loss: 0.4861 - val_accuracy: 0.7597\n",
      "Epoch 505/600\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.4285 - accuracy: 0.8176 - val_loss: 0.4895 - val_accuracy: 0.7273\n",
      "Epoch 506/600\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.4194 - accuracy: 0.8306 - val_loss: 0.4900 - val_accuracy: 0.7273\n",
      "Epoch 507/600\n",
      "20/20 [==============================] - 1s 42ms/step - loss: 0.4233 - accuracy: 0.8225 - val_loss: 0.4936 - val_accuracy: 0.7338\n",
      "Epoch 508/600\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.4318 - accuracy: 0.8013 - val_loss: 0.4874 - val_accuracy: 0.7532\n",
      "Epoch 509/600\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.4156 - accuracy: 0.8339 - val_loss: 0.4872 - val_accuracy: 0.7532\n",
      "Epoch 510/600\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.4195 - accuracy: 0.8176 - val_loss: 0.4877 - val_accuracy: 0.7403\n",
      "Epoch 511/600\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.4175 - accuracy: 0.8322 - val_loss: 0.4890 - val_accuracy: 0.7338\n",
      "Epoch 512/600\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 0.4249 - accuracy: 0.8062 - val_loss: 0.4906 - val_accuracy: 0.7468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 513/600\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.4321 - accuracy: 0.8094 - val_loss: 0.4890 - val_accuracy: 0.7338\n",
      "Epoch 514/600\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.4279 - accuracy: 0.8094 - val_loss: 0.4871 - val_accuracy: 0.7338\n",
      "Epoch 515/600\n",
      "20/20 [==============================] - 0s 20ms/step - loss: 0.4236 - accuracy: 0.8208 - val_loss: 0.4872 - val_accuracy: 0.7468\n",
      "Epoch 516/600\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 0.4419 - accuracy: 0.7997 - val_loss: 0.4868 - val_accuracy: 0.7403\n",
      "Epoch 517/600\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.4313 - accuracy: 0.8127 - val_loss: 0.4865 - val_accuracy: 0.7532\n",
      "Epoch 518/600\n",
      "20/20 [==============================] - 1s 49ms/step - loss: 0.4176 - accuracy: 0.8062 - val_loss: 0.4865 - val_accuracy: 0.7403\n",
      "Epoch 519/600\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.4289 - accuracy: 0.8127 - val_loss: 0.4870 - val_accuracy: 0.7468\n",
      "Epoch 520/600\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.4226 - accuracy: 0.8388 - val_loss: 0.4859 - val_accuracy: 0.7468\n",
      "Epoch 521/600\n",
      "20/20 [==============================] - 0s 22ms/step - loss: 0.4183 - accuracy: 0.8274 - val_loss: 0.4849 - val_accuracy: 0.7597\n",
      "Epoch 522/600\n",
      "20/20 [==============================] - 1s 27ms/step - loss: 0.4156 - accuracy: 0.8160 - val_loss: 0.4847 - val_accuracy: 0.7403\n",
      "Epoch 523/600\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.3991 - accuracy: 0.8322 - val_loss: 0.4845 - val_accuracy: 0.7403\n",
      "Epoch 524/600\n",
      "20/20 [==============================] - 1s 56ms/step - loss: 0.4316 - accuracy: 0.8094 - val_loss: 0.4942 - val_accuracy: 0.7273\n",
      "Epoch 525/600\n",
      "20/20 [==============================] - 1s 46ms/step - loss: 0.4268 - accuracy: 0.8241 - val_loss: 0.4907 - val_accuracy: 0.7403\n",
      "Epoch 526/600\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.4261 - accuracy: 0.8274 - val_loss: 0.4846 - val_accuracy: 0.7532\n",
      "Epoch 527/600\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 0.4206 - accuracy: 0.8274 - val_loss: 0.4900 - val_accuracy: 0.7403\n",
      "Epoch 528/600\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.4248 - accuracy: 0.8388 - val_loss: 0.4895 - val_accuracy: 0.7468\n",
      "Epoch 529/600\n",
      "20/20 [==============================] - 1s 27ms/step - loss: 0.4156 - accuracy: 0.8388 - val_loss: 0.4890 - val_accuracy: 0.7532\n",
      "Epoch 530/600\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.4076 - accuracy: 0.8355 - val_loss: 0.4895 - val_accuracy: 0.7532\n",
      "Epoch 531/600\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.4300 - accuracy: 0.8225 - val_loss: 0.4903 - val_accuracy: 0.7532\n",
      "Epoch 532/600\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.4300 - accuracy: 0.8192 - val_loss: 0.4970 - val_accuracy: 0.7338\n",
      "Epoch 533/600\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.4200 - accuracy: 0.8306 - val_loss: 0.4955 - val_accuracy: 0.7338\n",
      "Epoch 534/600\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.4253 - accuracy: 0.8176 - val_loss: 0.4961 - val_accuracy: 0.7468\n",
      "Epoch 535/600\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.4232 - accuracy: 0.8322 - val_loss: 0.4906 - val_accuracy: 0.7468\n",
      "Epoch 536/600\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 0.4378 - accuracy: 0.8094 - val_loss: 0.4940 - val_accuracy: 0.7273\n",
      "Epoch 537/600\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.4205 - accuracy: 0.8339 - val_loss: 0.4890 - val_accuracy: 0.7532\n",
      "Epoch 538/600\n",
      "20/20 [==============================] - 0s 25ms/step - loss: 0.4332 - accuracy: 0.8111 - val_loss: 0.4898 - val_accuracy: 0.7403\n",
      "Epoch 539/600\n",
      "20/20 [==============================] - 0s 24ms/step - loss: 0.4045 - accuracy: 0.8176 - val_loss: 0.4871 - val_accuracy: 0.7532\n",
      "Epoch 540/600\n",
      "20/20 [==============================] - 1s 44ms/step - loss: 0.4339 - accuracy: 0.8143 - val_loss: 0.4875 - val_accuracy: 0.7403\n",
      "Epoch 541/600\n",
      "20/20 [==============================] - 1s 49ms/step - loss: 0.4182 - accuracy: 0.8160 - val_loss: 0.4903 - val_accuracy: 0.7468\n",
      "Epoch 542/600\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.4176 - accuracy: 0.8322 - val_loss: 0.4885 - val_accuracy: 0.7532\n",
      "Epoch 543/600\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.4269 - accuracy: 0.8046 - val_loss: 0.4903 - val_accuracy: 0.7532\n",
      "Epoch 544/600\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.4112 - accuracy: 0.8225 - val_loss: 0.4928 - val_accuracy: 0.7273\n",
      "Epoch 545/600\n",
      "20/20 [==============================] - 1s 26ms/step - loss: 0.4405 - accuracy: 0.8111 - val_loss: 0.4912 - val_accuracy: 0.7403\n",
      "Epoch 546/600\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.4263 - accuracy: 0.8192 - val_loss: 0.4940 - val_accuracy: 0.7273\n",
      "Epoch 547/600\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.4127 - accuracy: 0.8322 - val_loss: 0.4902 - val_accuracy: 0.7468\n",
      "Epoch 548/600\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.4360 - accuracy: 0.8257 - val_loss: 0.4935 - val_accuracy: 0.7338\n",
      "Epoch 549/600\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.4001 - accuracy: 0.8469 - val_loss: 0.4930 - val_accuracy: 0.7468\n",
      "Epoch 550/600\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.4300 - accuracy: 0.8160 - val_loss: 0.5048 - val_accuracy: 0.7273\n",
      "Epoch 551/600\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.4318 - accuracy: 0.8127 - val_loss: 0.4992 - val_accuracy: 0.7403\n",
      "Epoch 552/600\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.4308 - accuracy: 0.8192 - val_loss: 0.5030 - val_accuracy: 0.7208\n",
      "Epoch 553/600\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.4198 - accuracy: 0.8208 - val_loss: 0.4955 - val_accuracy: 0.7532\n",
      "Epoch 554/600\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.4216 - accuracy: 0.8355 - val_loss: 0.4961 - val_accuracy: 0.7338\n",
      "Epoch 555/600\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.3999 - accuracy: 0.8388 - val_loss: 0.4972 - val_accuracy: 0.7208\n",
      "Epoch 556/600\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.4065 - accuracy: 0.8502 - val_loss: 0.4947 - val_accuracy: 0.7403\n",
      "Epoch 557/600\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 0.4264 - accuracy: 0.8225 - val_loss: 0.4926 - val_accuracy: 0.7468\n",
      "Epoch 558/600\n",
      "20/20 [==============================] - 0s 25ms/step - loss: 0.4282 - accuracy: 0.8257 - val_loss: 0.4992 - val_accuracy: 0.7273\n",
      "Epoch 559/600\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.4179 - accuracy: 0.8290 - val_loss: 0.4966 - val_accuracy: 0.7338\n",
      "Epoch 560/600\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.4153 - accuracy: 0.8322 - val_loss: 0.4967 - val_accuracy: 0.7468\n",
      "Epoch 561/600\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.4069 - accuracy: 0.8241 - val_loss: 0.4985 - val_accuracy: 0.7468\n",
      "Epoch 562/600\n",
      "20/20 [==============================] - 1s 27ms/step - loss: 0.4093 - accuracy: 0.8127 - val_loss: 0.4965 - val_accuracy: 0.7468\n",
      "Epoch 563/600\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.4097 - accuracy: 0.8176 - val_loss: 0.4928 - val_accuracy: 0.7532\n",
      "Epoch 564/600\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.4160 - accuracy: 0.8306 - val_loss: 0.4944 - val_accuracy: 0.7532\n",
      "Epoch 565/600\n",
      "20/20 [==============================] - 1s 50ms/step - loss: 0.4275 - accuracy: 0.8078 - val_loss: 0.4907 - val_accuracy: 0.7662\n",
      "Epoch 566/600\n",
      "20/20 [==============================] - 1s 48ms/step - loss: 0.4039 - accuracy: 0.8322 - val_loss: 0.4969 - val_accuracy: 0.7273\n",
      "Epoch 567/600\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.4237 - accuracy: 0.8176 - val_loss: 0.4975 - val_accuracy: 0.7273\n",
      "Epoch 568/600\n",
      "20/20 [==============================] - 1s 27ms/step - loss: 0.4234 - accuracy: 0.8225 - val_loss: 0.4990 - val_accuracy: 0.7338\n",
      "Epoch 569/600\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.4136 - accuracy: 0.8241 - val_loss: 0.4967 - val_accuracy: 0.7468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 570/600\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.4309 - accuracy: 0.8192 - val_loss: 0.5045 - val_accuracy: 0.7273\n",
      "Epoch 571/600\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.4115 - accuracy: 0.8306 - val_loss: 0.5005 - val_accuracy: 0.7468\n",
      "Epoch 572/600\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 0.4136 - accuracy: 0.8322 - val_loss: 0.4979 - val_accuracy: 0.7468\n",
      "Epoch 573/600\n",
      "20/20 [==============================] - 1s 27ms/step - loss: 0.4162 - accuracy: 0.8111 - val_loss: 0.5007 - val_accuracy: 0.7403\n",
      "Epoch 574/600\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.4336 - accuracy: 0.8208 - val_loss: 0.5033 - val_accuracy: 0.7208\n",
      "Epoch 575/600\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.4049 - accuracy: 0.8274 - val_loss: 0.5014 - val_accuracy: 0.7143\n",
      "Epoch 576/600\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.4184 - accuracy: 0.8306 - val_loss: 0.5000 - val_accuracy: 0.7338\n",
      "Epoch 577/600\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 0.4121 - accuracy: 0.8436 - val_loss: 0.5019 - val_accuracy: 0.7468\n",
      "Epoch 578/600\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.4131 - accuracy: 0.8388 - val_loss: 0.4977 - val_accuracy: 0.7403\n",
      "Epoch 579/600\n",
      "20/20 [==============================] - 1s 27ms/step - loss: 0.4059 - accuracy: 0.8388 - val_loss: 0.4995 - val_accuracy: 0.7468\n",
      "Epoch 580/600\n",
      "20/20 [==============================] - 1s 26ms/step - loss: 0.4076 - accuracy: 0.8306 - val_loss: 0.5014 - val_accuracy: 0.7273\n",
      "Epoch 581/600\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 0.4116 - accuracy: 0.8322 - val_loss: 0.4991 - val_accuracy: 0.7468\n",
      "Epoch 582/600\n",
      "20/20 [==============================] - 0s 23ms/step - loss: 0.4315 - accuracy: 0.8208 - val_loss: 0.4978 - val_accuracy: 0.7338\n",
      "Epoch 583/600\n",
      "20/20 [==============================] - 0s 22ms/step - loss: 0.4148 - accuracy: 0.8274 - val_loss: 0.4917 - val_accuracy: 0.7468\n",
      "Epoch 584/600\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.4300 - accuracy: 0.8176 - val_loss: 0.4966 - val_accuracy: 0.7273\n",
      "Epoch 585/600\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.4055 - accuracy: 0.8306 - val_loss: 0.4992 - val_accuracy: 0.7273\n",
      "Epoch 586/600\n",
      "20/20 [==============================] - 1s 45ms/step - loss: 0.4065 - accuracy: 0.8371 - val_loss: 0.4981 - val_accuracy: 0.7532\n",
      "Epoch 587/600\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.4203 - accuracy: 0.8160 - val_loss: 0.4965 - val_accuracy: 0.7338\n",
      "Epoch 588/600\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.4080 - accuracy: 0.8322 - val_loss: 0.4931 - val_accuracy: 0.7468\n",
      "Epoch 589/600\n",
      "20/20 [==============================] - 0s 23ms/step - loss: 0.4211 - accuracy: 0.8208 - val_loss: 0.4910 - val_accuracy: 0.7532\n",
      "Epoch 590/600\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.4163 - accuracy: 0.8160 - val_loss: 0.4951 - val_accuracy: 0.7468\n",
      "Epoch 591/600\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.4085 - accuracy: 0.8355 - val_loss: 0.4916 - val_accuracy: 0.7403\n",
      "Epoch 592/600\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.4148 - accuracy: 0.8225 - val_loss: 0.4919 - val_accuracy: 0.7597\n",
      "Epoch 593/600\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.4286 - accuracy: 0.8192 - val_loss: 0.4935 - val_accuracy: 0.7532\n",
      "Epoch 594/600\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.4229 - accuracy: 0.8339 - val_loss: 0.4979 - val_accuracy: 0.7338\n",
      "Epoch 595/600\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.4007 - accuracy: 0.8339 - val_loss: 0.4935 - val_accuracy: 0.7403\n",
      "Epoch 596/600\n",
      "20/20 [==============================] - 1s 27ms/step - loss: 0.4154 - accuracy: 0.8208 - val_loss: 0.4916 - val_accuracy: 0.7597\n",
      "Epoch 597/600\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.4102 - accuracy: 0.8208 - val_loss: 0.4967 - val_accuracy: 0.7532\n",
      "Epoch 598/600\n",
      "20/20 [==============================] - 1s 27ms/step - loss: 0.4012 - accuracy: 0.8257 - val_loss: 0.4905 - val_accuracy: 0.7597\n",
      "Epoch 599/600\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.4289 - accuracy: 0.8290 - val_loss: 0.4917 - val_accuracy: 0.7532\n",
      "Epoch 600/600\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.4051 - accuracy: 0.8404 - val_loss: 0.4932 - val_accuracy: 0.7532\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4932 - accuracy: 0.7532\n",
      "Test Accuracy: 0.7532\n"
     ]
    }
   ],
   "source": [
    "#CNN: 1 convolution layer - 1 Pooling - MLP  \"avec adem optimizer\"\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, Flatten, Dropout, MaxPooling1D\n",
    "from keras import regularizers\n",
    "import keras\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "model_cnn = Sequential()\n",
    "\n",
    "model_cnn.add(Conv1D(16, kernel_size=2, activation='relu', input_shape=(8,1)))\n",
    "\n",
    "model_cnn.add(Conv1D(32, kernel_size=2, strides=1, activation='relu'))\n",
    "model_cnn.add(Conv1D(32, kernel_size=2, strides=1, activation='relu'))\n",
    "#model_cnn.add(Dropout(0.25))\n",
    "model_cnn.add(MaxPooling1D(pool_size=2, padding='same'))\n",
    "model_cnn.add(Dropout(0.60))\n",
    "model_cnn.add(Flatten())\n",
    "model_cnn.add(Dense(3, kernel_regularizer=regularizers.l2(0.04), activation='relu'))\n",
    "model_cnn.add(Dense(1, kernel_regularizer=regularizers.l2(0.02), activation='sigmoid'))\n",
    "\n",
    "model_cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history=model_cnn.fit(X_train, y_train, batch_size=32, epochs=600,validation_data=(X_test, y_test))\n",
    "    \n",
    "loss, accuracy = model_cnn.evaluate(X_test, y_test, batch_size=None, verbose=1)\n",
    "print(\"Test Accuracy: {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac213819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_15 (Conv1D)           (None, 7, 16)             48        \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 6, 32)             1056      \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 5, 32)             2080      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 3, 32)             0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 3, 32)             0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 96)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 3)                 291       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 3,479\n",
      "Trainable params: 3,479\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "25099d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.callbacks import CallbackList as KerasCallbackList\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e04b97c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Test', 'Train'], loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Test', 'Train'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "510decf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "62/62 [==============================] - 1s 21ms/step - loss: 0.4124 - accuracy: 0.7231 - val_loss: 0.3513 - val_accuracy: 0.7143\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.3052 - accuracy: 0.7704 - val_loss: 0.2863 - val_accuracy: 0.7273\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.2565 - accuracy: 0.7769 - val_loss: 0.2515 - val_accuracy: 0.7273\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.2287 - accuracy: 0.7687 - val_loss: 0.2329 - val_accuracy: 0.7208\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.2156 - accuracy: 0.7687 - val_loss: 0.2200 - val_accuracy: 0.7403\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.2053 - accuracy: 0.7818 - val_loss: 0.2134 - val_accuracy: 0.7532\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.2004 - accuracy: 0.7785 - val_loss: 0.2085 - val_accuracy: 0.7403\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1974 - accuracy: 0.7638 - val_loss: 0.2060 - val_accuracy: 0.7338\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1940 - accuracy: 0.7801 - val_loss: 0.2060 - val_accuracy: 0.7403\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1932 - accuracy: 0.7899 - val_loss: 0.2058 - val_accuracy: 0.7338\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1913 - accuracy: 0.7736 - val_loss: 0.2011 - val_accuracy: 0.7403\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1901 - accuracy: 0.7883 - val_loss: 0.2009 - val_accuracy: 0.7403\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1896 - accuracy: 0.7769 - val_loss: 0.1994 - val_accuracy: 0.7338\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1884 - accuracy: 0.7932 - val_loss: 0.2018 - val_accuracy: 0.7468\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1889 - accuracy: 0.7899 - val_loss: 0.2036 - val_accuracy: 0.7273\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1863 - accuracy: 0.7850 - val_loss: 0.1994 - val_accuracy: 0.7468\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1865 - accuracy: 0.7915 - val_loss: 0.1995 - val_accuracy: 0.7338\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1868 - accuracy: 0.7866 - val_loss: 0.2006 - val_accuracy: 0.7338\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1873 - accuracy: 0.7834 - val_loss: 0.2005 - val_accuracy: 0.7468\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1861 - accuracy: 0.7915 - val_loss: 0.1984 - val_accuracy: 0.7403\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1851 - accuracy: 0.7850 - val_loss: 0.2042 - val_accuracy: 0.7403\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1851 - accuracy: 0.7883 - val_loss: 0.2031 - val_accuracy: 0.7338\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.1843 - accuracy: 0.7801 - val_loss: 0.1966 - val_accuracy: 0.7403\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1861 - accuracy: 0.7818 - val_loss: 0.1949 - val_accuracy: 0.7468\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1845 - accuracy: 0.7818 - val_loss: 0.1955 - val_accuracy: 0.7273\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1831 - accuracy: 0.7915 - val_loss: 0.1994 - val_accuracy: 0.7273\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1831 - accuracy: 0.7850 - val_loss: 0.1955 - val_accuracy: 0.7403\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1855 - accuracy: 0.7720 - val_loss: 0.1984 - val_accuracy: 0.7208\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1822 - accuracy: 0.7997 - val_loss: 0.1993 - val_accuracy: 0.7338\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1823 - accuracy: 0.7980 - val_loss: 0.1962 - val_accuracy: 0.7403\n",
      "Epoch 31/100\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.1816 - accuracy: 0.7948 - val_loss: 0.1995 - val_accuracy: 0.7208\n",
      "Epoch 32/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1817 - accuracy: 0.7915 - val_loss: 0.2004 - val_accuracy: 0.7403\n",
      "Epoch 33/100\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.1820 - accuracy: 0.7997 - val_loss: 0.1986 - val_accuracy: 0.7208\n",
      "Epoch 34/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1810 - accuracy: 0.8062 - val_loss: 0.1974 - val_accuracy: 0.7273\n",
      "Epoch 35/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1806 - accuracy: 0.7932 - val_loss: 0.1987 - val_accuracy: 0.7403\n",
      "Epoch 36/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1814 - accuracy: 0.7801 - val_loss: 0.1956 - val_accuracy: 0.7338\n",
      "Epoch 37/100\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.1809 - accuracy: 0.7932 - val_loss: 0.1970 - val_accuracy: 0.7338\n",
      "Epoch 38/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.1806 - accuracy: 0.7866 - val_loss: 0.1985 - val_accuracy: 0.7208\n",
      "Epoch 39/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.1800 - accuracy: 0.8013 - val_loss: 0.1957 - val_accuracy: 0.7208\n",
      "Epoch 40/100\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.1803 - accuracy: 0.7883 - val_loss: 0.2002 - val_accuracy: 0.7273\n",
      "Epoch 41/100\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.1801 - accuracy: 0.7932 - val_loss: 0.1959 - val_accuracy: 0.7338\n",
      "Epoch 42/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1789 - accuracy: 0.7883 - val_loss: 0.1989 - val_accuracy: 0.7273\n",
      "Epoch 43/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1793 - accuracy: 0.7932 - val_loss: 0.1978 - val_accuracy: 0.7273\n",
      "Epoch 44/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1788 - accuracy: 0.7899 - val_loss: 0.1956 - val_accuracy: 0.7143\n",
      "Epoch 45/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1785 - accuracy: 0.7866 - val_loss: 0.1960 - val_accuracy: 0.7273\n",
      "Epoch 46/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1792 - accuracy: 0.7964 - val_loss: 0.1966 - val_accuracy: 0.7208\n",
      "Epoch 47/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1785 - accuracy: 0.7883 - val_loss: 0.1976 - val_accuracy: 0.7273\n",
      "Epoch 48/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1782 - accuracy: 0.7964 - val_loss: 0.1957 - val_accuracy: 0.7338\n",
      "Epoch 49/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1778 - accuracy: 0.7948 - val_loss: 0.1953 - val_accuracy: 0.7338\n",
      "Epoch 50/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1780 - accuracy: 0.7899 - val_loss: 0.1974 - val_accuracy: 0.7338\n",
      "Epoch 51/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1771 - accuracy: 0.7980 - val_loss: 0.1957 - val_accuracy: 0.7273\n",
      "Epoch 52/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1765 - accuracy: 0.7948 - val_loss: 0.1997 - val_accuracy: 0.7078\n",
      "Epoch 53/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1766 - accuracy: 0.8046 - val_loss: 0.1964 - val_accuracy: 0.7143\n",
      "Epoch 54/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1769 - accuracy: 0.7932 - val_loss: 0.1962 - val_accuracy: 0.7273\n",
      "Epoch 55/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1763 - accuracy: 0.8013 - val_loss: 0.1972 - val_accuracy: 0.7338\n",
      "Epoch 56/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1767 - accuracy: 0.8029 - val_loss: 0.1972 - val_accuracy: 0.7143\n",
      "Epoch 57/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1757 - accuracy: 0.7883 - val_loss: 0.1942 - val_accuracy: 0.7403\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1763 - accuracy: 0.8078 - val_loss: 0.1938 - val_accuracy: 0.7338\n",
      "Epoch 59/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1743 - accuracy: 0.8046 - val_loss: 0.2042 - val_accuracy: 0.7338\n",
      "Epoch 60/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1766 - accuracy: 0.8029 - val_loss: 0.1976 - val_accuracy: 0.7208\n",
      "Epoch 61/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1758 - accuracy: 0.7997 - val_loss: 0.1984 - val_accuracy: 0.7208\n",
      "Epoch 62/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1761 - accuracy: 0.7980 - val_loss: 0.1990 - val_accuracy: 0.7143\n",
      "Epoch 63/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1752 - accuracy: 0.8013 - val_loss: 0.1956 - val_accuracy: 0.7143\n",
      "Epoch 64/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1742 - accuracy: 0.7997 - val_loss: 0.1938 - val_accuracy: 0.7143\n",
      "Epoch 65/100\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.1737 - accuracy: 0.80 - 1s 9ms/step - loss: 0.1745 - accuracy: 0.8013 - val_loss: 0.1987 - val_accuracy: 0.7208\n",
      "Epoch 66/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1745 - accuracy: 0.8062 - val_loss: 0.1962 - val_accuracy: 0.7143\n",
      "Epoch 67/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1742 - accuracy: 0.7997 - val_loss: 0.1963 - val_accuracy: 0.7013\n",
      "Epoch 68/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1741 - accuracy: 0.8013 - val_loss: 0.1958 - val_accuracy: 0.7143\n",
      "Epoch 69/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1733 - accuracy: 0.8094 - val_loss: 0.1982 - val_accuracy: 0.7208\n",
      "Epoch 70/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1731 - accuracy: 0.8192 - val_loss: 0.1968 - val_accuracy: 0.7143\n",
      "Epoch 71/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.1728 - accuracy: 0.8160 - val_loss: 0.1976 - val_accuracy: 0.7208\n",
      "Epoch 72/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1737 - accuracy: 0.8111 - val_loss: 0.1941 - val_accuracy: 0.7403\n",
      "Epoch 73/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1742 - accuracy: 0.8192 - val_loss: 0.1964 - val_accuracy: 0.7208\n",
      "Epoch 74/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1729 - accuracy: 0.8078 - val_loss: 0.1962 - val_accuracy: 0.7143\n",
      "Epoch 75/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1720 - accuracy: 0.8094 - val_loss: 0.2006 - val_accuracy: 0.7273\n",
      "Epoch 76/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1729 - accuracy: 0.8062 - val_loss: 0.1957 - val_accuracy: 0.7143\n",
      "Epoch 77/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1717 - accuracy: 0.8127 - val_loss: 0.1983 - val_accuracy: 0.7143\n",
      "Epoch 78/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1715 - accuracy: 0.8111 - val_loss: 0.1985 - val_accuracy: 0.7143\n",
      "Epoch 79/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1721 - accuracy: 0.8111 - val_loss: 0.1988 - val_accuracy: 0.7208\n",
      "Epoch 80/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1719 - accuracy: 0.8078 - val_loss: 0.2027 - val_accuracy: 0.7403\n",
      "Epoch 81/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1715 - accuracy: 0.8078 - val_loss: 0.1939 - val_accuracy: 0.7273\n",
      "Epoch 82/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1721 - accuracy: 0.8160 - val_loss: 0.1953 - val_accuracy: 0.7208\n",
      "Epoch 83/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1706 - accuracy: 0.8127 - val_loss: 0.1973 - val_accuracy: 0.7208\n",
      "Epoch 84/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1721 - accuracy: 0.8160 - val_loss: 0.1985 - val_accuracy: 0.7143\n",
      "Epoch 85/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1710 - accuracy: 0.8111 - val_loss: 0.1997 - val_accuracy: 0.7208\n",
      "Epoch 86/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1710 - accuracy: 0.8046 - val_loss: 0.1987 - val_accuracy: 0.7143\n",
      "Epoch 87/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1701 - accuracy: 0.8208 - val_loss: 0.1959 - val_accuracy: 0.7208\n",
      "Epoch 88/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1698 - accuracy: 0.8176 - val_loss: 0.1984 - val_accuracy: 0.7273\n",
      "Epoch 89/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1696 - accuracy: 0.8062 - val_loss: 0.1946 - val_accuracy: 0.7273\n",
      "Epoch 90/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1707 - accuracy: 0.8111 - val_loss: 0.1982 - val_accuracy: 0.7273\n",
      "Epoch 91/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1700 - accuracy: 0.8160 - val_loss: 0.1961 - val_accuracy: 0.7338\n",
      "Epoch 92/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1694 - accuracy: 0.8094 - val_loss: 0.1933 - val_accuracy: 0.7338\n",
      "Epoch 93/100\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.1711 - accuracy: 0.8208 - val_loss: 0.1981 - val_accuracy: 0.7273\n",
      "Epoch 94/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1701 - accuracy: 0.8160 - val_loss: 0.1999 - val_accuracy: 0.7338\n",
      "Epoch 95/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1696 - accuracy: 0.8111 - val_loss: 0.1997 - val_accuracy: 0.7143\n",
      "Epoch 96/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1692 - accuracy: 0.8208 - val_loss: 0.1944 - val_accuracy: 0.7273\n",
      "Epoch 97/100\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.1683 - accuracy: 0.8176 - val_loss: 0.2012 - val_accuracy: 0.7273\n",
      "Epoch 98/100\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.1683 - accuracy: 0.83 - 1s 11ms/step - loss: 0.1684 - accuracy: 0.8290 - val_loss: 0.1969 - val_accuracy: 0.7208\n",
      "Epoch 99/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1681 - accuracy: 0.8192 - val_loss: 0.1979 - val_accuracy: 0.7273\n",
      "Epoch 100/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1690 - accuracy: 0.8078 - val_loss: 0.1978 - val_accuracy: 0.7338\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1978 - accuracy: 0.7338\n",
      "Test Accuracy: 0.7338\n"
     ]
    }
   ],
   "source": [
    "#CNN: 1 convolution layer - 1 Pooling - MLP  \"avec activation tanh\"\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, Flatten, Dropout, MaxPooling1D\n",
    "from keras import regularizers\n",
    "import keras\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "model_cnn = Sequential()\n",
    "\n",
    "model_cnn.add(Conv1D(16, kernel_size=2, activation='tanh', input_shape=(8,1), data_format = 'channels_last'))\n",
    "\n",
    "model_cnn.add(Conv1D(32, kernel_size=2, strides=1, activation='tanh'))\n",
    "model_cnn.add(Conv1D(32, kernel_size=2, strides=1, activation='tanh'))\n",
    "model_cnn.add(MaxPooling1D(pool_size=2, padding='same'))\n",
    "model_cnn.add(Flatten())\n",
    "model_cnn.add(Dense(3, kernel_regularizer=regularizers.l2(0.04), activation='tanh'))\n",
    "model_cnn.add(Dense(1, kernel_regularizer=regularizers.l2(0.02), activation='sigmoid'))\n",
    "\n",
    "model_cnn.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "\n",
    "history=model_cnn.fit(X_train, y_train, batch_size=10, epochs=100,validation_data=(X_test, y_test))\n",
    "    \n",
    "loss, accuracy = model_cnn.evaluate(X_test, y_test, batch_size=None, verbose=1)\n",
    "print(\"Test Accuracy: {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da59ced2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/350\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.5018 - accuracy: 0.6107 - val_loss: 0.4855 - val_accuracy: 0.6558\n",
      "Epoch 2/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.4716 - accuracy: 0.6498 - val_loss: 0.4584 - val_accuracy: 0.6558\n",
      "Epoch 3/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.4466 - accuracy: 0.6498 - val_loss: 0.4353 - val_accuracy: 0.6558\n",
      "Epoch 4/350\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.4251 - accuracy: 0.6498 - val_loss: 0.4150 - val_accuracy: 0.6558\n",
      "Epoch 5/350\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.4061 - accuracy: 0.6498 - val_loss: 0.3970 - val_accuracy: 0.6558\n",
      "Epoch 6/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.3891 - accuracy: 0.6498 - val_loss: 0.3810 - val_accuracy: 0.6558\n",
      "Epoch 7/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.3740 - accuracy: 0.6498 - val_loss: 0.3665 - val_accuracy: 0.6558\n",
      "Epoch 8/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.3604 - accuracy: 0.6498 - val_loss: 0.3536 - val_accuracy: 0.6558\n",
      "Epoch 9/350\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.3481 - accuracy: 0.6498 - val_loss: 0.3419 - val_accuracy: 0.6558\n",
      "Epoch 10/350\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.3371 - accuracy: 0.6482 - val_loss: 0.3313 - val_accuracy: 0.6558\n",
      "Epoch 11/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.3271 - accuracy: 0.6482 - val_loss: 0.3218 - val_accuracy: 0.6558\n",
      "Epoch 12/350\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.3182 - accuracy: 0.6482 - val_loss: 0.3132 - val_accuracy: 0.6558\n",
      "Epoch 13/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.3100 - accuracy: 0.6482 - val_loss: 0.3054 - val_accuracy: 0.6558\n",
      "Epoch 14/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.3026 - accuracy: 0.6482 - val_loss: 0.2983 - val_accuracy: 0.6558\n",
      "Epoch 15/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.2959 - accuracy: 0.6482 - val_loss: 0.2919 - val_accuracy: 0.6558\n",
      "Epoch 16/350\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.2898 - accuracy: 0.6482 - val_loss: 0.2860 - val_accuracy: 0.6558\n",
      "Epoch 17/350\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.2844 - accuracy: 0.64 - 1s 11ms/step - loss: 0.2843 - accuracy: 0.6482 - val_loss: 0.2807 - val_accuracy: 0.6558\n",
      "Epoch 18/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.2793 - accuracy: 0.6482 - val_loss: 0.2759 - val_accuracy: 0.6558\n",
      "Epoch 19/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.2746 - accuracy: 0.6482 - val_loss: 0.2715 - val_accuracy: 0.6558\n",
      "Epoch 20/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.2704 - accuracy: 0.6482 - val_loss: 0.2675 - val_accuracy: 0.6558\n",
      "Epoch 21/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.2666 - accuracy: 0.6498 - val_loss: 0.2638 - val_accuracy: 0.6558\n",
      "Epoch 22/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.2630 - accuracy: 0.6498 - val_loss: 0.2604 - val_accuracy: 0.6558\n",
      "Epoch 23/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.2598 - accuracy: 0.6498 - val_loss: 0.2573 - val_accuracy: 0.6558\n",
      "Epoch 24/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.2568 - accuracy: 0.6498 - val_loss: 0.2545 - val_accuracy: 0.6558\n",
      "Epoch 25/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.2542 - accuracy: 0.6498 - val_loss: 0.2519 - val_accuracy: 0.6558\n",
      "Epoch 26/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.2517 - accuracy: 0.6498 - val_loss: 0.2495 - val_accuracy: 0.6558\n",
      "Epoch 27/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.2494 - accuracy: 0.6498 - val_loss: 0.2473 - val_accuracy: 0.6558\n",
      "Epoch 28/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.2472 - accuracy: 0.6498 - val_loss: 0.2452 - val_accuracy: 0.6558\n",
      "Epoch 29/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.2453 - accuracy: 0.6498 - val_loss: 0.2434 - val_accuracy: 0.6558\n",
      "Epoch 30/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.2436 - accuracy: 0.6482 - val_loss: 0.2416 - val_accuracy: 0.6558\n",
      "Epoch 31/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.2419 - accuracy: 0.6482 - val_loss: 0.2400 - val_accuracy: 0.6558\n",
      "Epoch 32/350\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.2404 - accuracy: 0.6498 - val_loss: 0.2386 - val_accuracy: 0.6558\n",
      "Epoch 33/350\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.2390 - accuracy: 0.6498 - val_loss: 0.2372 - val_accuracy: 0.6558\n",
      "Epoch 34/350\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.2377 - accuracy: 0.6498 - val_loss: 0.2360 - val_accuracy: 0.6558\n",
      "Epoch 35/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.2365 - accuracy: 0.6498 - val_loss: 0.2348 - val_accuracy: 0.6558\n",
      "Epoch 36/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.2354 - accuracy: 0.6498 - val_loss: 0.2337 - val_accuracy: 0.6558\n",
      "Epoch 37/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.2344 - accuracy: 0.6498 - val_loss: 0.2327 - val_accuracy: 0.6558\n",
      "Epoch 38/350\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.2334 - accuracy: 0.6498 - val_loss: 0.2317 - val_accuracy: 0.6558\n",
      "Epoch 39/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.2325 - accuracy: 0.6498 - val_loss: 0.2308 - val_accuracy: 0.6558\n",
      "Epoch 40/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.2316 - accuracy: 0.6498 - val_loss: 0.2299 - val_accuracy: 0.6558\n",
      "Epoch 41/350\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.2308 - accuracy: 0.6498 - val_loss: 0.2291 - val_accuracy: 0.6558\n",
      "Epoch 42/350\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.2301 - accuracy: 0.6498 - val_loss: 0.2284 - val_accuracy: 0.6558\n",
      "Epoch 43/350\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.2294 - accuracy: 0.6498 - val_loss: 0.2277 - val_accuracy: 0.6558\n",
      "Epoch 44/350\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.2287 - accuracy: 0.6498 - val_loss: 0.2270 - val_accuracy: 0.6558\n",
      "Epoch 45/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.2280 - accuracy: 0.6498 - val_loss: 0.2263 - val_accuracy: 0.6558\n",
      "Epoch 46/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.2274 - accuracy: 0.6498 - val_loss: 0.2257 - val_accuracy: 0.6623\n",
      "Epoch 47/350\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.2268 - accuracy: 0.6498 - val_loss: 0.2251 - val_accuracy: 0.6688\n",
      "Epoch 48/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.2262 - accuracy: 0.6482 - val_loss: 0.2246 - val_accuracy: 0.6688\n",
      "Epoch 49/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.2256 - accuracy: 0.6482 - val_loss: 0.2240 - val_accuracy: 0.6688\n",
      "Epoch 50/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.2251 - accuracy: 0.6482 - val_loss: 0.2235 - val_accuracy: 0.6688\n",
      "Epoch 51/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.2245 - accuracy: 0.6482 - val_loss: 0.2229 - val_accuracy: 0.6688\n",
      "Epoch 52/350\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.2240 - accuracy: 0.6515 - val_loss: 0.2224 - val_accuracy: 0.6688\n",
      "Epoch 53/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.2234 - accuracy: 0.6515 - val_loss: 0.2219 - val_accuracy: 0.6688\n",
      "Epoch 54/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.2229 - accuracy: 0.6515 - val_loss: 0.2214 - val_accuracy: 0.6688\n",
      "Epoch 55/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.2224 - accuracy: 0.6531 - val_loss: 0.2209 - val_accuracy: 0.6688\n",
      "Epoch 56/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.2219 - accuracy: 0.6547 - val_loss: 0.2204 - val_accuracy: 0.6558\n",
      "Epoch 57/350\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.2194 - accuracy: 0.66 - 1s 9ms/step - loss: 0.2214 - accuracy: 0.6596 - val_loss: 0.2199 - val_accuracy: 0.6558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/350\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.2208 - accuracy: 0.6612 - val_loss: 0.2194 - val_accuracy: 0.6688\n",
      "Epoch 59/350\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.2203 - accuracy: 0.6596 - val_loss: 0.2189 - val_accuracy: 0.6688\n",
      "Epoch 60/350\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.2198 - accuracy: 0.6678 - val_loss: 0.2184 - val_accuracy: 0.6753\n",
      "Epoch 61/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.2193 - accuracy: 0.6678 - val_loss: 0.2179 - val_accuracy: 0.6753\n",
      "Epoch 62/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.2187 - accuracy: 0.6743 - val_loss: 0.2174 - val_accuracy: 0.6753\n",
      "Epoch 63/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.2182 - accuracy: 0.6840 - val_loss: 0.2169 - val_accuracy: 0.6818\n",
      "Epoch 64/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.2177 - accuracy: 0.6840 - val_loss: 0.2164 - val_accuracy: 0.7013\n",
      "Epoch 65/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.2172 - accuracy: 0.6938 - val_loss: 0.2159 - val_accuracy: 0.7013\n",
      "Epoch 66/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.2166 - accuracy: 0.7085 - val_loss: 0.2154 - val_accuracy: 0.7013\n",
      "Epoch 67/350\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.2162 - accuracy: 0.7036 - val_loss: 0.2149 - val_accuracy: 0.7013\n",
      "Epoch 68/350\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.2155 - accuracy: 0.7101 - val_loss: 0.2144 - val_accuracy: 0.7013\n",
      "Epoch 69/350\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.2150 - accuracy: 0.7182 - val_loss: 0.2139 - val_accuracy: 0.7013\n",
      "Epoch 70/350\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.2144 - accuracy: 0.7182 - val_loss: 0.2134 - val_accuracy: 0.7013\n",
      "Epoch 71/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.2140 - accuracy: 0.7248 - val_loss: 0.2130 - val_accuracy: 0.6948\n",
      "Epoch 72/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.2134 - accuracy: 0.7313 - val_loss: 0.2125 - val_accuracy: 0.7078\n",
      "Epoch 73/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.2129 - accuracy: 0.7329 - val_loss: 0.2120 - val_accuracy: 0.7143\n",
      "Epoch 74/350\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.2123 - accuracy: 0.7329 - val_loss: 0.2116 - val_accuracy: 0.7143\n",
      "Epoch 75/350\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.2118 - accuracy: 0.7313 - val_loss: 0.2111 - val_accuracy: 0.7273\n",
      "Epoch 76/350\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.2112 - accuracy: 0.7329 - val_loss: 0.2107 - val_accuracy: 0.7403\n",
      "Epoch 77/350\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.2107 - accuracy: 0.7394 - val_loss: 0.2103 - val_accuracy: 0.7403\n",
      "Epoch 78/350\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.2102 - accuracy: 0.7362 - val_loss: 0.2099 - val_accuracy: 0.7273\n",
      "Epoch 79/350\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.2096 - accuracy: 0.7443 - val_loss: 0.2095 - val_accuracy: 0.7338\n",
      "Epoch 80/350\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.2092 - accuracy: 0.7427 - val_loss: 0.2091 - val_accuracy: 0.7208\n",
      "Epoch 81/350\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.2086 - accuracy: 0.7459 - val_loss: 0.2087 - val_accuracy: 0.7208\n",
      "Epoch 82/350\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.2082 - accuracy: 0.7459 - val_loss: 0.2083 - val_accuracy: 0.7208\n",
      "Epoch 83/350\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.2077 - accuracy: 0.7459 - val_loss: 0.2079 - val_accuracy: 0.7143\n",
      "Epoch 84/350\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.2072 - accuracy: 0.7459 - val_loss: 0.2077 - val_accuracy: 0.7208\n",
      "Epoch 85/350\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.2067 - accuracy: 0.7443 - val_loss: 0.2073 - val_accuracy: 0.7208\n",
      "Epoch 86/350\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.2062 - accuracy: 0.7443 - val_loss: 0.2069 - val_accuracy: 0.7273\n",
      "Epoch 87/350\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.2058 - accuracy: 0.7443 - val_loss: 0.2066 - val_accuracy: 0.7208\n",
      "Epoch 88/350\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.2053 - accuracy: 0.7443 - val_loss: 0.2063 - val_accuracy: 0.7208\n",
      "Epoch 89/350\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.2048 - accuracy: 0.7443 - val_loss: 0.2060 - val_accuracy: 0.7338\n",
      "Epoch 90/350\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.2044 - accuracy: 0.7410 - val_loss: 0.2056 - val_accuracy: 0.7403\n",
      "Epoch 91/350\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.2040 - accuracy: 0.7427 - val_loss: 0.2053 - val_accuracy: 0.7403\n",
      "Epoch 92/350\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.2035 - accuracy: 0.7410 - val_loss: 0.2051 - val_accuracy: 0.7338\n",
      "Epoch 93/350\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.2031 - accuracy: 0.7427 - val_loss: 0.2050 - val_accuracy: 0.7403\n",
      "Epoch 94/350\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.2027 - accuracy: 0.7427 - val_loss: 0.2050 - val_accuracy: 0.7403\n",
      "Epoch 95/350\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.2023 - accuracy: 0.7443 - val_loss: 0.2045 - val_accuracy: 0.7403\n",
      "Epoch 96/350\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.2019 - accuracy: 0.7476 - val_loss: 0.2041 - val_accuracy: 0.7403\n",
      "Epoch 97/350\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.2014 - accuracy: 0.7476 - val_loss: 0.2038 - val_accuracy: 0.7403\n",
      "Epoch 98/350\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.2010 - accuracy: 0.7476 - val_loss: 0.2038 - val_accuracy: 0.7532\n",
      "Epoch 99/350\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.2006 - accuracy: 0.7524 - val_loss: 0.2034 - val_accuracy: 0.7468\n",
      "Epoch 100/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.2002 - accuracy: 0.7508 - val_loss: 0.2032 - val_accuracy: 0.7532\n",
      "Epoch 101/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1999 - accuracy: 0.7492 - val_loss: 0.2029 - val_accuracy: 0.7597\n",
      "Epoch 102/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1994 - accuracy: 0.7508 - val_loss: 0.2024 - val_accuracy: 0.7532\n",
      "Epoch 103/350\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1991 - accuracy: 0.7590 - val_loss: 0.2020 - val_accuracy: 0.7468\n",
      "Epoch 104/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1988 - accuracy: 0.7492 - val_loss: 0.2025 - val_accuracy: 0.7532\n",
      "Epoch 105/350\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.1985 - accuracy: 0.7524 - val_loss: 0.2018 - val_accuracy: 0.7532\n",
      "Epoch 106/350\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1980 - accuracy: 0.7557 - val_loss: 0.2018 - val_accuracy: 0.7597\n",
      "Epoch 107/350\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.1976 - accuracy: 0.7606 - val_loss: 0.2018 - val_accuracy: 0.7532\n",
      "Epoch 108/350\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1973 - accuracy: 0.7590 - val_loss: 0.2020 - val_accuracy: 0.7468\n",
      "Epoch 109/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1968 - accuracy: 0.7524 - val_loss: 0.2007 - val_accuracy: 0.7532\n",
      "Epoch 110/350\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1968 - accuracy: 0.7557 - val_loss: 0.2008 - val_accuracy: 0.7468\n",
      "Epoch 111/350\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1962 - accuracy: 0.7655 - val_loss: 0.2013 - val_accuracy: 0.7468\n",
      "Epoch 112/350\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.1961 - accuracy: 0.7557 - val_loss: 0.2002 - val_accuracy: 0.7468\n",
      "Epoch 113/350\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1960 - accuracy: 0.7590 - val_loss: 0.1998 - val_accuracy: 0.7468\n",
      "Epoch 114/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1955 - accuracy: 0.7622 - val_loss: 0.1997 - val_accuracy: 0.7403\n",
      "Epoch 115/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 1s 12ms/step - loss: 0.1952 - accuracy: 0.7655 - val_loss: 0.1997 - val_accuracy: 0.7468\n",
      "Epoch 116/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1948 - accuracy: 0.7638 - val_loss: 0.1997 - val_accuracy: 0.7468\n",
      "Epoch 117/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1946 - accuracy: 0.7622 - val_loss: 0.1996 - val_accuracy: 0.7468\n",
      "Epoch 118/350\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.1942 - accuracy: 0.7590 - val_loss: 0.1987 - val_accuracy: 0.7468\n",
      "Epoch 119/350\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.1940 - accuracy: 0.7590 - val_loss: 0.1983 - val_accuracy: 0.7468\n",
      "Epoch 120/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1935 - accuracy: 0.7655 - val_loss: 0.1987 - val_accuracy: 0.7468\n",
      "Epoch 121/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1934 - accuracy: 0.7573 - val_loss: 0.1984 - val_accuracy: 0.7468\n",
      "Epoch 122/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1933 - accuracy: 0.7606 - val_loss: 0.1979 - val_accuracy: 0.7532\n",
      "Epoch 123/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1929 - accuracy: 0.7655 - val_loss: 0.1978 - val_accuracy: 0.7532\n",
      "Epoch 124/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1925 - accuracy: 0.7622 - val_loss: 0.1975 - val_accuracy: 0.7532\n",
      "Epoch 125/350\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.1925 - accuracy: 0.7622 - val_loss: 0.1974 - val_accuracy: 0.7532\n",
      "Epoch 126/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1922 - accuracy: 0.7736 - val_loss: 0.1975 - val_accuracy: 0.7468\n",
      "Epoch 127/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1920 - accuracy: 0.7492 - val_loss: 0.1974 - val_accuracy: 0.7468\n",
      "Epoch 128/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1914 - accuracy: 0.7557 - val_loss: 0.1965 - val_accuracy: 0.7532\n",
      "Epoch 129/350\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.1914 - accuracy: 0.7590 - val_loss: 0.1966 - val_accuracy: 0.7532\n",
      "Epoch 130/350\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.1910 - accuracy: 0.7655 - val_loss: 0.1970 - val_accuracy: 0.7403\n",
      "Epoch 131/350\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1908 - accuracy: 0.7638 - val_loss: 0.1959 - val_accuracy: 0.7532\n",
      "Epoch 132/350\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.1907 - accuracy: 0.7687 - val_loss: 0.1960 - val_accuracy: 0.7532\n",
      "Epoch 133/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1903 - accuracy: 0.7606 - val_loss: 0.1956 - val_accuracy: 0.7532\n",
      "Epoch 134/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1902 - accuracy: 0.7655 - val_loss: 0.1956 - val_accuracy: 0.7468\n",
      "Epoch 135/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1898 - accuracy: 0.7720 - val_loss: 0.1952 - val_accuracy: 0.7532\n",
      "Epoch 136/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1899 - accuracy: 0.7606 - val_loss: 0.1952 - val_accuracy: 0.7532\n",
      "Epoch 137/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1896 - accuracy: 0.7606 - val_loss: 0.1947 - val_accuracy: 0.7532\n",
      "Epoch 138/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1894 - accuracy: 0.7606 - val_loss: 0.1947 - val_accuracy: 0.7532\n",
      "Epoch 139/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1892 - accuracy: 0.7638 - val_loss: 0.1947 - val_accuracy: 0.7532\n",
      "Epoch 140/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1888 - accuracy: 0.7622 - val_loss: 0.1943 - val_accuracy: 0.7468\n",
      "Epoch 141/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1887 - accuracy: 0.7704 - val_loss: 0.1944 - val_accuracy: 0.7468\n",
      "Epoch 142/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1882 - accuracy: 0.7655 - val_loss: 0.1939 - val_accuracy: 0.7532\n",
      "Epoch 143/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1880 - accuracy: 0.7590 - val_loss: 0.1943 - val_accuracy: 0.7468\n",
      "Epoch 144/350\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1880 - accuracy: 0.7671 - val_loss: 0.1950 - val_accuracy: 0.7273\n",
      "Epoch 145/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1880 - accuracy: 0.7606 - val_loss: 0.1936 - val_accuracy: 0.7468\n",
      "Epoch 146/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1877 - accuracy: 0.7671 - val_loss: 0.1932 - val_accuracy: 0.7532\n",
      "Epoch 147/350\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.1874 - accuracy: 0.7687 - val_loss: 0.1931 - val_accuracy: 0.7532\n",
      "Epoch 148/350\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.1874 - accuracy: 0.7704 - val_loss: 0.1936 - val_accuracy: 0.7338\n",
      "Epoch 149/350\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.1874 - accuracy: 0.7573 - val_loss: 0.1928 - val_accuracy: 0.7468\n",
      "Epoch 150/350\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.1869 - accuracy: 0.7720 - val_loss: 0.1932 - val_accuracy: 0.7403\n",
      "Epoch 151/350\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.1869 - accuracy: 0.7720 - val_loss: 0.1927 - val_accuracy: 0.7468\n",
      "Epoch 152/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1863 - accuracy: 0.7785 - val_loss: 0.1923 - val_accuracy: 0.7532\n",
      "Epoch 153/350\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.1863 - accuracy: 0.7736 - val_loss: 0.1922 - val_accuracy: 0.7468\n",
      "Epoch 154/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1865 - accuracy: 0.7638 - val_loss: 0.1923 - val_accuracy: 0.7468\n",
      "Epoch 155/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1862 - accuracy: 0.7687 - val_loss: 0.1919 - val_accuracy: 0.7532\n",
      "Epoch 156/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1860 - accuracy: 0.7687 - val_loss: 0.1917 - val_accuracy: 0.7468\n",
      "Epoch 157/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1857 - accuracy: 0.7736 - val_loss: 0.1914 - val_accuracy: 0.7532\n",
      "Epoch 158/350\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1856 - accuracy: 0.7704 - val_loss: 0.1913 - val_accuracy: 0.7532\n",
      "Epoch 159/350\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.1853 - accuracy: 0.7687 - val_loss: 0.1915 - val_accuracy: 0.7468\n",
      "Epoch 160/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1855 - accuracy: 0.7687 - val_loss: 0.1915 - val_accuracy: 0.7468\n",
      "Epoch 161/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1848 - accuracy: 0.7752 - val_loss: 0.1922 - val_accuracy: 0.7403\n",
      "Epoch 162/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1851 - accuracy: 0.7752 - val_loss: 0.1912 - val_accuracy: 0.7532\n",
      "Epoch 163/350\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.1851 - accuracy: 0.7638 - val_loss: 0.1910 - val_accuracy: 0.7532ss: 0.1907 - accuracy\n",
      "Epoch 164/350\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1846 - accuracy: 0.7638 - val_loss: 0.1904 - val_accuracy: 0.7532\n",
      "Epoch 165/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1845 - accuracy: 0.7704 - val_loss: 0.1909 - val_accuracy: 0.7468\n",
      "Epoch 166/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1845 - accuracy: 0.7720 - val_loss: 0.1901 - val_accuracy: 0.7532\n",
      "Epoch 167/350\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1842 - accuracy: 0.7720 - val_loss: 0.1905 - val_accuracy: 0.7468\n",
      "Epoch 168/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1843 - accuracy: 0.7720 - val_loss: 0.1904 - val_accuracy: 0.7532\n",
      "Epoch 169/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1842 - accuracy: 0.7687 - val_loss: 0.1901 - val_accuracy: 0.7468\n",
      "Epoch 170/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1831 - accuracy: 0.7785 - val_loss: 0.1897 - val_accuracy: 0.7468\n",
      "Epoch 171/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1840 - accuracy: 0.7638 - val_loss: 0.1892 - val_accuracy: 0.7532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/350\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.1837 - accuracy: 0.7655 - val_loss: 0.1899 - val_accuracy: 0.7468\n",
      "Epoch 173/350\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.1835 - accuracy: 0.7720 - val_loss: 0.1894 - val_accuracy: 0.7532\n",
      "Epoch 174/350\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.1835 - accuracy: 0.7655 - val_loss: 0.1893 - val_accuracy: 0.7532\n",
      "Epoch 175/350\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.1831 - accuracy: 0.7736 - val_loss: 0.1893 - val_accuracy: 0.7532\n",
      "Epoch 176/350\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.1831 - accuracy: 0.7736 - val_loss: 0.1889 - val_accuracy: 0.7532\n",
      "Epoch 177/350\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.1831 - accuracy: 0.7671 - val_loss: 0.1886 - val_accuracy: 0.7532\n",
      "Epoch 178/350\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.1829 - accuracy: 0.7687 - val_loss: 0.1886 - val_accuracy: 0.7532\n",
      "Epoch 179/350\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.1828 - accuracy: 0.7655 - val_loss: 0.1881 - val_accuracy: 0.7532\n",
      "Epoch 180/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1824 - accuracy: 0.7671 - val_loss: 0.1881 - val_accuracy: 0.7532\n",
      "Epoch 181/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1825 - accuracy: 0.7704 - val_loss: 0.1880 - val_accuracy: 0.7532\n",
      "Epoch 182/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1822 - accuracy: 0.7752 - val_loss: 0.1879 - val_accuracy: 0.7532\n",
      "Epoch 183/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1825 - accuracy: 0.7736 - val_loss: 0.1885 - val_accuracy: 0.7532\n",
      "Epoch 184/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1821 - accuracy: 0.7704 - val_loss: 0.1890 - val_accuracy: 0.7403\n",
      "Epoch 185/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1818 - accuracy: 0.7638 - val_loss: 0.1878 - val_accuracy: 0.7532\n",
      "Epoch 186/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1820 - accuracy: 0.7557 - val_loss: 0.1876 - val_accuracy: 0.7532\n",
      "Epoch 187/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1818 - accuracy: 0.7704 - val_loss: 0.1877 - val_accuracy: 0.7532\n",
      "Epoch 188/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1819 - accuracy: 0.7736 - val_loss: 0.1876 - val_accuracy: 0.7597\n",
      "Epoch 189/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1818 - accuracy: 0.7704 - val_loss: 0.1872 - val_accuracy: 0.7532\n",
      "Epoch 190/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1814 - accuracy: 0.7671 - val_loss: 0.1871 - val_accuracy: 0.7532\n",
      "Epoch 191/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1813 - accuracy: 0.7671 - val_loss: 0.1881 - val_accuracy: 0.7403\n",
      "Epoch 192/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1814 - accuracy: 0.7655 - val_loss: 0.1869 - val_accuracy: 0.7597\n",
      "Epoch 193/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1812 - accuracy: 0.7590 - val_loss: 0.1866 - val_accuracy: 0.7532\n",
      "Epoch 194/350\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.1809 - accuracy: 0.7671 - val_loss: 0.1867 - val_accuracy: 0.7597\n",
      "Epoch 195/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1809 - accuracy: 0.7655 - val_loss: 0.1869 - val_accuracy: 0.7468\n",
      "Epoch 196/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1809 - accuracy: 0.7687 - val_loss: 0.1876 - val_accuracy: 0.7403\n",
      "Epoch 197/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1802 - accuracy: 0.7655 - val_loss: 0.1862 - val_accuracy: 0.7532\n",
      "Epoch 198/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1806 - accuracy: 0.7752 - val_loss: 0.1872 - val_accuracy: 0.7403\n",
      "Epoch 199/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1805 - accuracy: 0.7720 - val_loss: 0.1862 - val_accuracy: 0.7597\n",
      "Epoch 200/350\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.1809 - accuracy: 0.7638 - val_loss: 0.1867 - val_accuracy: 0.7403\n",
      "Epoch 201/350\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.1805 - accuracy: 0.7606 - val_loss: 0.1860 - val_accuracy: 0.7597\n",
      "Epoch 202/350\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.1804 - accuracy: 0.7671 - val_loss: 0.1856 - val_accuracy: 0.7532\n",
      "Epoch 203/350\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.1803 - accuracy: 0.7736 - val_loss: 0.1854 - val_accuracy: 0.7532\n",
      "Epoch 204/350\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.1801 - accuracy: 0.7736 - val_loss: 0.1857 - val_accuracy: 0.7468\n",
      "Epoch 205/350\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.1800 - accuracy: 0.7655 - val_loss: 0.1868 - val_accuracy: 0.7403\n",
      "Epoch 206/350\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.1793 - accuracy: 0.7671 - val_loss: 0.1880 - val_accuracy: 0.7468\n",
      "Epoch 207/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1799 - accuracy: 0.7687 - val_loss: 0.1854 - val_accuracy: 0.7532\n",
      "Epoch 208/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1795 - accuracy: 0.7752 - val_loss: 0.1850 - val_accuracy: 0.7597\n",
      "Epoch 209/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1796 - accuracy: 0.7720 - val_loss: 0.1855 - val_accuracy: 0.7403\n",
      "Epoch 210/350\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1795 - accuracy: 0.7769 - val_loss: 0.1851 - val_accuracy: 0.7532\n",
      "Epoch 211/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1795 - accuracy: 0.7704 - val_loss: 0.1856 - val_accuracy: 0.7403\n",
      "Epoch 212/350\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1797 - accuracy: 0.7752 - val_loss: 0.1848 - val_accuracy: 0.7597\n",
      "Epoch 213/350\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1792 - accuracy: 0.7687 - val_loss: 0.1844 - val_accuracy: 0.7597\n",
      "Epoch 214/350\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.1781 - accuracy: 0.76 - 1s 10ms/step - loss: 0.1794 - accuracy: 0.7655 - val_loss: 0.1845 - val_accuracy: 0.7597\n",
      "Epoch 215/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1794 - accuracy: 0.7704 - val_loss: 0.1845 - val_accuracy: 0.7597\n",
      "Epoch 216/350\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1789 - accuracy: 0.7704 - val_loss: 0.1847 - val_accuracy: 0.7532\n",
      "Epoch 217/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1787 - accuracy: 0.7720 - val_loss: 0.1853 - val_accuracy: 0.7468\n",
      "Epoch 218/350\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1783 - accuracy: 0.7769 - val_loss: 0.1843 - val_accuracy: 0.7532\n",
      "Epoch 219/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1787 - accuracy: 0.7687 - val_loss: 0.1847 - val_accuracy: 0.7468\n",
      "Epoch 220/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1787 - accuracy: 0.7671 - val_loss: 0.1855 - val_accuracy: 0.7532\n",
      "Epoch 221/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1786 - accuracy: 0.7736 - val_loss: 0.1842 - val_accuracy: 0.7532\n",
      "Epoch 222/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1786 - accuracy: 0.7704 - val_loss: 0.1837 - val_accuracy: 0.7662\n",
      "Epoch 223/350\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.1786 - accuracy: 0.7638 - val_loss: 0.1835 - val_accuracy: 0.7662\n",
      "Epoch 224/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1784 - accuracy: 0.7687 - val_loss: 0.1838 - val_accuracy: 0.7597\n",
      "Epoch 225/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1784 - accuracy: 0.7655 - val_loss: 0.1839 - val_accuracy: 0.7532\n",
      "Epoch 226/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1782 - accuracy: 0.7736 - val_loss: 0.1853 - val_accuracy: 0.7532\n",
      "Epoch 227/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1777 - accuracy: 0.7720 - val_loss: 0.1832 - val_accuracy: 0.7597\n",
      "Epoch 228/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1780 - accuracy: 0.7704 - val_loss: 0.1832 - val_accuracy: 0.7662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1775 - accuracy: 0.7687 - val_loss: 0.1837 - val_accuracy: 0.7403\n",
      "Epoch 230/350\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.1768 - accuracy: 0.7638 - val_loss: 0.1874 - val_accuracy: 0.7403\n",
      "Epoch 231/350\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.1777 - accuracy: 0.7769 - val_loss: 0.1846 - val_accuracy: 0.7532\n",
      "Epoch 232/350\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1776 - accuracy: 0.7736 - val_loss: 0.1832 - val_accuracy: 0.7468\n",
      "Epoch 233/350\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.1773 - accuracy: 0.7704 - val_loss: 0.1828 - val_accuracy: 0.7597\n",
      "Epoch 234/350\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.1777 - accuracy: 0.7655 - val_loss: 0.1838 - val_accuracy: 0.7468\n",
      "Epoch 235/350\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.1770 - accuracy: 0.7736 - val_loss: 0.1828 - val_accuracy: 0.7597\n",
      "Epoch 236/350\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.1767 - accuracy: 0.7801 - val_loss: 0.1851 - val_accuracy: 0.7468\n",
      "Epoch 237/350\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.1772 - accuracy: 0.7704 - val_loss: 0.1828 - val_accuracy: 0.7468\n",
      "Epoch 238/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1766 - accuracy: 0.7687 - val_loss: 0.1825 - val_accuracy: 0.7597\n",
      "Epoch 239/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1772 - accuracy: 0.7687 - val_loss: 0.1826 - val_accuracy: 0.7662\n",
      "Epoch 240/350\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.1773 - accuracy: 0.76 - 1s 9ms/step - loss: 0.1777 - accuracy: 0.7687 - val_loss: 0.1825 - val_accuracy: 0.7662\n",
      "Epoch 241/350\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.1784 - accuracy: 0.76 - 1s 11ms/step - loss: 0.1776 - accuracy: 0.7655 - val_loss: 0.1823 - val_accuracy: 0.7662\n",
      "Epoch 242/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1768 - accuracy: 0.7736 - val_loss: 0.1826 - val_accuracy: 0.7403\n",
      "Epoch 243/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1772 - accuracy: 0.7736 - val_loss: 0.1847 - val_accuracy: 0.7403\n",
      "Epoch 244/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1767 - accuracy: 0.7752 - val_loss: 0.1825 - val_accuracy: 0.7662\n",
      "Epoch 245/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1774 - accuracy: 0.7687 - val_loss: 0.1822 - val_accuracy: 0.7468\n",
      "Epoch 246/350\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.1767 - accuracy: 0.7736 - val_loss: 0.1820 - val_accuracy: 0.7597\n",
      "Epoch 247/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1767 - accuracy: 0.7704 - val_loss: 0.1819 - val_accuracy: 0.7597\n",
      "Epoch 248/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1768 - accuracy: 0.7655 - val_loss: 0.1824 - val_accuracy: 0.7532\n",
      "Epoch 249/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1766 - accuracy: 0.7769 - val_loss: 0.1831 - val_accuracy: 0.7532\n",
      "Epoch 250/350\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.1765 - accuracy: 0.7736 - val_loss: 0.1842 - val_accuracy: 0.7403\n",
      "Epoch 251/350\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.1771 - accuracy: 0.7655 - val_loss: 0.1833 - val_accuracy: 0.7532\n",
      "Epoch 252/350\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.1767 - accuracy: 0.7606 - val_loss: 0.1815 - val_accuracy: 0.7662\n",
      "Epoch 253/350\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.1757 - accuracy: 0.7769 - val_loss: 0.1844 - val_accuracy: 0.7403\n",
      "Epoch 254/350\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.1764 - accuracy: 0.7720 - val_loss: 0.1818 - val_accuracy: 0.7532\n",
      "Epoch 255/350\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.1761 - accuracy: 0.7704 - val_loss: 0.1813 - val_accuracy: 0.7532\n",
      "Epoch 256/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1756 - accuracy: 0.7720 - val_loss: 0.1825 - val_accuracy: 0.7532\n",
      "Epoch 257/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1769 - accuracy: 0.7752 - val_loss: 0.1810 - val_accuracy: 0.7597\n",
      "Epoch 258/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1762 - accuracy: 0.7704 - val_loss: 0.1807 - val_accuracy: 0.7662\n",
      "Epoch 259/350\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1761 - accuracy: 0.7720 - val_loss: 0.1807 - val_accuracy: 0.7662\n",
      "Epoch 260/350\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.1764 - accuracy: 0.7704 - val_loss: 0.1812 - val_accuracy: 0.7468\n",
      "Epoch 261/350\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.1757 - accuracy: 0.7638 - val_loss: 0.1805 - val_accuracy: 0.7662\n",
      "Epoch 262/350\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.1754 - accuracy: 0.7752 - val_loss: 0.1833 - val_accuracy: 0.7403\n",
      "Epoch 263/350\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.1762 - accuracy: 0.7769 - val_loss: 0.1814 - val_accuracy: 0.7597\n",
      "Epoch 264/350\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.1754 - accuracy: 0.7687 - val_loss: 0.1805 - val_accuracy: 0.7662\n",
      "Epoch 265/350\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1758 - accuracy: 0.7655 - val_loss: 0.1807 - val_accuracy: 0.7468\n",
      "Epoch 266/350\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1753 - accuracy: 0.7687 - val_loss: 0.1809 - val_accuracy: 0.7597\n",
      "Epoch 267/350\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1760 - accuracy: 0.7655 - val_loss: 0.1805 - val_accuracy: 0.7662\n",
      "Epoch 268/350\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1756 - accuracy: 0.7704 - val_loss: 0.1814 - val_accuracy: 0.7403\n",
      "Epoch 269/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1754 - accuracy: 0.7720 - val_loss: 0.1809 - val_accuracy: 0.7532\n",
      "Epoch 270/350\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.1750 - accuracy: 0.7752 - val_loss: 0.1811 - val_accuracy: 0.7597\n",
      "Epoch 271/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1758 - accuracy: 0.7622 - val_loss: 0.1804 - val_accuracy: 0.7532\n",
      "Epoch 272/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1753 - accuracy: 0.7752 - val_loss: 0.1801 - val_accuracy: 0.7662\n",
      "Epoch 273/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1757 - accuracy: 0.7687 - val_loss: 0.1810 - val_accuracy: 0.7468\n",
      "Epoch 274/350\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.1751 - accuracy: 0.7752 - val_loss: 0.1805 - val_accuracy: 0.7532\n",
      "Epoch 275/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1758 - accuracy: 0.7704 - val_loss: 0.1800 - val_accuracy: 0.7662\n",
      "Epoch 276/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1745 - accuracy: 0.7769 - val_loss: 0.1845 - val_accuracy: 0.7338\n",
      "Epoch 277/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1750 - accuracy: 0.7801 - val_loss: 0.1801 - val_accuracy: 0.7532\n",
      "Epoch 278/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1750 - accuracy: 0.7704 - val_loss: 0.1805 - val_accuracy: 0.7468\n",
      "Epoch 279/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1745 - accuracy: 0.7785 - val_loss: 0.1816 - val_accuracy: 0.7403\n",
      "Epoch 280/350\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1750 - accuracy: 0.7655 - val_loss: 0.1808 - val_accuracy: 0.7532\n",
      "Epoch 281/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1748 - accuracy: 0.7785 - val_loss: 0.1799 - val_accuracy: 0.7532\n",
      "Epoch 282/350\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.1748 - accuracy: 0.7720 - val_loss: 0.1799 - val_accuracy: 0.7597\n",
      "Epoch 283/350\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.1749 - accuracy: 0.7801 - val_loss: 0.1796 - val_accuracy: 0.7662\n",
      "Epoch 284/350\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.1743 - accuracy: 0.7687 - val_loss: 0.1831 - val_accuracy: 0.7338\n",
      "Epoch 285/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 1s 13ms/step - loss: 0.1744 - accuracy: 0.7769 - val_loss: 0.1796 - val_accuracy: 0.7532\n",
      "Epoch 286/350\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1751 - accuracy: 0.7638 - val_loss: 0.1800 - val_accuracy: 0.7532\n",
      "Epoch 287/350\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1744 - accuracy: 0.7687 - val_loss: 0.1800 - val_accuracy: 0.7597\n",
      "Epoch 288/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1745 - accuracy: 0.7785 - val_loss: 0.1798 - val_accuracy: 0.7468\n",
      "Epoch 289/350\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1738 - accuracy: 0.7720 - val_loss: 0.1803 - val_accuracy: 0.7468\n",
      "Epoch 290/350\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1736 - accuracy: 0.7818 - val_loss: 0.1811 - val_accuracy: 0.7468\n",
      "Epoch 291/350\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.1744 - accuracy: 0.7752 - val_loss: 0.1795 - val_accuracy: 0.7532\n",
      "Epoch 292/350\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.1746 - accuracy: 0.7671 - val_loss: 0.1794 - val_accuracy: 0.7532\n",
      "Epoch 293/350\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.1744 - accuracy: 0.7720 - val_loss: 0.1794 - val_accuracy: 0.7597\n",
      "Epoch 294/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1744 - accuracy: 0.7704 - val_loss: 0.1795 - val_accuracy: 0.7532\n",
      "Epoch 295/350\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1733 - accuracy: 0.7752 - val_loss: 0.1796 - val_accuracy: 0.7662\n",
      "Epoch 296/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1746 - accuracy: 0.7736 - val_loss: 0.1789 - val_accuracy: 0.7662\n",
      "Epoch 297/350\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1734 - accuracy: 0.7769 - val_loss: 0.1788 - val_accuracy: 0.7727\n",
      "Epoch 298/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1729 - accuracy: 0.7752 - val_loss: 0.1877 - val_accuracy: 0.7273\n",
      "Epoch 299/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1743 - accuracy: 0.7736 - val_loss: 0.1827 - val_accuracy: 0.7273\n",
      "Epoch 300/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1742 - accuracy: 0.7655 - val_loss: 0.1796 - val_accuracy: 0.7468\n",
      "Epoch 301/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1737 - accuracy: 0.7704 - val_loss: 0.1802 - val_accuracy: 0.7532\n",
      "Epoch 302/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1739 - accuracy: 0.7736 - val_loss: 0.1797 - val_accuracy: 0.7597\n",
      "Epoch 303/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1735 - accuracy: 0.7704 - val_loss: 0.1795 - val_accuracy: 0.7532\n",
      "Epoch 304/350\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1735 - accuracy: 0.7736 - val_loss: 0.1784 - val_accuracy: 0.7597\n",
      "Epoch 305/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1746 - accuracy: 0.7785 - val_loss: 0.1790 - val_accuracy: 0.7597\n",
      "Epoch 306/350\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1717 - accuracy: 0.7850 - val_loss: 0.1781 - val_accuracy: 0.7532\n",
      "Epoch 307/350\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.1736 - accuracy: 0.7720 - val_loss: 0.1780 - val_accuracy: 0.7662\n",
      "Epoch 308/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1734 - accuracy: 0.7736 - val_loss: 0.1791 - val_accuracy: 0.7532\n",
      "Epoch 309/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1731 - accuracy: 0.7655 - val_loss: 0.1782 - val_accuracy: 0.7532\n",
      "Epoch 310/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1731 - accuracy: 0.7769 - val_loss: 0.1795 - val_accuracy: 0.7532\n",
      "Epoch 311/350\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1728 - accuracy: 0.7769 - val_loss: 0.1779 - val_accuracy: 0.7792\n",
      "Epoch 312/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1740 - accuracy: 0.7736 - val_loss: 0.1780 - val_accuracy: 0.7792\n",
      "Epoch 313/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1739 - accuracy: 0.7720 - val_loss: 0.1783 - val_accuracy: 0.7532\n",
      "Epoch 314/350\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1733 - accuracy: 0.7752 - val_loss: 0.1782 - val_accuracy: 0.7662\n",
      "Epoch 315/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1730 - accuracy: 0.7818 - val_loss: 0.1780 - val_accuracy: 0.7792\n",
      "Epoch 316/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1728 - accuracy: 0.7704 - val_loss: 0.1832 - val_accuracy: 0.7143\n",
      "Epoch 317/350\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.1694 - accuracy: 0.78 - 1s 9ms/step - loss: 0.1734 - accuracy: 0.7801 - val_loss: 0.1781 - val_accuracy: 0.7727\n",
      "Epoch 318/350\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1728 - accuracy: 0.7801 - val_loss: 0.1782 - val_accuracy: 0.7597\n",
      "Epoch 319/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1726 - accuracy: 0.7834 - val_loss: 0.1775 - val_accuracy: 0.7597\n",
      "Epoch 320/350\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.1732 - accuracy: 0.77 - 1s 10ms/step - loss: 0.1734 - accuracy: 0.7752 - val_loss: 0.1779 - val_accuracy: 0.7532\n",
      "Epoch 321/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1731 - accuracy: 0.7785 - val_loss: 0.1779 - val_accuracy: 0.7597\n",
      "Epoch 322/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1728 - accuracy: 0.7704 - val_loss: 0.1782 - val_accuracy: 0.7662\n",
      "Epoch 323/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1729 - accuracy: 0.7671 - val_loss: 0.1778 - val_accuracy: 0.7662\n",
      "Epoch 324/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1729 - accuracy: 0.7736 - val_loss: 0.1774 - val_accuracy: 0.7597\n",
      "Epoch 325/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1725 - accuracy: 0.7704 - val_loss: 0.1781 - val_accuracy: 0.7468\n",
      "Epoch 326/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1720 - accuracy: 0.7769 - val_loss: 0.1788 - val_accuracy: 0.7468\n",
      "Epoch 327/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1732 - accuracy: 0.7752 - val_loss: 0.1774 - val_accuracy: 0.7727\n",
      "Epoch 328/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1721 - accuracy: 0.7834 - val_loss: 0.1771 - val_accuracy: 0.7597\n",
      "Epoch 329/350\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1725 - accuracy: 0.7769 - val_loss: 0.1813 - val_accuracy: 0.7338\n",
      "Epoch 330/350\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.1727 - accuracy: 0.7866 - val_loss: 0.1793 - val_accuracy: 0.7468\n",
      "Epoch 331/350\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.1724 - accuracy: 0.7622 - val_loss: 0.1782 - val_accuracy: 0.7532\n",
      "Epoch 332/350\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.1729 - accuracy: 0.7704 - val_loss: 0.1770 - val_accuracy: 0.7857\n",
      "Epoch 333/350\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.1722 - accuracy: 0.7687 - val_loss: 0.1769 - val_accuracy: 0.7662\n",
      "Epoch 334/350\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.1720 - accuracy: 0.7818 - val_loss: 0.1793 - val_accuracy: 0.7403\n",
      "Epoch 335/350\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1716 - accuracy: 0.7834 - val_loss: 0.1778 - val_accuracy: 0.7857\n",
      "Epoch 336/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1721 - accuracy: 0.7752 - val_loss: 0.1778 - val_accuracy: 0.7468\n",
      "Epoch 337/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1721 - accuracy: 0.7704 - val_loss: 0.1776 - val_accuracy: 0.7597\n",
      "Epoch 338/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1727 - accuracy: 0.7801 - val_loss: 0.1768 - val_accuracy: 0.7662\n",
      "Epoch 339/350\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.1718 - accuracy: 0.7736 - val_loss: 0.1762 - val_accuracy: 0.7597\n",
      "Epoch 340/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1719 - accuracy: 0.7801 - val_loss: 0.1777 - val_accuracy: 0.7532\n",
      "Epoch 341/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1726 - accuracy: 0.7801 - val_loss: 0.1770 - val_accuracy: 0.7662\n",
      "Epoch 342/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1720 - accuracy: 0.7769 - val_loss: 0.1764 - val_accuracy: 0.7727\n",
      "Epoch 343/350\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.1723 - accuracy: 0.7736 - val_loss: 0.1769 - val_accuracy: 0.7532\n",
      "Epoch 344/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1722 - accuracy: 0.7850 - val_loss: 0.1765 - val_accuracy: 0.7727\n",
      "Epoch 345/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1714 - accuracy: 0.7785 - val_loss: 0.1773 - val_accuracy: 0.7597\n",
      "Epoch 346/350\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.1719 - accuracy: 0.7655 - val_loss: 0.1766 - val_accuracy: 0.7727\n",
      "Epoch 347/350\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.1716 - accuracy: 0.7801 - val_loss: 0.1768 - val_accuracy: 0.7597\n",
      "Epoch 348/350\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.1713 - accuracy: 0.7769 - val_loss: 0.1831 - val_accuracy: 0.7208\n",
      "Epoch 349/350\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.1724 - accuracy: 0.7736 - val_loss: 0.1772 - val_accuracy: 0.7857\n",
      "Epoch 350/350\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.1721 - accuracy: 0.7720 - val_loss: 0.1770 - val_accuracy: 0.7662\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.1770 - accuracy: 0.7662\n",
      "Test Accuracy: 0.7662\n"
     ]
    }
   ],
   "source": [
    "#CNN: 1 convolution layer - 1 Pooling - MLP  \"avec sgd optimizer\"\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, Flatten, Dropout, MaxPooling1D\n",
    "from keras import regularizers\n",
    "import keras\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "model_cnn = Sequential()\n",
    "\n",
    "model_cnn.add(Conv1D(16, kernel_size=2, activation='relu', input_shape=(8,1), data_format = 'channels_last'))\n",
    "\n",
    "model_cnn.add(Conv1D(32, kernel_size=2, strides=1, activation='relu'))\n",
    "model_cnn.add(Conv1D(32, kernel_size=2, strides=1, activation='relu'))\n",
    "model_cnn.add(MaxPooling1D(pool_size=2, padding='same'))\n",
    "model_cnn.add(Flatten())\n",
    "model_cnn.add(Dense(3, kernel_regularizer=regularizers.l2(0.04), activation='relu'))\n",
    "\n",
    "model_cnn.add(Dense(1, kernel_regularizer=regularizers.l2(0.02), activation='sigmoid'))\n",
    "\n",
    "model_cnn.compile(optimizer='sgd', loss='mse', metrics=['accuracy'])\n",
    "\n",
    "history=model_cnn.fit(X_train, y_train, batch_size=10, epochs=350,validation_data=(X_test, y_test))\n",
    "    \n",
    "loss, accuracy = model_cnn.evaluate(X_test, y_test, batch_size=None, verbose=1)\n",
    "print(\"Test Accuracy: {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d52fc0c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 1.7778 - accuracy: 0.6678 - val_loss: 1.3863 - val_accuracy: 0.7987\n",
      "Epoch 2/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 1.1706 - accuracy: 0.7590 - val_loss: 0.9607 - val_accuracy: 0.7727\n",
      "Epoch 3/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.8578 - accuracy: 0.7655 - val_loss: 0.7474 - val_accuracy: 0.7727\n",
      "Epoch 4/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.7055 - accuracy: 0.7671 - val_loss: 0.6460 - val_accuracy: 0.7792\n",
      "Epoch 5/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.6286 - accuracy: 0.7704 - val_loss: 0.6027 - val_accuracy: 0.7403\n",
      "Epoch 6/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.5912 - accuracy: 0.7704 - val_loss: 0.5734 - val_accuracy: 0.7468\n",
      "Epoch 7/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.5715 - accuracy: 0.7752 - val_loss: 0.5550 - val_accuracy: 0.7468\n",
      "Epoch 8/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.5594 - accuracy: 0.7818 - val_loss: 0.5499 - val_accuracy: 0.7662\n",
      "Epoch 9/300\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.5511 - accuracy: 0.7785 - val_loss: 0.5394 - val_accuracy: 0.7597\n",
      "Epoch 10/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.5472 - accuracy: 0.7801 - val_loss: 0.5365 - val_accuracy: 0.7532\n",
      "Epoch 11/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.5429 - accuracy: 0.7704 - val_loss: 0.5378 - val_accuracy: 0.7403\n",
      "Epoch 12/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.5409 - accuracy: 0.7687 - val_loss: 0.5341 - val_accuracy: 0.7532\n",
      "Epoch 13/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.5397 - accuracy: 0.7736 - val_loss: 0.5309 - val_accuracy: 0.7468\n",
      "Epoch 14/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.5388 - accuracy: 0.7704 - val_loss: 0.5349 - val_accuracy: 0.7403\n",
      "Epoch 15/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.5349 - accuracy: 0.7834 - val_loss: 0.5355 - val_accuracy: 0.7403\n",
      "Epoch 16/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.5331 - accuracy: 0.7769 - val_loss: 0.5219 - val_accuracy: 0.7727\n",
      "Epoch 17/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.5285 - accuracy: 0.7932 - val_loss: 0.5415 - val_accuracy: 0.7403\n",
      "Epoch 18/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.5355 - accuracy: 0.7704 - val_loss: 0.5194 - val_accuracy: 0.7922\n",
      "Epoch 19/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.5301 - accuracy: 0.7834 - val_loss: 0.5249 - val_accuracy: 0.7727\n",
      "Epoch 20/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.5280 - accuracy: 0.7752 - val_loss: 0.5215 - val_accuracy: 0.7597\n",
      "Epoch 21/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.5284 - accuracy: 0.7834 - val_loss: 0.5237 - val_accuracy: 0.7857\n",
      "Epoch 22/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.5305 - accuracy: 0.7720 - val_loss: 0.5230 - val_accuracy: 0.7857\n",
      "Epoch 23/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.5296 - accuracy: 0.7752 - val_loss: 0.5182 - val_accuracy: 0.7792\n",
      "Epoch 24/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.5266 - accuracy: 0.7801 - val_loss: 0.5151 - val_accuracy: 0.7662\n",
      "Epoch 25/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.5219 - accuracy: 0.7769 - val_loss: 0.5199 - val_accuracy: 0.7727\n",
      "Epoch 26/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.5268 - accuracy: 0.7736 - val_loss: 0.5200 - val_accuracy: 0.7922\n",
      "Epoch 27/300\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.5207 - accuracy: 0.7736 - val_loss: 0.5229 - val_accuracy: 0.7468\n",
      "Epoch 28/300\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.5204 - accuracy: 0.7785 - val_loss: 0.5267 - val_accuracy: 0.7532\n",
      "Epoch 29/300\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.5189 - accuracy: 0.7785 - val_loss: 0.5125 - val_accuracy: 0.7662\n",
      "Epoch 30/300\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.5205 - accuracy: 0.7769 - val_loss: 0.5099 - val_accuracy: 0.7857\n",
      "Epoch 31/300\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.5258 - accuracy: 0.7834 - val_loss: 0.5197 - val_accuracy: 0.7662\n",
      "Epoch 32/300\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.5215 - accuracy: 0.7655 - val_loss: 0.5139 - val_accuracy: 0.7662\n",
      "Epoch 33/300\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.5191 - accuracy: 0.7801 - val_loss: 0.5119 - val_accuracy: 0.7727\n",
      "Epoch 34/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.5223 - accuracy: 0.7720 - val_loss: 0.5187 - val_accuracy: 0.7727\n",
      "Epoch 35/300\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.5160 - accuracy: 0.7736 - val_loss: 0.5141 - val_accuracy: 0.7857\n",
      "Epoch 36/300\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.5184 - accuracy: 0.7785 - val_loss: 0.5126 - val_accuracy: 0.7792\n",
      "Epoch 37/300\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.5157 - accuracy: 0.7801 - val_loss: 0.5149 - val_accuracy: 0.7532\n",
      "Epoch 38/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.5171 - accuracy: 0.7785 - val_loss: 0.5218 - val_accuracy: 0.7403\n",
      "Epoch 39/300\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.5185 - accuracy: 0.7655 - val_loss: 0.5087 - val_accuracy: 0.7662\n",
      "Epoch 40/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.5185 - accuracy: 0.7801 - val_loss: 0.5130 - val_accuracy: 0.7727\n",
      "Epoch 41/300\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.5137 - accuracy: 0.78 - 0s 7ms/step - loss: 0.5137 - accuracy: 0.7834 - val_loss: 0.5102 - val_accuracy: 0.7727\n",
      "Epoch 42/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.5130 - accuracy: 0.7752 - val_loss: 0.5132 - val_accuracy: 0.7662\n",
      "Epoch 43/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.5127 - accuracy: 0.7769 - val_loss: 0.5074 - val_accuracy: 0.7662\n",
      "Epoch 44/300\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.5110 - accuracy: 0.7834 - val_loss: 0.5111 - val_accuracy: 0.7922\n",
      "Epoch 45/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.5182 - accuracy: 0.7671 - val_loss: 0.5096 - val_accuracy: 0.7662\n",
      "Epoch 46/300\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.5142 - accuracy: 0.7834 - val_loss: 0.5094 - val_accuracy: 0.7532\n",
      "Epoch 47/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.5103 - accuracy: 0.7915 - val_loss: 0.5133 - val_accuracy: 0.7468\n",
      "Epoch 48/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.5118 - accuracy: 0.7850 - val_loss: 0.5025 - val_accuracy: 0.7727\n",
      "Epoch 49/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.5101 - accuracy: 0.7818 - val_loss: 0.5115 - val_accuracy: 0.7727\n",
      "Epoch 50/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.5116 - accuracy: 0.7785 - val_loss: 0.5158 - val_accuracy: 0.7468\n",
      "Epoch 51/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.5101 - accuracy: 0.7671 - val_loss: 0.5054 - val_accuracy: 0.7662\n",
      "Epoch 52/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.5104 - accuracy: 0.7866 - val_loss: 0.5238 - val_accuracy: 0.7403\n",
      "Epoch 53/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.5070 - accuracy: 0.7834 - val_loss: 0.5069 - val_accuracy: 0.7727\n",
      "Epoch 54/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.5086 - accuracy: 0.7736 - val_loss: 0.5096 - val_accuracy: 0.7727\n",
      "Epoch 55/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.5068 - accuracy: 0.7801 - val_loss: 0.5058 - val_accuracy: 0.7597\n",
      "Epoch 56/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.5060 - accuracy: 0.7818 - val_loss: 0.5040 - val_accuracy: 0.7857\n",
      "Epoch 57/300\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.5130 - accuracy: 0.7834 - val_loss: 0.5053 - val_accuracy: 0.7792\n",
      "Epoch 58/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 0s 8ms/step - loss: 0.5065 - accuracy: 0.7752 - val_loss: 0.5110 - val_accuracy: 0.7532\n",
      "Epoch 59/300\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.5044 - accuracy: 0.7818 - val_loss: 0.5083 - val_accuracy: 0.7727\n",
      "Epoch 60/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.5051 - accuracy: 0.7834 - val_loss: 0.5074 - val_accuracy: 0.7792\n",
      "Epoch 61/300\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.5038 - accuracy: 0.7883 - val_loss: 0.5036 - val_accuracy: 0.7662\n",
      "Epoch 62/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.5050 - accuracy: 0.7752 - val_loss: 0.5055 - val_accuracy: 0.7727\n",
      "Epoch 63/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.5030 - accuracy: 0.7801 - val_loss: 0.5052 - val_accuracy: 0.7597\n",
      "Epoch 64/300\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5053 - accuracy: 0.7801 - val_loss: 0.5016 - val_accuracy: 0.7662\n",
      "Epoch 65/300\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.5024 - accuracy: 0.7785 - val_loss: 0.5124 - val_accuracy: 0.7403\n",
      "Epoch 66/300\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.5069 - accuracy: 0.7720 - val_loss: 0.5085 - val_accuracy: 0.7597\n",
      "Epoch 67/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.5083 - accuracy: 0.7769 - val_loss: 0.5029 - val_accuracy: 0.7727\n",
      "Epoch 68/300\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.5034 - accuracy: 0.7801 - val_loss: 0.5292 - val_accuracy: 0.7468\n",
      "Epoch 69/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.5067 - accuracy: 0.7801 - val_loss: 0.5078 - val_accuracy: 0.7597\n",
      "Epoch 70/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.5041 - accuracy: 0.7720 - val_loss: 0.4997 - val_accuracy: 0.7597\n",
      "Epoch 71/300\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.5034 - accuracy: 0.7850 - val_loss: 0.5008 - val_accuracy: 0.7662\n",
      "Epoch 72/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.5016 - accuracy: 0.7769 - val_loss: 0.5033 - val_accuracy: 0.7662\n",
      "Epoch 73/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.5036 - accuracy: 0.7736 - val_loss: 0.4964 - val_accuracy: 0.7662\n",
      "Epoch 74/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.5042 - accuracy: 0.7866 - val_loss: 0.5039 - val_accuracy: 0.7662\n",
      "Epoch 75/300\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.5039 - accuracy: 0.7687 - val_loss: 0.5009 - val_accuracy: 0.7662\n",
      "Epoch 76/300\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.4994 - accuracy: 0.7980 - val_loss: 0.5015 - val_accuracy: 0.7597\n",
      "Epoch 77/300\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.5035 - accuracy: 0.7785 - val_loss: 0.5001 - val_accuracy: 0.7597\n",
      "Epoch 78/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.5035 - accuracy: 0.7818 - val_loss: 0.5064 - val_accuracy: 0.7662\n",
      "Epoch 79/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4995 - accuracy: 0.7834 - val_loss: 0.4992 - val_accuracy: 0.7597\n",
      "Epoch 80/300\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.5055 - accuracy: 0.7655 - val_loss: 0.4988 - val_accuracy: 0.7662\n",
      "Epoch 81/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4968 - accuracy: 0.7720 - val_loss: 0.5065 - val_accuracy: 0.7532\n",
      "Epoch 82/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4984 - accuracy: 0.7883 - val_loss: 0.5024 - val_accuracy: 0.7662\n",
      "Epoch 83/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.5029 - accuracy: 0.7850 - val_loss: 0.5004 - val_accuracy: 0.7727\n",
      "Epoch 84/300\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.4990 - accuracy: 0.7834 - val_loss: 0.5025 - val_accuracy: 0.7727\n",
      "Epoch 85/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.5004 - accuracy: 0.7883 - val_loss: 0.5001 - val_accuracy: 0.7792\n",
      "Epoch 86/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4988 - accuracy: 0.7752 - val_loss: 0.5016 - val_accuracy: 0.7662\n",
      "Epoch 87/300\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.4967 - accuracy: 0.7850 - val_loss: 0.5012 - val_accuracy: 0.7792\n",
      "Epoch 88/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4980 - accuracy: 0.7866 - val_loss: 0.5024 - val_accuracy: 0.7662\n",
      "Epoch 89/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4970 - accuracy: 0.7834 - val_loss: 0.4991 - val_accuracy: 0.7792\n",
      "Epoch 90/300\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.5020 - accuracy: 0.7687 - val_loss: 0.5005 - val_accuracy: 0.7662\n",
      "Epoch 91/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4968 - accuracy: 0.7818 - val_loss: 0.5038 - val_accuracy: 0.7532\n",
      "Epoch 92/300\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.4975 - accuracy: 0.7801 - val_loss: 0.4978 - val_accuracy: 0.7662\n",
      "Epoch 93/300\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.5013 - accuracy: 0.7769 - val_loss: 0.5053 - val_accuracy: 0.7727\n",
      "Epoch 94/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4957 - accuracy: 0.7769 - val_loss: 0.4979 - val_accuracy: 0.7662\n",
      "Epoch 95/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4963 - accuracy: 0.7801 - val_loss: 0.5142 - val_accuracy: 0.7468\n",
      "Epoch 96/300\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.4944 - accuracy: 0.7866 - val_loss: 0.4967 - val_accuracy: 0.7662\n",
      "Epoch 97/300\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.4961 - accuracy: 0.7687 - val_loss: 0.5045 - val_accuracy: 0.7597\n",
      "Epoch 98/300\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.4962 - accuracy: 0.7818 - val_loss: 0.4995 - val_accuracy: 0.7597\n",
      "Epoch 99/300\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.4922 - accuracy: 0.7866 - val_loss: 0.4973 - val_accuracy: 0.7662\n",
      "Epoch 100/300\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.4955 - accuracy: 0.7883 - val_loss: 0.4982 - val_accuracy: 0.7597\n",
      "Epoch 101/300\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.4977 - accuracy: 0.7850 - val_loss: 0.5000 - val_accuracy: 0.7597\n",
      "Epoch 102/300\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.4945 - accuracy: 0.7801 - val_loss: 0.5052 - val_accuracy: 0.7597\n",
      "Epoch 103/300\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.4951 - accuracy: 0.7834 - val_loss: 0.5009 - val_accuracy: 0.7792\n",
      "Epoch 104/300\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.4969 - accuracy: 0.7834 - val_loss: 0.4971 - val_accuracy: 0.7597\n",
      "Epoch 105/300\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.4961 - accuracy: 0.7834 - val_loss: 0.5000 - val_accuracy: 0.7727\n",
      "Epoch 106/300\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.4964 - accuracy: 0.7834 - val_loss: 0.4981 - val_accuracy: 0.7727\n",
      "Epoch 107/300\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.4952 - accuracy: 0.7883 - val_loss: 0.4960 - val_accuracy: 0.7597\n",
      "Epoch 108/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4915 - accuracy: 0.7834 - val_loss: 0.4995 - val_accuracy: 0.7662\n",
      "Epoch 109/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4951 - accuracy: 0.7899 - val_loss: 0.5052 - val_accuracy: 0.7857\n",
      "Epoch 110/300\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.4985 - accuracy: 0.7752 - val_loss: 0.5009 - val_accuracy: 0.7662\n",
      "Epoch 111/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4927 - accuracy: 0.7866 - val_loss: 0.4965 - val_accuracy: 0.7727\n",
      "Epoch 112/300\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.5005 - accuracy: 0.7704 - val_loss: 0.4982 - val_accuracy: 0.7597\n",
      "Epoch 113/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4911 - accuracy: 0.7866 - val_loss: 0.5009 - val_accuracy: 0.7727\n",
      "Epoch 114/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4921 - accuracy: 0.7866 - val_loss: 0.5005 - val_accuracy: 0.7662\n",
      "Epoch 115/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4956 - accuracy: 0.7785 - val_loss: 0.5010 - val_accuracy: 0.7662\n",
      "Epoch 116/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4907 - accuracy: 0.7899 - val_loss: 0.4968 - val_accuracy: 0.7792\n",
      "Epoch 117/300\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.4927 - accuracy: 0.7818 - val_loss: 0.4964 - val_accuracy: 0.7727\n",
      "Epoch 118/300\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.4943 - accuracy: 0.7769 - val_loss: 0.4971 - val_accuracy: 0.7662\n",
      "Epoch 119/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4931 - accuracy: 0.7801 - val_loss: 0.4988 - val_accuracy: 0.7792\n",
      "Epoch 120/300\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.4895 - accuracy: 0.7899 - val_loss: 0.4968 - val_accuracy: 0.7792\n",
      "Epoch 121/300\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.4913 - accuracy: 0.7850 - val_loss: 0.4979 - val_accuracy: 0.7727\n",
      "Epoch 122/300\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.4918 - accuracy: 0.7752 - val_loss: 0.4975 - val_accuracy: 0.7727\n",
      "Epoch 123/300\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.4959 - accuracy: 0.7801 - val_loss: 0.4961 - val_accuracy: 0.7662\n",
      "Epoch 124/300\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.4911 - accuracy: 0.7850 - val_loss: 0.4967 - val_accuracy: 0.7792\n",
      "Epoch 125/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4915 - accuracy: 0.7834 - val_loss: 0.4976 - val_accuracy: 0.7857\n",
      "Epoch 126/300\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.4916 - accuracy: 0.7720 - val_loss: 0.4987 - val_accuracy: 0.7727\n",
      "Epoch 127/300\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.4918 - accuracy: 0.7801 - val_loss: 0.4923 - val_accuracy: 0.7727\n",
      "Epoch 128/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4920 - accuracy: 0.7866 - val_loss: 0.4941 - val_accuracy: 0.7597\n",
      "Epoch 129/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4902 - accuracy: 0.7785 - val_loss: 0.5000 - val_accuracy: 0.7727\n",
      "Epoch 130/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4946 - accuracy: 0.7687 - val_loss: 0.4954 - val_accuracy: 0.7857\n",
      "Epoch 131/300\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.4918 - accuracy: 0.7801 - val_loss: 0.5051 - val_accuracy: 0.7662\n",
      "Epoch 132/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4896 - accuracy: 0.7899 - val_loss: 0.5013 - val_accuracy: 0.7597\n",
      "Epoch 133/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4926 - accuracy: 0.7785 - val_loss: 0.5001 - val_accuracy: 0.7662\n",
      "Epoch 134/300\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.4912 - accuracy: 0.7866 - val_loss: 0.5002 - val_accuracy: 0.7532\n",
      "Epoch 135/300\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.4910 - accuracy: 0.7769 - val_loss: 0.4953 - val_accuracy: 0.7597\n",
      "Epoch 136/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4913 - accuracy: 0.7752 - val_loss: 0.4960 - val_accuracy: 0.7727\n",
      "Epoch 137/300\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.4922 - accuracy: 0.7785 - val_loss: 0.5025 - val_accuracy: 0.7468\n",
      "Epoch 138/300\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.4887 - accuracy: 0.7866 - val_loss: 0.5047 - val_accuracy: 0.7532\n",
      "Epoch 139/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4898 - accuracy: 0.7785 - val_loss: 0.4950 - val_accuracy: 0.7662\n",
      "Epoch 140/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4909 - accuracy: 0.7769 - val_loss: 0.4984 - val_accuracy: 0.7662\n",
      "Epoch 141/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4924 - accuracy: 0.7948 - val_loss: 0.5096 - val_accuracy: 0.7468\n",
      "Epoch 142/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4891 - accuracy: 0.7736 - val_loss: 0.4974 - val_accuracy: 0.7792\n",
      "Epoch 143/300\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.4888 - accuracy: 0.7850 - val_loss: 0.4963 - val_accuracy: 0.7727\n",
      "Epoch 144/300\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.4890 - accuracy: 0.7866 - val_loss: 0.4906 - val_accuracy: 0.7662\n",
      "Epoch 145/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4874 - accuracy: 0.7899 - val_loss: 0.5003 - val_accuracy: 0.7597\n",
      "Epoch 146/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4887 - accuracy: 0.7687 - val_loss: 0.4918 - val_accuracy: 0.7662\n",
      "Epoch 147/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4886 - accuracy: 0.7899 - val_loss: 0.4948 - val_accuracy: 0.7792\n",
      "Epoch 148/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4898 - accuracy: 0.7785 - val_loss: 0.4925 - val_accuracy: 0.7662\n",
      "Epoch 149/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4885 - accuracy: 0.7801 - val_loss: 0.4937 - val_accuracy: 0.7662\n",
      "Epoch 150/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4866 - accuracy: 0.7834 - val_loss: 0.4935 - val_accuracy: 0.7727\n",
      "Epoch 151/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4899 - accuracy: 0.7915 - val_loss: 0.4972 - val_accuracy: 0.7662\n",
      "Epoch 152/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4866 - accuracy: 0.7752 - val_loss: 0.4943 - val_accuracy: 0.7792\n",
      "Epoch 153/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4870 - accuracy: 0.7834 - val_loss: 0.4956 - val_accuracy: 0.7727\n",
      "Epoch 154/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4915 - accuracy: 0.7785 - val_loss: 0.4951 - val_accuracy: 0.7662\n",
      "Epoch 155/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4882 - accuracy: 0.7736 - val_loss: 0.4930 - val_accuracy: 0.7662\n",
      "Epoch 156/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4859 - accuracy: 0.7883 - val_loss: 0.4929 - val_accuracy: 0.7727\n",
      "Epoch 157/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4865 - accuracy: 0.7818 - val_loss: 0.4986 - val_accuracy: 0.7662\n",
      "Epoch 158/300\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.4883 - accuracy: 0.7818 - val_loss: 0.4978 - val_accuracy: 0.7532\n",
      "Epoch 159/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4853 - accuracy: 0.7850 - val_loss: 0.4969 - val_accuracy: 0.7727\n",
      "Epoch 160/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4873 - accuracy: 0.7834 - val_loss: 0.4900 - val_accuracy: 0.7727\n",
      "Epoch 161/300\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.4848 - accuracy: 0.7834 - val_loss: 0.4968 - val_accuracy: 0.7857\n",
      "Epoch 162/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4884 - accuracy: 0.7818 - val_loss: 0.4952 - val_accuracy: 0.7727\n",
      "Epoch 163/300\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.4854 - accuracy: 0.7834 - val_loss: 0.4943 - val_accuracy: 0.7727\n",
      "Epoch 164/300\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.4827 - accuracy: 0.7785 - val_loss: 0.5105 - val_accuracy: 0.7403\n",
      "Epoch 165/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4899 - accuracy: 0.7818 - val_loss: 0.4936 - val_accuracy: 0.7662\n",
      "Epoch 166/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4863 - accuracy: 0.7850 - val_loss: 0.4894 - val_accuracy: 0.7727\n",
      "Epoch 167/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4851 - accuracy: 0.7785 - val_loss: 0.4967 - val_accuracy: 0.7792\n",
      "Epoch 168/300\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.4883 - accuracy: 0.7866 - val_loss: 0.4928 - val_accuracy: 0.7727\n",
      "Epoch 169/300\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.4834 - accuracy: 0.7915 - val_loss: 0.4946 - val_accuracy: 0.7662\n",
      "Epoch 170/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4900 - accuracy: 0.7948 - val_loss: 0.4957 - val_accuracy: 0.7727\n",
      "Epoch 171/300\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.4887 - accuracy: 0.7818 - val_loss: 0.4920 - val_accuracy: 0.7662\n",
      "Epoch 172/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4852 - accuracy: 0.7785 - val_loss: 0.4991 - val_accuracy: 0.7532\n",
      "Epoch 173/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4858 - accuracy: 0.7899 - val_loss: 0.4957 - val_accuracy: 0.7662\n",
      "Epoch 174/300\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.4838 - accuracy: 0.77 - 0s 7ms/step - loss: 0.4885 - accuracy: 0.7720 - val_loss: 0.4902 - val_accuracy: 0.7792\n",
      "Epoch 175/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4836 - accuracy: 0.7834 - val_loss: 0.4896 - val_accuracy: 0.7792\n",
      "Epoch 176/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4834 - accuracy: 0.7834 - val_loss: 0.4907 - val_accuracy: 0.7597\n",
      "Epoch 177/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4870 - accuracy: 0.7818 - val_loss: 0.5000 - val_accuracy: 0.7727\n",
      "Epoch 178/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4878 - accuracy: 0.7687 - val_loss: 0.4915 - val_accuracy: 0.7662\n",
      "Epoch 179/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4847 - accuracy: 0.7883 - val_loss: 0.4966 - val_accuracy: 0.7662\n",
      "Epoch 180/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4886 - accuracy: 0.7655 - val_loss: 0.4903 - val_accuracy: 0.7857\n",
      "Epoch 181/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4852 - accuracy: 0.7818 - val_loss: 0.4938 - val_accuracy: 0.7727\n",
      "Epoch 182/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4802 - accuracy: 0.7736 - val_loss: 0.5073 - val_accuracy: 0.7273\n",
      "Epoch 183/300\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.4858 - accuracy: 0.7801 - val_loss: 0.4929 - val_accuracy: 0.7662\n",
      "Epoch 184/300\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.4828 - accuracy: 0.7932 - val_loss: 0.4916 - val_accuracy: 0.7792\n",
      "Epoch 185/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4852 - accuracy: 0.7834 - val_loss: 0.4904 - val_accuracy: 0.7727\n",
      "Epoch 186/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4867 - accuracy: 0.7834 - val_loss: 0.4920 - val_accuracy: 0.7792\n",
      "Epoch 187/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4817 - accuracy: 0.7883 - val_loss: 0.4879 - val_accuracy: 0.7597\n",
      "Epoch 188/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4832 - accuracy: 0.7850 - val_loss: 0.4916 - val_accuracy: 0.7727\n",
      "Epoch 189/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4832 - accuracy: 0.7801 - val_loss: 0.5088 - val_accuracy: 0.7532\n",
      "Epoch 190/300\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.4892 - accuracy: 0.7687 - val_loss: 0.5061 - val_accuracy: 0.7338\n",
      "Epoch 191/300\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.4832 - accuracy: 0.7883 - val_loss: 0.4887 - val_accuracy: 0.7662\n",
      "Epoch 192/300\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.4816 - accuracy: 0.7769 - val_loss: 0.4991 - val_accuracy: 0.7597\n",
      "Epoch 193/300\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.4864 - accuracy: 0.7720 - val_loss: 0.4946 - val_accuracy: 0.7727\n",
      "Epoch 194/300\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.4822 - accuracy: 0.7818 - val_loss: 0.4914 - val_accuracy: 0.7727\n",
      "Epoch 195/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4861 - accuracy: 0.7720 - val_loss: 0.4969 - val_accuracy: 0.7792\n",
      "Epoch 196/300\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.4848 - accuracy: 0.7850 - val_loss: 0.4921 - val_accuracy: 0.7727\n",
      "Epoch 197/300\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.4851 - accuracy: 0.7785 - val_loss: 0.4974 - val_accuracy: 0.7532\n",
      "Epoch 198/300\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.4843 - accuracy: 0.7769 - val_loss: 0.4972 - val_accuracy: 0.7597\n",
      "Epoch 199/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4900 - accuracy: 0.7883 - val_loss: 0.5002 - val_accuracy: 0.7597\n",
      "Epoch 200/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4829 - accuracy: 0.7752 - val_loss: 0.4889 - val_accuracy: 0.7727\n",
      "Epoch 201/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4809 - accuracy: 0.7769 - val_loss: 0.5035 - val_accuracy: 0.7338\n",
      "Epoch 202/300\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.4857 - accuracy: 0.7769 - val_loss: 0.5012 - val_accuracy: 0.7532\n",
      "Epoch 203/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4853 - accuracy: 0.7785 - val_loss: 0.4917 - val_accuracy: 0.7792\n",
      "Epoch 204/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4816 - accuracy: 0.7899 - val_loss: 0.4952 - val_accuracy: 0.7792\n",
      "Epoch 205/300\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.4849 - accuracy: 0.7818 - val_loss: 0.5043 - val_accuracy: 0.7468\n",
      "Epoch 206/300\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.4808 - accuracy: 0.7850 - val_loss: 0.4884 - val_accuracy: 0.7662\n",
      "Epoch 207/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4808 - accuracy: 0.7801 - val_loss: 0.5067 - val_accuracy: 0.7468\n",
      "Epoch 208/300\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.4806 - accuracy: 0.7915 - val_loss: 0.5055 - val_accuracy: 0.7403\n",
      "Epoch 209/300\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.4833 - accuracy: 0.7818 - val_loss: 0.4947 - val_accuracy: 0.7662\n",
      "Epoch 210/300\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.4849 - accuracy: 0.7801 - val_loss: 0.5038 - val_accuracy: 0.7468\n",
      "Epoch 211/300\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.4872 - accuracy: 0.7932 - val_loss: 0.4918 - val_accuracy: 0.7792\n",
      "Epoch 212/300\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.4891 - accuracy: 0.7769 - val_loss: 0.4894 - val_accuracy: 0.7857\n",
      "Epoch 213/300\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.4843 - accuracy: 0.7785 - val_loss: 0.4960 - val_accuracy: 0.7597\n",
      "Epoch 214/300\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.4808 - accuracy: 0.7850 - val_loss: 0.4894 - val_accuracy: 0.7857\n",
      "Epoch 215/300\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.4809 - accuracy: 0.7818 - val_loss: 0.5021 - val_accuracy: 0.7403\n",
      "Epoch 216/300\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.4815 - accuracy: 0.7801 - val_loss: 0.4888 - val_accuracy: 0.7792\n",
      "Epoch 217/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4824 - accuracy: 0.7801 - val_loss: 0.4869 - val_accuracy: 0.7727\n",
      "Epoch 218/300\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.4822 - accuracy: 0.7834 - val_loss: 0.4909 - val_accuracy: 0.7792\n",
      "Epoch 219/300\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.4811 - accuracy: 0.7785 - val_loss: 0.4943 - val_accuracy: 0.7662\n",
      "Epoch 220/300\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.4815 - accuracy: 0.7769 - val_loss: 0.4905 - val_accuracy: 0.7727\n",
      "Epoch 221/300\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.4829 - accuracy: 0.7883 - val_loss: 0.4960 - val_accuracy: 0.7792\n",
      "Epoch 222/300\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.4793 - accuracy: 0.7883 - val_loss: 0.4907 - val_accuracy: 0.7792\n",
      "Epoch 223/300\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.4798 - accuracy: 0.7785 - val_loss: 0.5039 - val_accuracy: 0.7403\n",
      "Epoch 224/300\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.4827 - accuracy: 0.7818 - val_loss: 0.4883 - val_accuracy: 0.7662\n",
      "Epoch 225/300\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.4813 - accuracy: 0.7818 - val_loss: 0.4940 - val_accuracy: 0.7662\n",
      "Epoch 226/300\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.4820 - accuracy: 0.7834 - val_loss: 0.4945 - val_accuracy: 0.7662\n",
      "Epoch 227/300\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.4813 - accuracy: 0.7736 - val_loss: 0.4988 - val_accuracy: 0.7532\n",
      "Epoch 228/300\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.4812 - accuracy: 0.7769 - val_loss: 0.4929 - val_accuracy: 0.7662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4797 - accuracy: 0.7834 - val_loss: 0.4909 - val_accuracy: 0.7792\n",
      "Epoch 230/300\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.4779 - accuracy: 0.7899 - val_loss: 0.4903 - val_accuracy: 0.7792\n",
      "Epoch 231/300\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.4880 - accuracy: 0.7801 - val_loss: 0.4945 - val_accuracy: 0.7792\n",
      "Epoch 232/300\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.4802 - accuracy: 0.7752 - val_loss: 0.4943 - val_accuracy: 0.7727\n",
      "Epoch 233/300\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.4858 - accuracy: 0.7769 - val_loss: 0.4868 - val_accuracy: 0.7857\n",
      "Epoch 234/300\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.4795 - accuracy: 0.7883 - val_loss: 0.4879 - val_accuracy: 0.7792\n",
      "Epoch 235/300\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.4786 - accuracy: 0.7850 - val_loss: 0.5048 - val_accuracy: 0.7597\n",
      "Epoch 236/300\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.4823 - accuracy: 0.7964 - val_loss: 0.5119 - val_accuracy: 0.7532\n",
      "Epoch 237/300\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.4825 - accuracy: 0.7818 - val_loss: 0.4929 - val_accuracy: 0.7727\n",
      "Epoch 238/300\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.4799 - accuracy: 0.7899 - val_loss: 0.5015 - val_accuracy: 0.7468\n",
      "Epoch 239/300\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.4808 - accuracy: 0.7818 - val_loss: 0.4920 - val_accuracy: 0.7792\n",
      "Epoch 240/300\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.4827 - accuracy: 0.7769 - val_loss: 0.4960 - val_accuracy: 0.7727\n",
      "Epoch 241/300\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.4777 - accuracy: 0.7850 - val_loss: 0.4899 - val_accuracy: 0.7792\n",
      "Epoch 242/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4771 - accuracy: 0.7866 - val_loss: 0.4966 - val_accuracy: 0.7792\n",
      "Epoch 243/300\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.4833 - accuracy: 0.7752 - val_loss: 0.4877 - val_accuracy: 0.7792\n",
      "Epoch 244/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4781 - accuracy: 0.7850 - val_loss: 0.4943 - val_accuracy: 0.7597\n",
      "Epoch 245/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4775 - accuracy: 0.7720 - val_loss: 0.4965 - val_accuracy: 0.7532\n",
      "Epoch 246/300\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.4812 - accuracy: 0.7769 - val_loss: 0.4947 - val_accuracy: 0.7727\n",
      "Epoch 247/300\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.4811 - accuracy: 0.7899 - val_loss: 0.4965 - val_accuracy: 0.7727\n",
      "Epoch 248/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4771 - accuracy: 0.7834 - val_loss: 0.4943 - val_accuracy: 0.7727\n",
      "Epoch 249/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4779 - accuracy: 0.7801 - val_loss: 0.4960 - val_accuracy: 0.7792\n",
      "Epoch 250/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4821 - accuracy: 0.7769 - val_loss: 0.4879 - val_accuracy: 0.7662\n",
      "Epoch 251/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4763 - accuracy: 0.7769 - val_loss: 0.5125 - val_accuracy: 0.7468\n",
      "Epoch 252/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4823 - accuracy: 0.7899 - val_loss: 0.4979 - val_accuracy: 0.7532\n",
      "Epoch 253/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4786 - accuracy: 0.7785 - val_loss: 0.4913 - val_accuracy: 0.7792\n",
      "Epoch 254/300\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.4789 - accuracy: 0.7834 - val_loss: 0.4958 - val_accuracy: 0.7662\n",
      "Epoch 255/300\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.4828 - accuracy: 0.7834 - val_loss: 0.4896 - val_accuracy: 0.7727\n",
      "Epoch 256/300\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.4822 - accuracy: 0.7850 - val_loss: 0.4881 - val_accuracy: 0.7727\n",
      "Epoch 257/300\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.4741 - accuracy: 0.7785 - val_loss: 0.5126 - val_accuracy: 0.7532\n",
      "Epoch 258/300\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.4813 - accuracy: 0.7866 - val_loss: 0.4914 - val_accuracy: 0.7857\n",
      "Epoch 259/300\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.4779 - accuracy: 0.7932 - val_loss: 0.4871 - val_accuracy: 0.7597\n",
      "Epoch 260/300\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.4804 - accuracy: 0.7801 - val_loss: 0.4990 - val_accuracy: 0.7532\n",
      "Epoch 261/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4766 - accuracy: 0.7801 - val_loss: 0.4891 - val_accuracy: 0.7792\n",
      "Epoch 262/300\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.4785 - accuracy: 0.7866 - val_loss: 0.4878 - val_accuracy: 0.7662\n",
      "Epoch 263/300\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.4791 - accuracy: 0.7883 - val_loss: 0.4874 - val_accuracy: 0.7662\n",
      "Epoch 264/300\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.4791 - accuracy: 0.7834 - val_loss: 0.4929 - val_accuracy: 0.7727\n",
      "Epoch 265/300\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.4777 - accuracy: 0.7834 - val_loss: 0.4903 - val_accuracy: 0.7727\n",
      "Epoch 266/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4768 - accuracy: 0.7899 - val_loss: 0.4926 - val_accuracy: 0.7792\n",
      "Epoch 267/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4777 - accuracy: 0.7866 - val_loss: 0.4877 - val_accuracy: 0.7662\n",
      "Epoch 268/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4780 - accuracy: 0.7736 - val_loss: 0.4992 - val_accuracy: 0.7403\n",
      "Epoch 269/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4782 - accuracy: 0.7818 - val_loss: 0.4881 - val_accuracy: 0.7662\n",
      "Epoch 270/300\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.4761 - accuracy: 0.7883 - val_loss: 0.4921 - val_accuracy: 0.7792\n",
      "Epoch 271/300\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.4781 - accuracy: 0.7801 - val_loss: 0.4915 - val_accuracy: 0.7727\n",
      "Epoch 272/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4755 - accuracy: 0.7769 - val_loss: 0.4974 - val_accuracy: 0.7532\n",
      "Epoch 273/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4788 - accuracy: 0.7866 - val_loss: 0.4924 - val_accuracy: 0.7727\n",
      "Epoch 274/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4788 - accuracy: 0.7704 - val_loss: 0.4925 - val_accuracy: 0.7792\n",
      "Epoch 275/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4769 - accuracy: 0.7850 - val_loss: 0.4857 - val_accuracy: 0.7662\n",
      "Epoch 276/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4808 - accuracy: 0.7769 - val_loss: 0.4883 - val_accuracy: 0.7792\n",
      "Epoch 277/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4745 - accuracy: 0.7850 - val_loss: 0.5115 - val_accuracy: 0.7468\n",
      "Epoch 278/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4839 - accuracy: 0.7769 - val_loss: 0.4918 - val_accuracy: 0.7727\n",
      "Epoch 279/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4765 - accuracy: 0.7883 - val_loss: 0.4922 - val_accuracy: 0.7662\n",
      "Epoch 280/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4760 - accuracy: 0.7834 - val_loss: 0.4889 - val_accuracy: 0.7727\n",
      "Epoch 281/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4760 - accuracy: 0.7834 - val_loss: 0.4988 - val_accuracy: 0.7532\n",
      "Epoch 282/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4775 - accuracy: 0.7883 - val_loss: 0.4944 - val_accuracy: 0.7727\n",
      "Epoch 283/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4785 - accuracy: 0.7850 - val_loss: 0.4886 - val_accuracy: 0.7792\n",
      "Epoch 284/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4724 - accuracy: 0.7899 - val_loss: 0.4915 - val_accuracy: 0.7857\n",
      "Epoch 285/300\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.4776 - accuracy: 0.7801 - val_loss: 0.4952 - val_accuracy: 0.7727\n",
      "Epoch 286/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 0s 8ms/step - loss: 0.4762 - accuracy: 0.7850 - val_loss: 0.4926 - val_accuracy: 0.7662\n",
      "Epoch 287/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4776 - accuracy: 0.7883 - val_loss: 0.4902 - val_accuracy: 0.7727\n",
      "Epoch 288/300\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.4767 - accuracy: 0.7834 - val_loss: 0.4910 - val_accuracy: 0.7792\n",
      "Epoch 289/300\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.4763 - accuracy: 0.7818 - val_loss: 0.4928 - val_accuracy: 0.7727\n",
      "Epoch 290/300\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.4771 - accuracy: 0.7769 - val_loss: 0.4913 - val_accuracy: 0.7727\n",
      "Epoch 291/300\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.4750 - accuracy: 0.7834 - val_loss: 0.4932 - val_accuracy: 0.7857\n",
      "Epoch 292/300\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.4759 - accuracy: 0.7818 - val_loss: 0.4902 - val_accuracy: 0.7727\n",
      "Epoch 293/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4759 - accuracy: 0.7932 - val_loss: 0.4973 - val_accuracy: 0.7662\n",
      "Epoch 294/300\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4767 - accuracy: 0.7785 - val_loss: 0.4978 - val_accuracy: 0.7597\n",
      "Epoch 295/300\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.4775 - accuracy: 0.7834 - val_loss: 0.4951 - val_accuracy: 0.7792\n",
      "Epoch 296/300\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.4743 - accuracy: 0.7883 - val_loss: 0.4926 - val_accuracy: 0.7727\n",
      "Epoch 297/300\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.4749 - accuracy: 0.7769 - val_loss: 0.4902 - val_accuracy: 0.7792\n",
      "Epoch 298/300\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.4767 - accuracy: 0.7899 - val_loss: 0.4873 - val_accuracy: 0.7857\n",
      "Epoch 299/300\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.4730 - accuracy: 0.7834 - val_loss: 0.4920 - val_accuracy: 0.7792\n",
      "Epoch 300/300\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.4770 - accuracy: 0.7801 - val_loss: 0.4971 - val_accuracy: 0.7662\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4971 - accuracy: 0.7662\n",
      "Test Accuracy: 0.7662\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, Flatten, Dropout, MaxPooling1D\n",
    "from keras import regularizers\n",
    "import keras\n",
    "from sklearn.model_selection import cross_val_score\n",
    "model_cnn = Sequential()\n",
    "#step convolution\n",
    "model_cnn.add(Conv1D(10, kernel_size=2, activation='relu', input_shape=(8,1), data_format = 'channels_last'))\n",
    "#step 2 pooling\n",
    "model_cnn.add(MaxPooling1D(pool_size=1, padding='same'))\n",
    "#step 3 flattening\n",
    "model_cnn.add(Flatten())# partie de MLP\n",
    "# step 4 full connection\n",
    "model_cnn.add(Dense(26, input_dim=26, kernel_regularizer=regularizers.l2(0.04), activation='relu'))\n",
    "model_cnn.add(Dense(1, kernel_regularizer=regularizers.l2(0.02), activation='sigmoid'))\n",
    "# compiling CNN\n",
    "model_cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "#train CNN\n",
    "history=model_cnn.fit(X_train, y_train, batch_size=10, epochs=300,validation_data=(X_test, y_test))\n",
    "\n",
    "    \n",
    "loss, accuracy = model_cnn.evaluate(X_test, y_test, batch_size=None, verbose=1)\n",
    "print(\"Test Accuracy: {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb71b517",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
